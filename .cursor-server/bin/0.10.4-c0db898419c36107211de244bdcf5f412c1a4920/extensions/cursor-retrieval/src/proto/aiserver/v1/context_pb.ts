// @generated by protoc-gen-es v1.2.1 with parameter "target=ts"
// @generated from file aiserver/v1/context.proto (package aiserver.v1, syntax proto3)
/* eslint-disable */
// @ts-nocheck

import type { BinaryReadOptions, FieldList, JsonReadOptions, JsonValue, PartialMessage, PlainMessage } from "@bufbuild/protobuf";
import { Message, proto3 } from "@bufbuild/protobuf";
import { DocumentSymbol, LineRange, Lint, LintSeverity, SimpleRange } from './utils_pb';

/**
 * @generated from message aiserver.v1.PotentiallyCachedContextItem
 */
export class PotentiallyCachedContextItem extends Message<PotentiallyCachedContextItem> {
  /**
   * @generated from oneof aiserver.v1.PotentiallyCachedContextItem.item
   */
  item: {
    /**
     * @generated from field: aiserver.v1.ContextItem context_item = 1;
     */
    value: ContextItem;
    case: "contextItem";
  } | {
    /**
     * @generated from field: string context_item_hash = 2;
     */
    value: string;
    case: "contextItemHash";
  } | { case: undefined; value?: undefined } = { case: undefined };

  constructor(data?: PartialMessage<PotentiallyCachedContextItem>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.PotentiallyCachedContextItem";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "context_item", kind: "message", T: ContextItem, oneof: "item" },
    { no: 2, name: "context_item_hash", kind: "scalar", T: 9 /* ScalarType.STRING */, oneof: "item" },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): PotentiallyCachedContextItem {
    return new PotentiallyCachedContextItem().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): PotentiallyCachedContextItem {
    return new PotentiallyCachedContextItem().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): PotentiallyCachedContextItem {
    return new PotentiallyCachedContextItem().fromJsonString(jsonString, options);
  }

  static equals(a: PotentiallyCachedContextItem | PlainMessage<PotentiallyCachedContextItem> | undefined, b: PotentiallyCachedContextItem | PlainMessage<PotentiallyCachedContextItem> | undefined): boolean {
    return proto3.util.equals(PotentiallyCachedContextItem, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextStatusUpdate
 */
export class ContextStatusUpdate extends Message<ContextStatusUpdate> {
  /**
   * ALL context items that were in the request MUST BE included in the response
   *
   * @generated from field: repeated aiserver.v1.ContextItemStatus context_item_statuses = 1;
   */
  contextItemStatuses: ContextItemStatus[] = [];

  constructor(data?: PartialMessage<ContextStatusUpdate>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextStatusUpdate";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "context_item_statuses", kind: "message", T: ContextItemStatus, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextStatusUpdate {
    return new ContextStatusUpdate().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextStatusUpdate {
    return new ContextStatusUpdate().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextStatusUpdate {
    return new ContextStatusUpdate().fromJsonString(jsonString, options);
  }

  static equals(a: ContextStatusUpdate | PlainMessage<ContextStatusUpdate> | undefined, b: ContextStatusUpdate | PlainMessage<ContextStatusUpdate> | undefined): boolean {
    return proto3.util.equals(ContextStatusUpdate, a, b);
  }
}

/**
 * @generated from message aiserver.v1.MissingContextItems
 */
export class MissingContextItems extends Message<MissingContextItems> {
  /**
   * if there are any missing context items on the server (which can happen! could be evicted from the cache, could be routed to a new server because the pod crashed, etc) then the client should immediately retry the request with all the missing context items
   *
   * @generated from field: repeated string missing_context_item_hashes = 2;
   */
  missingContextItemHashes: string[] = [];

  constructor(data?: PartialMessage<MissingContextItems>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.MissingContextItems";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 2, name: "missing_context_item_hashes", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): MissingContextItems {
    return new MissingContextItems().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): MissingContextItems {
    return new MissingContextItems().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): MissingContextItems {
    return new MissingContextItems().fromJsonString(jsonString, options);
  }

  static equals(a: MissingContextItems | PlainMessage<MissingContextItems> | undefined, b: MissingContextItems | PlainMessage<MissingContextItems> | undefined): boolean {
    return proto3.util.equals(MissingContextItems, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextItemStatus
 */
export class ContextItemStatus extends Message<ContextItemStatus> {
  /**
   * @generated from field: string context_item_hash = 1;
   */
  contextItemHash = "";

  /**
   * @generated from field: bool shown_to_the_model = 2;
   */
  shownToTheModel = false;

  /**
   * higher score means more likely to be included by the model
   *
   * @generated from field: float score = 3;
   */
  score = 0;

  /**
   * percentage of available space tells you how much of the available context window this context item takes
   *
   * @generated from field: float percentage_of_available_space = 4;
   */
  percentageOfAvailableSpace = 0;

  /**
   * @generated from field: aiserver.v1.ContextItemStatus.PostGenerationEvaluation post_generation_evaluation = 5;
   */
  postGenerationEvaluation = ContextItemStatus_PostGenerationEvaluation.UNSPECIFIED;

  constructor(data?: PartialMessage<ContextItemStatus>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextItemStatus";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "context_item_hash", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "shown_to_the_model", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 3, name: "score", kind: "scalar", T: 2 /* ScalarType.FLOAT */ },
    { no: 4, name: "percentage_of_available_space", kind: "scalar", T: 2 /* ScalarType.FLOAT */ },
    { no: 5, name: "post_generation_evaluation", kind: "enum", T: proto3.getEnumType(ContextItemStatus_PostGenerationEvaluation) },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextItemStatus {
    return new ContextItemStatus().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextItemStatus {
    return new ContextItemStatus().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextItemStatus {
    return new ContextItemStatus().fromJsonString(jsonString, options);
  }

  static equals(a: ContextItemStatus | PlainMessage<ContextItemStatus> | undefined, b: ContextItemStatus | PlainMessage<ContextItemStatus> | undefined): boolean {
    return proto3.util.equals(ContextItemStatus, a, b);
  }
}

/**
 * @generated from enum aiserver.v1.ContextItemStatus.PostGenerationEvaluation
 */
export enum ContextItemStatus_PostGenerationEvaluation {
  /**
   * @generated from enum value: POST_GENERATION_EVALUATION_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: POST_GENERATION_EVALUATION_USEFUL = 1;
   */
  USEFUL = 1,

  /**
   * @generated from enum value: POST_GENERATION_EVALUATION_USELESS = 2;
   */
  USELESS = 2,
}
// Retrieve enum metadata with: proto3.getEnumType(ContextItemStatus_PostGenerationEvaluation)
proto3.util.setEnumType(ContextItemStatus_PostGenerationEvaluation, "aiserver.v1.ContextItemStatus.PostGenerationEvaluation", [
  { no: 0, name: "POST_GENERATION_EVALUATION_UNSPECIFIED" },
  { no: 1, name: "POST_GENERATION_EVALUATION_USEFUL" },
  { no: 2, name: "POST_GENERATION_EVALUATION_USELESS" },
]);

/**
 * the context item is the unit of context
 * it cannot be split up
 * each one should be independently renderable and not depend on anything else — not actually obvious to me!
 * if T is the rendered length of the context item, the space used by the serialized context item must be O(T)
 *
 * @generated from message aiserver.v1.ContextItem
 */
export class ContextItem extends Message<ContextItem> {
  /**
   * the intent that was the source of the context item
   *
   * @generated from field: aiserver.v1.ContextIntent intent = 1;
   */
  intent?: ContextIntent;

  /**
   * feel free to be liberal about adding types here. we can handle a lot of them, and it's better to let different things be different than to introduce unnecessary coupling
   *
   * @generated from oneof aiserver.v1.ContextItem.item
   */
  item: {
    /**
     * @generated from field: aiserver.v1.ContextItem.FileChunk file_chunk = 2;
     */
    value: ContextItem_FileChunk;
    case: "fileChunk";
  } | {
    /**
     * @generated from field: aiserver.v1.ContextItem.OutlineChunk outline_chunk = 3;
     */
    value: ContextItem_OutlineChunk;
    case: "outlineChunk";
  } | {
    /**
     * @generated from field: aiserver.v1.ContextItem.CmdKSelection cmd_k_selection = 4;
     */
    value: ContextItem_CmdKSelection;
    case: "cmdKSelection";
  } | {
    /**
     * @generated from field: aiserver.v1.ContextItem.CmdKImmediateContext cmd_k_immediate_context = 5;
     */
    value: ContextItem_CmdKImmediateContext;
    case: "cmdKImmediateContext";
  } | {
    /**
     * @generated from field: aiserver.v1.ContextItem.CmdKQuery cmd_k_query = 6;
     */
    value: ContextItem_CmdKQuery;
    case: "cmdKQuery";
  } | {
    /**
     * @generated from field: aiserver.v1.ContextItem.CmdKQueryHistory cmd_k_query_history = 7;
     */
    value: ContextItem_CmdKQueryHistory;
    case: "cmdKQueryHistory";
  } | {
    /**
     * @generated from field: aiserver.v1.ContextItem.CustomInstructions custom_instructions = 8;
     */
    value: ContextItem_CustomInstructions;
    case: "customInstructions";
  } | {
    /**
     * @generated from field: aiserver.v1.ContextItem.GoToDefinitionResult go_to_definition_result = 9;
     */
    value: ContextItem_GoToDefinitionResult;
    case: "goToDefinitionResult";
  } | {
    /**
     * @generated from field: aiserver.v1.ContextItem.DocumentationChunk documentation_chunk = 10;
     */
    value: ContextItem_DocumentationChunk;
    case: "documentationChunk";
  } | {
    /**
     * TODO: here we can add things that are more intent-like too!
     * for example, for advanced codebase context, we don't want to compute the item on-keypress, but rather just once after the user submits their query. in that case, the context item is just simply equal to the intent! and we can't really trust the context statuses. but the reranking still kind of works! or maybe in that case we just don't do any reranking at all while writing the query, and just do all of it at the end? and then probably in the style of a task, which makes sense to me! but yeah this abstraction still works!
     *
     * @generated from field: aiserver.v1.ContextItem.Lints lints = 11;
     */
    value: ContextItem_Lints;
    case: "lints";
  } | { case: undefined; value?: undefined } = { case: undefined };

  constructor(data?: PartialMessage<ContextItem>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextItem";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "intent", kind: "message", T: ContextIntent },
    { no: 2, name: "file_chunk", kind: "message", T: ContextItem_FileChunk, oneof: "item" },
    { no: 3, name: "outline_chunk", kind: "message", T: ContextItem_OutlineChunk, oneof: "item" },
    { no: 4, name: "cmd_k_selection", kind: "message", T: ContextItem_CmdKSelection, oneof: "item" },
    { no: 5, name: "cmd_k_immediate_context", kind: "message", T: ContextItem_CmdKImmediateContext, oneof: "item" },
    { no: 6, name: "cmd_k_query", kind: "message", T: ContextItem_CmdKQuery, oneof: "item" },
    { no: 7, name: "cmd_k_query_history", kind: "message", T: ContextItem_CmdKQueryHistory, oneof: "item" },
    { no: 8, name: "custom_instructions", kind: "message", T: ContextItem_CustomInstructions, oneof: "item" },
    { no: 9, name: "go_to_definition_result", kind: "message", T: ContextItem_GoToDefinitionResult, oneof: "item" },
    { no: 10, name: "documentation_chunk", kind: "message", T: ContextItem_DocumentationChunk, oneof: "item" },
    { no: 11, name: "lints", kind: "message", T: ContextItem_Lints, oneof: "item" },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextItem {
    return new ContextItem().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextItem {
    return new ContextItem().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextItem {
    return new ContextItem().fromJsonString(jsonString, options);
  }

  static equals(a: ContextItem | PlainMessage<ContextItem> | undefined, b: ContextItem | PlainMessage<ContextItem> | undefined): boolean {
    return proto3.util.equals(ContextItem, a, b);
  }
}

/**
 * file chunk is just a plain simple chunk taken directly from a file
 * processed chunks are either OutlineChunks or something else!
 *
 * @generated from message aiserver.v1.ContextItem.FileChunk
 */
export class ContextItem_FileChunk extends Message<ContextItem_FileChunk> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * why not do a repeated lines thing here?
   *
   * @generated from field: string chunk_contents = 2;
   */
  chunkContents = "";

  /**
   * we only include start line number and nothing else, to make sure our data storage is not redundant
   * end line number is implied by the number of lines
   * and we always replace entire lines, so column numbers are not necessary
   *
   * @generated from field: int32 start_line_number = 3;
   */
  startLineNumber = 0;

  constructor(data?: PartialMessage<ContextItem_FileChunk>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextItem.FileChunk";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "chunk_contents", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "start_line_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextItem_FileChunk {
    return new ContextItem_FileChunk().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextItem_FileChunk {
    return new ContextItem_FileChunk().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextItem_FileChunk {
    return new ContextItem_FileChunk().fromJsonString(jsonString, options);
  }

  static equals(a: ContextItem_FileChunk | PlainMessage<ContextItem_FileChunk> | undefined, b: ContextItem_FileChunk | PlainMessage<ContextItem_FileChunk> | undefined): boolean {
    return proto3.util.equals(ContextItem_FileChunk, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextItem.OutlineChunk
 */
export class ContextItem_OutlineChunk extends Message<ContextItem_OutlineChunk> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * for now we don't really provide any structured data here. we could if we wanted to
   *
   * @generated from field: string contents = 2;
   */
  contents = "";

  /**
   * this is the full range that the outline covers
   *
   * @generated from field: aiserver.v1.LineRange full_range = 3;
   */
  fullRange?: LineRange;

  constructor(data?: PartialMessage<ContextItem_OutlineChunk>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextItem.OutlineChunk";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "contents", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "full_range", kind: "message", T: LineRange },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextItem_OutlineChunk {
    return new ContextItem_OutlineChunk().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextItem_OutlineChunk {
    return new ContextItem_OutlineChunk().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextItem_OutlineChunk {
    return new ContextItem_OutlineChunk().fromJsonString(jsonString, options);
  }

  static equals(a: ContextItem_OutlineChunk | PlainMessage<ContextItem_OutlineChunk> | undefined, b: ContextItem_OutlineChunk | PlainMessage<ContextItem_OutlineChunk> | undefined): boolean {
    return proto3.util.equals(ContextItem_OutlineChunk, a, b);
  }
}

/**
 * generates also have a cmd-k selection!
 * for generates, we always add an empty line to generate within
 * so the selection will be whitespace only! but it always is included!
 *
 * @generated from message aiserver.v1.ContextItem.CmdKSelection
 */
export class ContextItem_CmdKSelection extends Message<ContextItem_CmdKSelection> {
  /**
   * we don't need a workspace path because this is always in the given file
   * we just send up the selection plain and simple
   * if this is a generate, the lines here will be empty! (or maybe one empty line?)
   *
   * @generated from field: repeated string lines = 1;
   */
  lines: string[] = [];

  /**
   * the end line number is implied by the number of lines
   *
   * @generated from field: int32 start_line_number = 2;
   */
  startLineNumber = 0;

  constructor(data?: PartialMessage<ContextItem_CmdKSelection>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextItem.CmdKSelection";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "lines", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 2, name: "start_line_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextItem_CmdKSelection {
    return new ContextItem_CmdKSelection().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextItem_CmdKSelection {
    return new ContextItem_CmdKSelection().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextItem_CmdKSelection {
    return new ContextItem_CmdKSelection().fromJsonString(jsonString, options);
  }

  static equals(a: ContextItem_CmdKSelection | PlainMessage<ContextItem_CmdKSelection> | undefined, b: ContextItem_CmdKSelection | PlainMessage<ContextItem_CmdKSelection> | undefined): boolean {
    return proto3.util.equals(ContextItem_CmdKSelection, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextItem.CmdKImmediateContext
 */
export class ContextItem_CmdKImmediateContext extends Message<ContextItem_CmdKImmediateContext> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * it is VERY IMPORTANT that these lines NOT BE SPOOFED
   * they MUST correspond to REAL LINES in the file, always.
   * instead of spoofing, please think of a way not to spoof
   * for example: for generates, we do not spoof to say there is no empty line (which we insert when the user does cmd+k), but rather we include the empty line here, we include the empty line as a deletion in the response, and then we just have a way on the client where we do not show the deleted lines in the diff
   * the reason to be adamant about this is that many other context items will reference line numbers (lints, chunks, etc), and we want to make sure that gpt-4 gets to see a consistent view of the file and the world. otherwise, it will be confused!
   *
   * @generated from field: repeated aiserver.v1.ContextItem.CmdKImmediateContext.Line lines = 2;
   */
  lines: ContextItem_CmdKImmediateContext_Line[] = [];

  /**
   * @generated from field: int32 total_number_of_lines_in_file = 3;
   */
  totalNumberOfLinesInFile = 0;

  constructor(data?: PartialMessage<ContextItem_CmdKImmediateContext>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextItem.CmdKImmediateContext";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "lines", kind: "message", T: ContextItem_CmdKImmediateContext_Line, repeated: true },
    { no: 3, name: "total_number_of_lines_in_file", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextItem_CmdKImmediateContext {
    return new ContextItem_CmdKImmediateContext().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextItem_CmdKImmediateContext {
    return new ContextItem_CmdKImmediateContext().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextItem_CmdKImmediateContext {
    return new ContextItem_CmdKImmediateContext().fromJsonString(jsonString, options);
  }

  static equals(a: ContextItem_CmdKImmediateContext | PlainMessage<ContextItem_CmdKImmediateContext> | undefined, b: ContextItem_CmdKImmediateContext | PlainMessage<ContextItem_CmdKImmediateContext> | undefined): boolean {
    return proto3.util.equals(ContextItem_CmdKImmediateContext, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextItem.CmdKImmediateContext.Line
 */
export class ContextItem_CmdKImmediateContext_Line extends Message<ContextItem_CmdKImmediateContext_Line> {
  /**
   * @generated from field: string line = 1;
   */
  line = "";

  /**
   * @generated from field: int32 line_number = 2;
   */
  lineNumber = 0;

  constructor(data?: PartialMessage<ContextItem_CmdKImmediateContext_Line>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextItem.CmdKImmediateContext.Line";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "line", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "line_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextItem_CmdKImmediateContext_Line {
    return new ContextItem_CmdKImmediateContext_Line().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextItem_CmdKImmediateContext_Line {
    return new ContextItem_CmdKImmediateContext_Line().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextItem_CmdKImmediateContext_Line {
    return new ContextItem_CmdKImmediateContext_Line().fromJsonString(jsonString, options);
  }

  static equals(a: ContextItem_CmdKImmediateContext_Line | PlainMessage<ContextItem_CmdKImmediateContext_Line> | undefined, b: ContextItem_CmdKImmediateContext_Line | PlainMessage<ContextItem_CmdKImmediateContext_Line> | undefined): boolean {
    return proto3.util.equals(ContextItem_CmdKImmediateContext_Line, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextItem.CmdKQuery
 */
export class ContextItem_CmdKQuery extends Message<ContextItem_CmdKQuery> {
  /**
   * @generated from field: string query = 1;
   */
  query = "";

  constructor(data?: PartialMessage<ContextItem_CmdKQuery>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextItem.CmdKQuery";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "query", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextItem_CmdKQuery {
    return new ContextItem_CmdKQuery().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextItem_CmdKQuery {
    return new ContextItem_CmdKQuery().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextItem_CmdKQuery {
    return new ContextItem_CmdKQuery().fromJsonString(jsonString, options);
  }

  static equals(a: ContextItem_CmdKQuery | PlainMessage<ContextItem_CmdKQuery> | undefined, b: ContextItem_CmdKQuery | PlainMessage<ContextItem_CmdKQuery> | undefined): boolean {
    return proto3.util.equals(ContextItem_CmdKQuery, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextItem.CmdKQueryHistory
 */
export class ContextItem_CmdKQueryHistory extends Message<ContextItem_CmdKQueryHistory> {
  /**
   * @generated from field: aiserver.v1.ContextItem.CmdKQuery query = 1;
   */
  query?: ContextItem_CmdKQuery;

  /**
   * @generated from field: aiserver.v1.ContextItem.CmdKImmediateContext immediate_context = 2;
   */
  immediateContext?: ContextItem_CmdKImmediateContext;

  /**
   * @generated from field: aiserver.v1.ContextItem.CmdKSelection selection = 3;
   */
  selection?: ContextItem_CmdKSelection;

  /**
   * @generated from field: aiserver.v1.ContextItem.CmdKQueryHistory query_history = 4;
   */
  queryHistory?: ContextItem_CmdKQueryHistory;

  /**
   * finally, we also include a hash of all context items that were SHOWN to the model in the previous request
   * this is useful for caching! it also makes the model's job easier, by putting past context at the top and only new context at the end
   * things may be confusing for the model if you include any hashes that were not shown to the model, since then the assistant response may look like it just ignored things..
   *
   * @generated from field: repeated string context_item_hashes = 5;
   */
  contextItemHashes: string[] = [];

  constructor(data?: PartialMessage<ContextItem_CmdKQueryHistory>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextItem.CmdKQueryHistory";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "query", kind: "message", T: ContextItem_CmdKQuery },
    { no: 2, name: "immediate_context", kind: "message", T: ContextItem_CmdKImmediateContext },
    { no: 3, name: "selection", kind: "message", T: ContextItem_CmdKSelection },
    { no: 4, name: "query_history", kind: "message", T: ContextItem_CmdKQueryHistory },
    { no: 5, name: "context_item_hashes", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextItem_CmdKQueryHistory {
    return new ContextItem_CmdKQueryHistory().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextItem_CmdKQueryHistory {
    return new ContextItem_CmdKQueryHistory().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextItem_CmdKQueryHistory {
    return new ContextItem_CmdKQueryHistory().fromJsonString(jsonString, options);
  }

  static equals(a: ContextItem_CmdKQueryHistory | PlainMessage<ContextItem_CmdKQueryHistory> | undefined, b: ContextItem_CmdKQueryHistory | PlainMessage<ContextItem_CmdKQueryHistory> | undefined): boolean {
    return proto3.util.equals(ContextItem_CmdKQueryHistory, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextItem.CustomInstructions
 */
export class ContextItem_CustomInstructions extends Message<ContextItem_CustomInstructions> {
  /**
   * @generated from field: string instructions = 1;
   */
  instructions = "";

  constructor(data?: PartialMessage<ContextItem_CustomInstructions>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextItem.CustomInstructions";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "instructions", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextItem_CustomInstructions {
    return new ContextItem_CustomInstructions().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextItem_CustomInstructions {
    return new ContextItem_CustomInstructions().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextItem_CustomInstructions {
    return new ContextItem_CustomInstructions().fromJsonString(jsonString, options);
  }

  static equals(a: ContextItem_CustomInstructions | PlainMessage<ContextItem_CustomInstructions> | undefined, b: ContextItem_CustomInstructions | PlainMessage<ContextItem_CustomInstructions> | undefined): boolean {
    return proto3.util.equals(ContextItem_CustomInstructions, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextItem.GoToDefinitionResult
 */
export class ContextItem_GoToDefinitionResult extends Message<ContextItem_GoToDefinitionResult> {
  /**
   * we specify the position we went to definition on
   *
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * @generated from field: string line = 2;
   */
  line = "";

  /**
   * 1-indexed! ofcourse!
   *
   * @generated from field: int32 line_number = 3;
   */
  lineNumber = 0;

  /**
   * 1-indexed! of course!
   *
   * @generated from field: int32 column_number = 4;
   */
  columnNumber = 0;

  /**
   * we currently represent the result as a file chunk, but may want to do something else at some point
   * e.g. it is possible that we want an outline chunk, for example
   *
   * @generated from field: aiserver.v1.ContextItem.FileChunk definition_chunk = 5;
   */
  definitionChunk?: ContextItem_FileChunk;

  constructor(data?: PartialMessage<ContextItem_GoToDefinitionResult>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextItem.GoToDefinitionResult";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "line", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "line_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 4, name: "column_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 5, name: "definition_chunk", kind: "message", T: ContextItem_FileChunk },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextItem_GoToDefinitionResult {
    return new ContextItem_GoToDefinitionResult().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextItem_GoToDefinitionResult {
    return new ContextItem_GoToDefinitionResult().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextItem_GoToDefinitionResult {
    return new ContextItem_GoToDefinitionResult().fromJsonString(jsonString, options);
  }

  static equals(a: ContextItem_GoToDefinitionResult | PlainMessage<ContextItem_GoToDefinitionResult> | undefined, b: ContextItem_GoToDefinitionResult | PlainMessage<ContextItem_GoToDefinitionResult> | undefined): boolean {
    return proto3.util.equals(ContextItem_GoToDefinitionResult, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextItem.DocumentationChunk
 */
export class ContextItem_DocumentationChunk extends Message<ContextItem_DocumentationChunk> {
  /**
   * @generated from field: string doc_name = 1;
   */
  docName = "";

  /**
   * @generated from field: string page_url = 2;
   */
  pageUrl = "";

  /**
   * @generated from field: string documentation_chunk = 3;
   */
  documentationChunk = "";

  /**
   * docs chunks are currently reranked first separately, getting the score below. the global reranker may or may not take this into account
   * it is possible we want to remove this score and just do the reranking in the global reranker itself. but it feels wasteful to just throw out this score, which we will alway get for free from doing the embedding retrieval!
   *
   * @generated from field: float score = 4;
   */
  score = 0;

  constructor(data?: PartialMessage<ContextItem_DocumentationChunk>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextItem.DocumentationChunk";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "doc_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "page_url", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "documentation_chunk", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "score", kind: "scalar", T: 2 /* ScalarType.FLOAT */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextItem_DocumentationChunk {
    return new ContextItem_DocumentationChunk().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextItem_DocumentationChunk {
    return new ContextItem_DocumentationChunk().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextItem_DocumentationChunk {
    return new ContextItem_DocumentationChunk().fromJsonString(jsonString, options);
  }

  static equals(a: ContextItem_DocumentationChunk | PlainMessage<ContextItem_DocumentationChunk> | undefined, b: ContextItem_DocumentationChunk | PlainMessage<ContextItem_DocumentationChunk> | undefined): boolean {
    return proto3.util.equals(ContextItem_DocumentationChunk, a, b);
  }
}

/**
 * we currently keep many lints in the same context item
 * the reason is that many of them build on each other, and it is probably easier to see all of them together
 * they are also all generally small enough that they don't need to be reranked separately
 * if we ever want to rerank separately, just introduce a new message here, called SingleLint or something like that
 *
 * @generated from message aiserver.v1.ContextItem.Lints
 */
export class ContextItem_Lints extends Message<ContextItem_Lints> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * @generated from field: repeated aiserver.v1.Lint lints = 2;
   */
  lints: Lint[] = [];

  /**
   * the context lines will potentially contain a few lines above/below the affected ranges
   *
   * @generated from field: repeated aiserver.v1.ContextItem.Lints.Line context_lines = 3;
   */
  contextLines: ContextItem_Lints_Line[] = [];

  constructor(data?: PartialMessage<ContextItem_Lints>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextItem.Lints";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "lints", kind: "message", T: Lint, repeated: true },
    { no: 3, name: "context_lines", kind: "message", T: ContextItem_Lints_Line, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextItem_Lints {
    return new ContextItem_Lints().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextItem_Lints {
    return new ContextItem_Lints().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextItem_Lints {
    return new ContextItem_Lints().fromJsonString(jsonString, options);
  }

  static equals(a: ContextItem_Lints | PlainMessage<ContextItem_Lints> | undefined, b: ContextItem_Lints | PlainMessage<ContextItem_Lints> | undefined): boolean {
    return proto3.util.equals(ContextItem_Lints, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextItem.Lints.Line
 */
export class ContextItem_Lints_Line extends Message<ContextItem_Lints_Line> {
  /**
   * @generated from field: string line = 1;
   */
  line = "";

  /**
   * @generated from field: int32 line_number = 2;
   */
  lineNumber = 0;

  constructor(data?: PartialMessage<ContextItem_Lints_Line>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextItem.Lints.Line";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "line", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "line_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextItem_Lints_Line {
    return new ContextItem_Lints_Line().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextItem_Lints_Line {
    return new ContextItem_Lints_Line().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextItem_Lints_Line {
    return new ContextItem_Lints_Line().fromJsonString(jsonString, options);
  }

  static equals(a: ContextItem_Lints_Line | PlainMessage<ContextItem_Lints_Line> | undefined, b: ContextItem_Lints_Line | PlainMessage<ContextItem_Lints_Line> | undefined): boolean {
    return proto3.util.equals(ContextItem_Lints_Line, a, b);
  }
}

/**
 * hmm why should the context intent be a proto type?
 * does the server ever need the context intent?
 * oh yeah it needs to know the context intent for each context item i think
 *
 * @generated from message aiserver.v1.ContextIntent
 */
export class ContextIntent extends Message<ContextIntent> {
  /**
   * the type decides how highly the context is prioritized
   * for example, user added context is always added above the automatic context
   *
   * @generated from field: aiserver.v1.ContextIntent.Type type = 1;
   */
  type = ContextIntent_Type.UNSPECIFIED;

  /**
   * @generated from oneof aiserver.v1.ContextIntent.intent
   */
  intent: {
    /**
     * when everything is done with just these two, we should write context handlers for everything else, which should hopefully be essentially instant!
     * i would suggest going for Documentation after this, because documentation is pretty interesting in terms of doing a lot of queries, etc.
     *
     * @generated from field: aiserver.v1.ContextIntent.File file = 2;
     */
    value: ContextIntent_File;
    case: "file";
  } | {
    /**
     * @generated from field: aiserver.v1.ContextIntent.CodeSelection code_selection = 3;
     */
    value: ContextIntent_CodeSelection;
    case: "codeSelection";
  } | {
    /**
     * Symbol symbol = 4;
     *
     * @generated from field: aiserver.v1.ContextIntent.Lints lints = 5;
     */
    value: ContextIntent_Lints;
    case: "lints";
  } | {
    /**
     * CodebaseChunks codebase_chunks = 7;
     *
     * @generated from field: aiserver.v1.ContextIntent.RecentLocations recent_locations = 6;
     */
    value: ContextIntent_RecentLocations;
    case: "recentLocations";
  } | {
    /**
     * these two intents are always included when we are using cmd-k! maybe not even necessary to be an intent? idk it simplifies things
     * it is possible that we want to merge these two intents. but for now it feels easier to keep them separate
     *
     * @generated from field: aiserver.v1.ContextIntent.CmdKCurrentFile cmd_k_current_file = 8;
     */
    value: ContextIntent_CmdKCurrentFile;
    case: "cmdKCurrentFile";
  } | {
    /**
     * @generated from field: aiserver.v1.ContextIntent.CmdKQueryEtc cmd_k_query_etc = 9;
     */
    value: ContextIntent_CmdKQueryEtc;
    case: "cmdKQueryEtc";
  } | {
    /**
     * @generated from field: aiserver.v1.ContextIntent.CmdKDefinitions cmd_k_definitions = 10;
     */
    value: ContextIntent_CmdKDefinitions;
    case: "cmdKDefinitions";
  } | {
    /**
     * @generated from field: aiserver.v1.ContextIntent.Documentation documentation = 11;
     */
    value: ContextIntent_Documentation;
    case: "documentation";
  } | {
    /**
     * @generated from field: aiserver.v1.ContextIntent.CustomInstructions custom_instructions = 12;
     */
    value: ContextIntent_CustomInstructions;
    case: "customInstructions";
  } | { case: undefined; value?: undefined } = { case: undefined };

  constructor(data?: PartialMessage<ContextIntent>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextIntent";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "type", kind: "enum", T: proto3.getEnumType(ContextIntent_Type) },
    { no: 2, name: "file", kind: "message", T: ContextIntent_File, oneof: "intent" },
    { no: 3, name: "code_selection", kind: "message", T: ContextIntent_CodeSelection, oneof: "intent" },
    { no: 5, name: "lints", kind: "message", T: ContextIntent_Lints, oneof: "intent" },
    { no: 6, name: "recent_locations", kind: "message", T: ContextIntent_RecentLocations, oneof: "intent" },
    { no: 8, name: "cmd_k_current_file", kind: "message", T: ContextIntent_CmdKCurrentFile, oneof: "intent" },
    { no: 9, name: "cmd_k_query_etc", kind: "message", T: ContextIntent_CmdKQueryEtc, oneof: "intent" },
    { no: 10, name: "cmd_k_definitions", kind: "message", T: ContextIntent_CmdKDefinitions, oneof: "intent" },
    { no: 11, name: "documentation", kind: "message", T: ContextIntent_Documentation, oneof: "intent" },
    { no: 12, name: "custom_instructions", kind: "message", T: ContextIntent_CustomInstructions, oneof: "intent" },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextIntent {
    return new ContextIntent().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextIntent {
    return new ContextIntent().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextIntent {
    return new ContextIntent().fromJsonString(jsonString, options);
  }

  static equals(a: ContextIntent | PlainMessage<ContextIntent> | undefined, b: ContextIntent | PlainMessage<ContextIntent> | undefined): boolean {
    return proto3.util.equals(ContextIntent, a, b);
  }
}

/**
 * @generated from enum aiserver.v1.ContextIntent.Type
 */
export enum ContextIntent_Type {
  /**
   * @generated from enum value: TYPE_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: TYPE_USER_ADDED = 1;
   */
  USER_ADDED = 1,

  /**
   * it is possible that we want to add more types here...
   *
   * @generated from enum value: TYPE_AUTOMATIC = 2;
   */
  AUTOMATIC = 2,
}
// Retrieve enum metadata with: proto3.getEnumType(ContextIntent_Type)
proto3.util.setEnumType(ContextIntent_Type, "aiserver.v1.ContextIntent.Type", [
  { no: 0, name: "TYPE_UNSPECIFIED" },
  { no: 1, name: "TYPE_USER_ADDED" },
  { no: 2, name: "TYPE_AUTOMATIC" },
]);

/**
 * @generated from message aiserver.v1.ContextIntent.Documentation
 */
export class ContextIntent_Documentation extends Message<ContextIntent_Documentation> {
  /**
   * @generated from field: string documentation_identifier = 1;
   */
  documentationIdentifier = "";

  constructor(data?: PartialMessage<ContextIntent_Documentation>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextIntent.Documentation";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "documentation_identifier", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextIntent_Documentation {
    return new ContextIntent_Documentation().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextIntent_Documentation {
    return new ContextIntent_Documentation().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextIntent_Documentation {
    return new ContextIntent_Documentation().fromJsonString(jsonString, options);
  }

  static equals(a: ContextIntent_Documentation | PlainMessage<ContextIntent_Documentation> | undefined, b: ContextIntent_Documentation | PlainMessage<ContextIntent_Documentation> | undefined): boolean {
    return proto3.util.equals(ContextIntent_Documentation, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextIntent.File
 */
export class ContextIntent_File extends Message<ContextIntent_File> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * @generated from field: aiserver.v1.ContextIntent.File.Mode mode = 2;
   */
  mode = ContextIntent_File_Mode.UNSPECIFIED;

  constructor(data?: PartialMessage<ContextIntent_File>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextIntent.File";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "mode", kind: "enum", T: proto3.getEnumType(ContextIntent_File_Mode) },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextIntent_File {
    return new ContextIntent_File().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextIntent_File {
    return new ContextIntent_File().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextIntent_File {
    return new ContextIntent_File().fromJsonString(jsonString, options);
  }

  static equals(a: ContextIntent_File | PlainMessage<ContextIntent_File> | undefined, b: ContextIntent_File | PlainMessage<ContextIntent_File> | undefined): boolean {
    return proto3.util.equals(ContextIntent_File, a, b);
  }
}

/**
 * @generated from enum aiserver.v1.ContextIntent.File.Mode
 */
export enum ContextIntent_File_Mode {
  /**
   * in UNSPECIFIED mode, we predict the correct mode heuristically
   *
   * @generated from enum value: MODE_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: MODE_FULL = 1;
   */
  FULL = 1,

  /**
   * ARVIDTODO: also add in semantic chunks here
   * for now though, i think it is possible that the full and outline modes are enough though!
   * MODE_SEMANTIC_CHUNKS = 3;
   *
   * @generated from enum value: MODE_OUTLINE = 2;
   */
  OUTLINE = 2,
}
// Retrieve enum metadata with: proto3.getEnumType(ContextIntent_File_Mode)
proto3.util.setEnumType(ContextIntent_File_Mode, "aiserver.v1.ContextIntent.File.Mode", [
  { no: 0, name: "MODE_UNSPECIFIED" },
  { no: 1, name: "MODE_FULL" },
  { no: 2, name: "MODE_OUTLINE" },
]);

/**
 * ARVIDTODO: how to deal with the code selections? they are special because often they are "part of the prompt" and not explicitly referred to with an @ symbol. the user just kind of assumes that there is knowledge of it
 * maybe we always insert @ symbols for each code selection? that would solve this problem, i think
 *
 * @generated from message aiserver.v1.ContextIntent.CodeSelection
 */
export class ContextIntent_CodeSelection extends Message<ContextIntent_CodeSelection> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * the range is not the source of truth. the selection is just a hint for allowing users to go to the right place
   *
   * @generated from field: aiserver.v1.SimpleRange potentially_out_of_date_range = 2;
   */
  potentiallyOutOfDateRange?: SimpleRange;

  /**
   * the text is the source of truth
   * it may contain \r\n or \n depending on the source
   * this becomes kind of redundant with the context item...
   *
   * @generated from field: string text = 3;
   */
  text = "";

  constructor(data?: PartialMessage<ContextIntent_CodeSelection>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextIntent.CodeSelection";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "potentially_out_of_date_range", kind: "message", T: SimpleRange },
    { no: 3, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextIntent_CodeSelection {
    return new ContextIntent_CodeSelection().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextIntent_CodeSelection {
    return new ContextIntent_CodeSelection().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextIntent_CodeSelection {
    return new ContextIntent_CodeSelection().fromJsonString(jsonString, options);
  }

  static equals(a: ContextIntent_CodeSelection | PlainMessage<ContextIntent_CodeSelection> | undefined, b: ContextIntent_CodeSelection | PlainMessage<ContextIntent_CodeSelection> | undefined): boolean {
    return proto3.util.equals(ContextIntent_CodeSelection, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextIntent.Symbol
 */
export class ContextIntent_Symbol extends Message<ContextIntent_Symbol> {
  /**
   * @generated from field: aiserver.v1.DocumentSymbol symbol = 1;
   */
  symbol?: DocumentSymbol;

  /**
   * @generated from field: string relative_workspace_path = 2;
   */
  relativeWorkspacePath = "";

  constructor(data?: PartialMessage<ContextIntent_Symbol>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextIntent.Symbol";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "symbol", kind: "message", T: DocumentSymbol },
    { no: 2, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextIntent_Symbol {
    return new ContextIntent_Symbol().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextIntent_Symbol {
    return new ContextIntent_Symbol().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextIntent_Symbol {
    return new ContextIntent_Symbol().fromJsonString(jsonString, options);
  }

  static equals(a: ContextIntent_Symbol | PlainMessage<ContextIntent_Symbol> | undefined, b: ContextIntent_Symbol | PlainMessage<ContextIntent_Symbol> | undefined): boolean {
    return proto3.util.equals(ContextIntent_Symbol, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextIntent.Lints
 */
export class ContextIntent_Lints extends Message<ContextIntent_Lints> {
  /**
   * @generated from oneof aiserver.v1.ContextIntent.Lints.scope
   */
  scope: {
    /**
     * @generated from field: aiserver.v1.ContextIntent.Lints.CmdKScope cmdk_scope = 1;
     */
    value: ContextIntent_Lints_CmdKScope;
    case: "cmdkScope";
  } | {
    /**
     * it is possible we want to add project-wide lints too! but maybe they should go in their own intent?
     *
     * @generated from field: aiserver.v1.ContextIntent.Lints.FileScope file_scope = 2;
     */
    value: ContextIntent_Lints_FileScope;
    case: "fileScope";
  } | { case: undefined; value?: undefined } = { case: undefined };

  /**
   * if this is empty, we allow all severities
   * otherwise, we restrict to only the given severities
   *
   * @generated from field: repeated aiserver.v1.LintSeverity filter_to_severities = 3;
   */
  filterToSeverities: LintSeverity[] = [];

  constructor(data?: PartialMessage<ContextIntent_Lints>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextIntent.Lints";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "cmdk_scope", kind: "message", T: ContextIntent_Lints_CmdKScope, oneof: "scope" },
    { no: 2, name: "file_scope", kind: "message", T: ContextIntent_Lints_FileScope, oneof: "scope" },
    { no: 3, name: "filter_to_severities", kind: "enum", T: proto3.getEnumType(LintSeverity), repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextIntent_Lints {
    return new ContextIntent_Lints().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextIntent_Lints {
    return new ContextIntent_Lints().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextIntent_Lints {
    return new ContextIntent_Lints().fromJsonString(jsonString, options);
  }

  static equals(a: ContextIntent_Lints | PlainMessage<ContextIntent_Lints> | undefined, b: ContextIntent_Lints | PlainMessage<ContextIntent_Lints> | undefined): boolean {
    return proto3.util.equals(ContextIntent_Lints, a, b);
  }
}

/**
 * we use the current file and the given range.
 * in the future, we may want to add an option here for a "plus-minus" on the range, or the ability to use all linter errors in the entire file
 *
 * @generated from message aiserver.v1.ContextIntent.Lints.CmdKScope
 */
export class ContextIntent_Lints_CmdKScope extends Message<ContextIntent_Lints_CmdKScope> {
  constructor(data?: PartialMessage<ContextIntent_Lints_CmdKScope>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextIntent.Lints.CmdKScope";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextIntent_Lints_CmdKScope {
    return new ContextIntent_Lints_CmdKScope().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextIntent_Lints_CmdKScope {
    return new ContextIntent_Lints_CmdKScope().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextIntent_Lints_CmdKScope {
    return new ContextIntent_Lints_CmdKScope().fromJsonString(jsonString, options);
  }

  static equals(a: ContextIntent_Lints_CmdKScope | PlainMessage<ContextIntent_Lints_CmdKScope> | undefined, b: ContextIntent_Lints_CmdKScope | PlainMessage<ContextIntent_Lints_CmdKScope> | undefined): boolean {
    return proto3.util.equals(ContextIntent_Lints_CmdKScope, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextIntent.Lints.FileScope
 */
export class ContextIntent_Lints_FileScope extends Message<ContextIntent_Lints_FileScope> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * optionally, linter errors can be filtered by selection
   *
   * @generated from field: optional aiserver.v1.LineRange filter_range = 2;
   */
  filterRange?: LineRange;

  constructor(data?: PartialMessage<ContextIntent_Lints_FileScope>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextIntent.Lints.FileScope";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "filter_range", kind: "message", T: LineRange, opt: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextIntent_Lints_FileScope {
    return new ContextIntent_Lints_FileScope().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextIntent_Lints_FileScope {
    return new ContextIntent_Lints_FileScope().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextIntent_Lints_FileScope {
    return new ContextIntent_Lints_FileScope().fromJsonString(jsonString, options);
  }

  static equals(a: ContextIntent_Lints_FileScope | PlainMessage<ContextIntent_Lints_FileScope> | undefined, b: ContextIntent_Lints_FileScope | PlainMessage<ContextIntent_Lints_FileScope> | undefined): boolean {
    return proto3.util.equals(ContextIntent_Lints_FileScope, a, b);
  }
}

/**
 * this is intentionally empty! not really any options here
 * potentially, if we add this in manually, we may want to limit or filter here
 *
 * @generated from message aiserver.v1.ContextIntent.RecentLocations
 */
export class ContextIntent_RecentLocations extends Message<ContextIntent_RecentLocations> {
  constructor(data?: PartialMessage<ContextIntent_RecentLocations>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextIntent.RecentLocations";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextIntent_RecentLocations {
    return new ContextIntent_RecentLocations().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextIntent_RecentLocations {
    return new ContextIntent_RecentLocations().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextIntent_RecentLocations {
    return new ContextIntent_RecentLocations().fromJsonString(jsonString, options);
  }

  static equals(a: ContextIntent_RecentLocations | PlainMessage<ContextIntent_RecentLocations> | undefined, b: ContextIntent_RecentLocations | PlainMessage<ContextIntent_RecentLocations> | undefined): boolean {
    return proto3.util.equals(ContextIntent_RecentLocations, a, b);
  }
}

/**
 * we currently don't have any options here
 * it is possible that we want to add in the advanced context building options here!
 *
 * @generated from message aiserver.v1.ContextIntent.CodebaseChunks
 */
export class ContextIntent_CodebaseChunks extends Message<ContextIntent_CodebaseChunks> {
  constructor(data?: PartialMessage<ContextIntent_CodebaseChunks>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextIntent.CodebaseChunks";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextIntent_CodebaseChunks {
    return new ContextIntent_CodebaseChunks().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextIntent_CodebaseChunks {
    return new ContextIntent_CodebaseChunks().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextIntent_CodebaseChunks {
    return new ContextIntent_CodebaseChunks().fromJsonString(jsonString, options);
  }

  static equals(a: ContextIntent_CodebaseChunks | PlainMessage<ContextIntent_CodebaseChunks> | undefined, b: ContextIntent_CodebaseChunks | PlainMessage<ContextIntent_CodebaseChunks> | undefined): boolean {
    return proto3.util.equals(ContextIntent_CodebaseChunks, a, b);
  }
}

/**
 * not really any options here either
 * this one is always required to be included? maybe there's some option for only restricted to the really needed part
 *
 * @generated from message aiserver.v1.ContextIntent.CmdKCurrentFile
 */
export class ContextIntent_CmdKCurrentFile extends Message<ContextIntent_CmdKCurrentFile> {
  constructor(data?: PartialMessage<ContextIntent_CmdKCurrentFile>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextIntent.CmdKCurrentFile";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextIntent_CmdKCurrentFile {
    return new ContextIntent_CmdKCurrentFile().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextIntent_CmdKCurrentFile {
    return new ContextIntent_CmdKCurrentFile().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextIntent_CmdKCurrentFile {
    return new ContextIntent_CmdKCurrentFile().fromJsonString(jsonString, options);
  }

  static equals(a: ContextIntent_CmdKCurrentFile | PlainMessage<ContextIntent_CmdKCurrentFile> | undefined, b: ContextIntent_CmdKCurrentFile | PlainMessage<ContextIntent_CmdKCurrentFile> | undefined): boolean {
    return proto3.util.equals(ContextIntent_CmdKCurrentFile, a, b);
  }
}

/**
 * always included! includes both the query and the history
 *
 * @generated from message aiserver.v1.ContextIntent.CmdKQueryEtc
 */
export class ContextIntent_CmdKQueryEtc extends Message<ContextIntent_CmdKQueryEtc> {
  constructor(data?: PartialMessage<ContextIntent_CmdKQueryEtc>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextIntent.CmdKQueryEtc";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextIntent_CmdKQueryEtc {
    return new ContextIntent_CmdKQueryEtc().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextIntent_CmdKQueryEtc {
    return new ContextIntent_CmdKQueryEtc().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextIntent_CmdKQueryEtc {
    return new ContextIntent_CmdKQueryEtc().fromJsonString(jsonString, options);
  }

  static equals(a: ContextIntent_CmdKQueryEtc | PlainMessage<ContextIntent_CmdKQueryEtc> | undefined, b: ContextIntent_CmdKQueryEtc | PlainMessage<ContextIntent_CmdKQueryEtc> | undefined): boolean {
    return proto3.util.equals(ContextIntent_CmdKQueryEtc, a, b);
  }
}

/**
 * currently this only works for the global custom instructions (also known as explicit context)
 * it is possible that this should work with e.g. README.ai.md files too!
 *
 * @generated from message aiserver.v1.ContextIntent.CustomInstructions
 */
export class ContextIntent_CustomInstructions extends Message<ContextIntent_CustomInstructions> {
  constructor(data?: PartialMessage<ContextIntent_CustomInstructions>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextIntent.CustomInstructions";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextIntent_CustomInstructions {
    return new ContextIntent_CustomInstructions().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextIntent_CustomInstructions {
    return new ContextIntent_CustomInstructions().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextIntent_CustomInstructions {
    return new ContextIntent_CustomInstructions().fromJsonString(jsonString, options);
  }

  static equals(a: ContextIntent_CustomInstructions | PlainMessage<ContextIntent_CustomInstructions> | undefined, b: ContextIntent_CustomInstructions | PlainMessage<ContextIntent_CustomInstructions> | undefined): boolean {
    return proto3.util.equals(ContextIntent_CustomInstructions, a, b);
  }
}

/**
 * if we bring it in manually, perhaps we want to give people the option of specifying how many types to include and whether to recurse or not?
 *
 * @generated from message aiserver.v1.ContextIntent.CmdKDefinitions
 */
export class ContextIntent_CmdKDefinitions extends Message<ContextIntent_CmdKDefinitions> {
  constructor(data?: PartialMessage<ContextIntent_CmdKDefinitions>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextIntent.CmdKDefinitions";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextIntent_CmdKDefinitions {
    return new ContextIntent_CmdKDefinitions().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextIntent_CmdKDefinitions {
    return new ContextIntent_CmdKDefinitions().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextIntent_CmdKDefinitions {
    return new ContextIntent_CmdKDefinitions().fromJsonString(jsonString, options);
  }

  static equals(a: ContextIntent_CmdKDefinitions | PlainMessage<ContextIntent_CmdKDefinitions> | undefined, b: ContextIntent_CmdKDefinitions | PlainMessage<ContextIntent_CmdKDefinitions> | undefined): boolean {
    return proto3.util.equals(ContextIntent_CmdKDefinitions, a, b);
  }
}

