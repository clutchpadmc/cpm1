// @generated by protoc-gen-es v1.2.1 with parameter "target=ts"
// @generated from file aiserver/v1/aiserver.proto (package aiserver.v1, syntax proto3)
/* eslint-disable */
// @ts-nocheck

import type { BinaryReadOptions, FieldList, JsonReadOptions, JsonValue, PartialMessage, PlainMessage } from "@bufbuild/protobuf";
import { Message, proto3 } from "@bufbuild/protobuf";
import { CodeBlock, CurrentFileInfo, CursorPosition, CursorRange, DataframeInfo, ExplicitContext, FeatureType, LineRange, LinterErrors, ModelDetails, SimpleRange } from './utils_pb';
import { CodeResult, FileResult, RepositoryInfo, RerankerAlgorithm, SearchRepositoryDeepContextResponse } from './repository_pb';
import { DocumentationChunk, DocumentationMetadata } from './docs_pb';
import { AiLintBug, AiLintRule, LintDiscriminator, LintGenerator } from './lint_pb';
import { ToolCall, ToolResult } from './tools_pb';
import { InterfaceAgentClientState, InterfaceAgentStatus } from './interface_agent_pb';

/**
 * @generated from enum aiserver.v1.ChunkType
 */
export enum ChunkType {
  /**
   * @generated from enum value: CHUNK_TYPE_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: CHUNK_TYPE_CODEBASE = 1;
   */
  CODEBASE = 1,

  /**
   * @generated from enum value: CHUNK_TYPE_LONG_FILE = 2;
   */
  LONG_FILE = 2,

  /**
   * @generated from enum value: CHUNK_TYPE_DOCS = 3;
   */
  DOCS = 3,
}
// Retrieve enum metadata with: proto3.getEnumType(ChunkType)
proto3.util.setEnumType(ChunkType, "aiserver.v1.ChunkType", [
  { no: 0, name: "CHUNK_TYPE_UNSPECIFIED" },
  { no: 1, name: "CHUNK_TYPE_CODEBASE" },
  { no: 2, name: "CHUNK_TYPE_LONG_FILE" },
  { no: 3, name: "CHUNK_TYPE_DOCS" },
]);

/**
 * @generated from enum aiserver.v1.TaskStatus
 */
export enum TaskStatus {
  /**
   * @generated from enum value: TASK_STATUS_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: TASK_STATUS_RUNNING = 1;
   */
  RUNNING = 1,

  /**
   * @generated from enum value: TASK_STATUS_PAUSED = 2;
   */
  PAUSED = 2,

  /**
   * @generated from enum value: TASK_STATUS_DONE = 3;
   */
  DONE = 3,

  /**
   * @generated from enum value: TASK_STATUS_NOT_STARTED = 4;
   */
  NOT_STARTED = 4,
}
// Retrieve enum metadata with: proto3.getEnumType(TaskStatus)
proto3.util.setEnumType(TaskStatus, "aiserver.v1.TaskStatus", [
  { no: 0, name: "TASK_STATUS_UNSPECIFIED" },
  { no: 1, name: "TASK_STATUS_RUNNING" },
  { no: 2, name: "TASK_STATUS_PAUSED" },
  { no: 3, name: "TASK_STATUS_DONE" },
  { no: 4, name: "TASK_STATUS_NOT_STARTED" },
]);

/**
 * @generated from message aiserver.v1.AiProjectRequest
 */
export class AiProjectRequest extends Message<AiProjectRequest> {
  /**
   * @generated from field: string description = 1;
   */
  description = "";

  /**
   * @generated from field: aiserver.v1.ModelDetails model_details = 2;
   */
  modelDetails?: ModelDetails;

  constructor(data?: PartialMessage<AiProjectRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.AiProjectRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "description", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "model_details", kind: "message", T: ModelDetails },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): AiProjectRequest {
    return new AiProjectRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): AiProjectRequest {
    return new AiProjectRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): AiProjectRequest {
    return new AiProjectRequest().fromJsonString(jsonString, options);
  }

  static equals(a: AiProjectRequest | PlainMessage<AiProjectRequest> | undefined, b: AiProjectRequest | PlainMessage<AiProjectRequest> | undefined): boolean {
    return proto3.util.equals(AiProjectRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.AiProjectResponse
 */
export class AiProjectResponse extends Message<AiProjectResponse> {
  /**
   * @generated from field: string text = 1;
   */
  text = "";

  constructor(data?: PartialMessage<AiProjectResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.AiProjectResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): AiProjectResponse {
    return new AiProjectResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): AiProjectResponse {
    return new AiProjectResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): AiProjectResponse {
    return new AiProjectResponse().fromJsonString(jsonString, options);
  }

  static equals(a: AiProjectResponse | PlainMessage<AiProjectResponse> | undefined, b: AiProjectResponse | PlainMessage<AiProjectResponse> | undefined): boolean {
    return proto3.util.equals(AiProjectResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ToCamelCaseRequest
 */
export class ToCamelCaseRequest extends Message<ToCamelCaseRequest> {
  /**
   * @generated from field: string text = 1;
   */
  text = "";

  constructor(data?: PartialMessage<ToCamelCaseRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ToCamelCaseRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ToCamelCaseRequest {
    return new ToCamelCaseRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ToCamelCaseRequest {
    return new ToCamelCaseRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ToCamelCaseRequest {
    return new ToCamelCaseRequest().fromJsonString(jsonString, options);
  }

  static equals(a: ToCamelCaseRequest | PlainMessage<ToCamelCaseRequest> | undefined, b: ToCamelCaseRequest | PlainMessage<ToCamelCaseRequest> | undefined): boolean {
    return proto3.util.equals(ToCamelCaseRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ToCamelCaseResponse
 */
export class ToCamelCaseResponse extends Message<ToCamelCaseResponse> {
  /**
   * @generated from field: string text = 1;
   */
  text = "";

  constructor(data?: PartialMessage<ToCamelCaseResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ToCamelCaseResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ToCamelCaseResponse {
    return new ToCamelCaseResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ToCamelCaseResponse {
    return new ToCamelCaseResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ToCamelCaseResponse {
    return new ToCamelCaseResponse().fromJsonString(jsonString, options);
  }

  static equals(a: ToCamelCaseResponse | PlainMessage<ToCamelCaseResponse> | undefined, b: ToCamelCaseResponse | PlainMessage<ToCamelCaseResponse> | undefined): boolean {
    return proto3.util.equals(ToCamelCaseResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamPriomptPromptRequest
 */
export class StreamPriomptPromptRequest extends Message<StreamPriomptPromptRequest> {
  /**
   * @generated from field: string prompt_props = 2;
   */
  promptProps = "";

  /**
   * @generated from field: string prompt_props_type_name = 3;
   */
  promptPropsTypeName = "";

  /**
   * @generated from field: bool skip_login_check = 5;
   */
  skipLoginCheck = false;

  /**
   * @generated from field: aiserver.v1.ModelDetails model_details = 4;
   */
  modelDetails?: ModelDetails;

  constructor(data?: PartialMessage<StreamPriomptPromptRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamPriomptPromptRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 2, name: "prompt_props", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "prompt_props_type_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 5, name: "skip_login_check", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 4, name: "model_details", kind: "message", T: ModelDetails },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamPriomptPromptRequest {
    return new StreamPriomptPromptRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamPriomptPromptRequest {
    return new StreamPriomptPromptRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamPriomptPromptRequest {
    return new StreamPriomptPromptRequest().fromJsonString(jsonString, options);
  }

  static equals(a: StreamPriomptPromptRequest | PlainMessage<StreamPriomptPromptRequest> | undefined, b: StreamPriomptPromptRequest | PlainMessage<StreamPriomptPromptRequest> | undefined): boolean {
    return proto3.util.equals(StreamPriomptPromptRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamPriomptPromptResponse
 */
export class StreamPriomptPromptResponse extends Message<StreamPriomptPromptResponse> {
  /**
   * @generated from field: string text = 1;
   */
  text = "";

  constructor(data?: PartialMessage<StreamPriomptPromptResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamPriomptPromptResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamPriomptPromptResponse {
    return new StreamPriomptPromptResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamPriomptPromptResponse {
    return new StreamPriomptPromptResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamPriomptPromptResponse {
    return new StreamPriomptPromptResponse().fromJsonString(jsonString, options);
  }

  static equals(a: StreamPriomptPromptResponse | PlainMessage<StreamPriomptPromptResponse> | undefined, b: StreamPriomptPromptResponse | PlainMessage<StreamPriomptPromptResponse> | undefined): boolean {
    return proto3.util.equals(StreamPriomptPromptResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.IntentPredictionRequest
 */
export class IntentPredictionRequest extends Message<IntentPredictionRequest> {
  /**
   * @generated from field: repeated aiserver.v1.ConversationMessage messages = 1;
   */
  messages: ConversationMessage[] = [];

  /**
   * @generated from field: aiserver.v1.ContextOptions context_options = 2;
   */
  contextOptions?: ContextOptions;

  /**
   * @generated from field: aiserver.v1.ModelDetails model_details = 3;
   */
  modelDetails?: ModelDetails;

  constructor(data?: PartialMessage<IntentPredictionRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.IntentPredictionRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "messages", kind: "message", T: ConversationMessage, repeated: true },
    { no: 2, name: "context_options", kind: "message", T: ContextOptions },
    { no: 3, name: "model_details", kind: "message", T: ModelDetails },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): IntentPredictionRequest {
    return new IntentPredictionRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): IntentPredictionRequest {
    return new IntentPredictionRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): IntentPredictionRequest {
    return new IntentPredictionRequest().fromJsonString(jsonString, options);
  }

  static equals(a: IntentPredictionRequest | PlainMessage<IntentPredictionRequest> | undefined, b: IntentPredictionRequest | PlainMessage<IntentPredictionRequest> | undefined): boolean {
    return proto3.util.equals(IntentPredictionRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.IntentPredictionResponse
 */
export class IntentPredictionResponse extends Message<IntentPredictionResponse> {
  /**
   * @generated from field: aiserver.v1.IntentPredictionResponse.ChosenDocumentation chosen_documentation = 1;
   */
  chosenDocumentation?: IntentPredictionResponse_ChosenDocumentation;

  /**
   * @generated from field: aiserver.v1.IntentPredictionResponse.ChosenFileContents chosen_file_contents = 2;
   */
  chosenFileContents?: IntentPredictionResponse_ChosenFileContents;

  /**
   * @generated from field: aiserver.v1.IntentPredictionResponse.ChosenLinterDiagnostics chosen_linter_diagnostics = 3;
   */
  chosenLinterDiagnostics?: IntentPredictionResponse_ChosenLinterDiagnostics;

  /**
   * @generated from field: bool use_global_context = 4;
   */
  useGlobalContext = false;

  constructor(data?: PartialMessage<IntentPredictionResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.IntentPredictionResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "chosen_documentation", kind: "message", T: IntentPredictionResponse_ChosenDocumentation },
    { no: 2, name: "chosen_file_contents", kind: "message", T: IntentPredictionResponse_ChosenFileContents },
    { no: 3, name: "chosen_linter_diagnostics", kind: "message", T: IntentPredictionResponse_ChosenLinterDiagnostics },
    { no: 4, name: "use_global_context", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): IntentPredictionResponse {
    return new IntentPredictionResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): IntentPredictionResponse {
    return new IntentPredictionResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): IntentPredictionResponse {
    return new IntentPredictionResponse().fromJsonString(jsonString, options);
  }

  static equals(a: IntentPredictionResponse | PlainMessage<IntentPredictionResponse> | undefined, b: IntentPredictionResponse | PlainMessage<IntentPredictionResponse> | undefined): boolean {
    return proto3.util.equals(IntentPredictionResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.IntentPredictionResponse.ChosenDocumentation
 */
export class IntentPredictionResponse_ChosenDocumentation extends Message<IntentPredictionResponse_ChosenDocumentation> {
  /**
   * We deprecate this parameter
   *
   * @generated from field: repeated int32 doc_indices = 1;
   */
  docIndices: number[] = [];

  /**
   * We use this parameter instead
   *
   * @generated from field: repeated string doc_identifiers = 2;
   */
  docIdentifiers: string[] = [];

  /**
   * @generated from field: repeated string doc_names = 3;
   */
  docNames: string[] = [];

  constructor(data?: PartialMessage<IntentPredictionResponse_ChosenDocumentation>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.IntentPredictionResponse.ChosenDocumentation";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "doc_indices", kind: "scalar", T: 5 /* ScalarType.INT32 */, repeated: true },
    { no: 2, name: "doc_identifiers", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 3, name: "doc_names", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): IntentPredictionResponse_ChosenDocumentation {
    return new IntentPredictionResponse_ChosenDocumentation().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): IntentPredictionResponse_ChosenDocumentation {
    return new IntentPredictionResponse_ChosenDocumentation().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): IntentPredictionResponse_ChosenDocumentation {
    return new IntentPredictionResponse_ChosenDocumentation().fromJsonString(jsonString, options);
  }

  static equals(a: IntentPredictionResponse_ChosenDocumentation | PlainMessage<IntentPredictionResponse_ChosenDocumentation> | undefined, b: IntentPredictionResponse_ChosenDocumentation | PlainMessage<IntentPredictionResponse_ChosenDocumentation> | undefined): boolean {
    return proto3.util.equals(IntentPredictionResponse_ChosenDocumentation, a, b);
  }
}

/**
 * For now, just the inclusion of this means
 * we want the file contents
 * bool include_preceding_lines = 1;
 * bool include_selected_lines = 2;
 * bool include_succeeding_lines = 3;
 *
 * @generated from message aiserver.v1.IntentPredictionResponse.ChosenFileContents
 */
export class IntentPredictionResponse_ChosenFileContents extends Message<IntentPredictionResponse_ChosenFileContents> {
  constructor(data?: PartialMessage<IntentPredictionResponse_ChosenFileContents>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.IntentPredictionResponse.ChosenFileContents";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): IntentPredictionResponse_ChosenFileContents {
    return new IntentPredictionResponse_ChosenFileContents().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): IntentPredictionResponse_ChosenFileContents {
    return new IntentPredictionResponse_ChosenFileContents().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): IntentPredictionResponse_ChosenFileContents {
    return new IntentPredictionResponse_ChosenFileContents().fromJsonString(jsonString, options);
  }

  static equals(a: IntentPredictionResponse_ChosenFileContents | PlainMessage<IntentPredictionResponse_ChosenFileContents> | undefined, b: IntentPredictionResponse_ChosenFileContents | PlainMessage<IntentPredictionResponse_ChosenFileContents> | undefined): boolean {
    return proto3.util.equals(IntentPredictionResponse_ChosenFileContents, a, b);
  }
}

/**
 * @generated from message aiserver.v1.IntentPredictionResponse.ChosenLinterDiagnostics
 */
export class IntentPredictionResponse_ChosenLinterDiagnostics extends Message<IntentPredictionResponse_ChosenLinterDiagnostics> {
  /**
   * @generated from field: repeated int32 diagnostic_indices = 1;
   */
  diagnosticIndices: number[] = [];

  constructor(data?: PartialMessage<IntentPredictionResponse_ChosenLinterDiagnostics>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.IntentPredictionResponse.ChosenLinterDiagnostics";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "diagnostic_indices", kind: "scalar", T: 5 /* ScalarType.INT32 */, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): IntentPredictionResponse_ChosenLinterDiagnostics {
    return new IntentPredictionResponse_ChosenLinterDiagnostics().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): IntentPredictionResponse_ChosenLinterDiagnostics {
    return new IntentPredictionResponse_ChosenLinterDiagnostics().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): IntentPredictionResponse_ChosenLinterDiagnostics {
    return new IntentPredictionResponse_ChosenLinterDiagnostics().fromJsonString(jsonString, options);
  }

  static equals(a: IntentPredictionResponse_ChosenLinterDiagnostics | PlainMessage<IntentPredictionResponse_ChosenLinterDiagnostics> | undefined, b: IntentPredictionResponse_ChosenLinterDiagnostics | PlainMessage<IntentPredictionResponse_ChosenLinterDiagnostics> | undefined): boolean {
    return proto3.util.equals(IntentPredictionResponse_ChosenLinterDiagnostics, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextOptions
 */
export class ContextOptions extends Message<ContextOptions> {
  /**
   * @generated from field: aiserver.v1.ContextOptions.AllDocumentation all_documentation = 1;
   */
  allDocumentation?: ContextOptions_AllDocumentation;

  /**
   * @generated from field: aiserver.v1.ContextOptions.CurrentFileContents current_file_contents = 2;
   */
  currentFileContents?: ContextOptions_CurrentFileContents;

  /**
   * @generated from field: aiserver.v1.ContextOptions.LinterDiagnostics linter_diagnostics = 3;
   */
  linterDiagnostics?: ContextOptions_LinterDiagnostics;

  /**
   * ASTSymbols ast_symbols = 5;
   * RecentFiles recent_files = 6;
   *
   * @generated from field: aiserver.v1.ContextOptions.GlobalContext global_context = 4;
   */
  globalContext?: ContextOptions_GlobalContext;

  constructor(data?: PartialMessage<ContextOptions>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextOptions";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "all_documentation", kind: "message", T: ContextOptions_AllDocumentation },
    { no: 2, name: "current_file_contents", kind: "message", T: ContextOptions_CurrentFileContents },
    { no: 3, name: "linter_diagnostics", kind: "message", T: ContextOptions_LinterDiagnostics },
    { no: 4, name: "global_context", kind: "message", T: ContextOptions_GlobalContext },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextOptions {
    return new ContextOptions().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextOptions {
    return new ContextOptions().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextOptions {
    return new ContextOptions().fromJsonString(jsonString, options);
  }

  static equals(a: ContextOptions | PlainMessage<ContextOptions> | undefined, b: ContextOptions | PlainMessage<ContextOptions> | undefined): boolean {
    return proto3.util.equals(ContextOptions, a, b);
  }
}

/**
 * Could be multiple documentation options
 *
 * @generated from message aiserver.v1.ContextOptions.AllDocumentation
 */
export class ContextOptions_AllDocumentation extends Message<ContextOptions_AllDocumentation> {
  /**
   * repeated Documentation whitelisted_docs = 2;
   *
   * @generated from field: repeated aiserver.v1.ContextOptions.AllDocumentation.Documentation available_docs = 1;
   */
  availableDocs: ContextOptions_AllDocumentation_Documentation[] = [];

  constructor(data?: PartialMessage<ContextOptions_AllDocumentation>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextOptions.AllDocumentation";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "available_docs", kind: "message", T: ContextOptions_AllDocumentation_Documentation, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextOptions_AllDocumentation {
    return new ContextOptions_AllDocumentation().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextOptions_AllDocumentation {
    return new ContextOptions_AllDocumentation().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextOptions_AllDocumentation {
    return new ContextOptions_AllDocumentation().fromJsonString(jsonString, options);
  }

  static equals(a: ContextOptions_AllDocumentation | PlainMessage<ContextOptions_AllDocumentation> | undefined, b: ContextOptions_AllDocumentation | PlainMessage<ContextOptions_AllDocumentation> | undefined): boolean {
    return proto3.util.equals(ContextOptions_AllDocumentation, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextOptions.AllDocumentation.Documentation
 */
export class ContextOptions_AllDocumentation_Documentation extends Message<ContextOptions_AllDocumentation_Documentation> {
  /**
   * @generated from field: string name = 1;
   */
  name = "";

  /**
   * @generated from field: string url = 2;
   */
  url = "";

  /**
   * @generated from field: string identifier = 3;
   */
  identifier = "";

  constructor(data?: PartialMessage<ContextOptions_AllDocumentation_Documentation>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextOptions.AllDocumentation.Documentation";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "url", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "identifier", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextOptions_AllDocumentation_Documentation {
    return new ContextOptions_AllDocumentation_Documentation().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextOptions_AllDocumentation_Documentation {
    return new ContextOptions_AllDocumentation_Documentation().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextOptions_AllDocumentation_Documentation {
    return new ContextOptions_AllDocumentation_Documentation().fromJsonString(jsonString, options);
  }

  static equals(a: ContextOptions_AllDocumentation_Documentation | PlainMessage<ContextOptions_AllDocumentation_Documentation> | undefined, b: ContextOptions_AllDocumentation_Documentation | PlainMessage<ContextOptions_AllDocumentation_Documentation> | undefined): boolean {
    return proto3.util.equals(ContextOptions_AllDocumentation_Documentation, a, b);
  }
}

/**
 * Only 1 or none of these
 *
 * @generated from message aiserver.v1.ContextOptions.CurrentFileContents
 */
export class ContextOptions_CurrentFileContents extends Message<ContextOptions_CurrentFileContents> {
  /**
   * the relative path in the current workspace
   *
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * TODO: support both text files and notebook files
   * TODO: maybe we don't need to send up the entire file if we have a file
   * sync server?
   *
   * @generated from field: string contents = 2;
   */
  contents = "";

  /**
   * @generated from field: aiserver.v1.CursorPosition cursor_position = 3;
   */
  cursorPosition?: CursorPosition;

  /**
   * dataframes only exist in notebooks
   *
   * @generated from field: repeated aiserver.v1.DataframeInfo dataframes = 4;
   */
  dataframes: DataframeInfo[] = [];

  /**
   * @generated from field: string language_id = 5;
   */
  languageId = "";

  /**
   * TODO: support multiple selections
   *
   * @generated from field: aiserver.v1.CursorRange selection = 6;
   */
  selection?: CursorRange;

  constructor(data?: PartialMessage<ContextOptions_CurrentFileContents>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextOptions.CurrentFileContents";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "contents", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "cursor_position", kind: "message", T: CursorPosition },
    { no: 4, name: "dataframes", kind: "message", T: DataframeInfo, repeated: true },
    { no: 5, name: "language_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 6, name: "selection", kind: "message", T: CursorRange },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextOptions_CurrentFileContents {
    return new ContextOptions_CurrentFileContents().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextOptions_CurrentFileContents {
    return new ContextOptions_CurrentFileContents().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextOptions_CurrentFileContents {
    return new ContextOptions_CurrentFileContents().fromJsonString(jsonString, options);
  }

  static equals(a: ContextOptions_CurrentFileContents | PlainMessage<ContextOptions_CurrentFileContents> | undefined, b: ContextOptions_CurrentFileContents | PlainMessage<ContextOptions_CurrentFileContents> | undefined): boolean {
    return proto3.util.equals(ContextOptions_CurrentFileContents, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextOptions.LinterDiagnostics
 */
export class ContextOptions_LinterDiagnostics extends Message<ContextOptions_LinterDiagnostics> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * @generated from field: string contents = 2;
   */
  contents = "";

  /**
   * @generated from field: repeated aiserver.v1.ContextOptions.LinterDiagnostics.Diagnostic diagnostics = 3;
   */
  diagnostics: ContextOptions_LinterDiagnostics_Diagnostic[] = [];

  constructor(data?: PartialMessage<ContextOptions_LinterDiagnostics>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextOptions.LinterDiagnostics";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "contents", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "diagnostics", kind: "message", T: ContextOptions_LinterDiagnostics_Diagnostic, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextOptions_LinterDiagnostics {
    return new ContextOptions_LinterDiagnostics().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextOptions_LinterDiagnostics {
    return new ContextOptions_LinterDiagnostics().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextOptions_LinterDiagnostics {
    return new ContextOptions_LinterDiagnostics().fromJsonString(jsonString, options);
  }

  static equals(a: ContextOptions_LinterDiagnostics | PlainMessage<ContextOptions_LinterDiagnostics> | undefined, b: ContextOptions_LinterDiagnostics | PlainMessage<ContextOptions_LinterDiagnostics> | undefined): boolean {
    return proto3.util.equals(ContextOptions_LinterDiagnostics, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextOptions.LinterDiagnostics.Diagnostic
 */
export class ContextOptions_LinterDiagnostics_Diagnostic extends Message<ContextOptions_LinterDiagnostics_Diagnostic> {
  /**
   * @generated from field: string message = 1;
   */
  message = "";

  /**
   * @generated from field: string source = 2;
   */
  source = "";

  /**
   * @generated from field: aiserver.v1.CursorRange range = 3;
   */
  range?: CursorRange;

  constructor(data?: PartialMessage<ContextOptions_LinterDiagnostics_Diagnostic>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextOptions.LinterDiagnostics.Diagnostic";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "message", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "source", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "range", kind: "message", T: CursorRange },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextOptions_LinterDiagnostics_Diagnostic {
    return new ContextOptions_LinterDiagnostics_Diagnostic().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextOptions_LinterDiagnostics_Diagnostic {
    return new ContextOptions_LinterDiagnostics_Diagnostic().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextOptions_LinterDiagnostics_Diagnostic {
    return new ContextOptions_LinterDiagnostics_Diagnostic().fromJsonString(jsonString, options);
  }

  static equals(a: ContextOptions_LinterDiagnostics_Diagnostic | PlainMessage<ContextOptions_LinterDiagnostics_Diagnostic> | undefined, b: ContextOptions_LinterDiagnostics_Diagnostic | PlainMessage<ContextOptions_LinterDiagnostics_Diagnostic> | undefined): boolean {
    return proto3.util.equals(ContextOptions_LinterDiagnostics_Diagnostic, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ContextOptions.GlobalContext
 */
export class ContextOptions_GlobalContext extends Message<ContextOptions_GlobalContext> {
  constructor(data?: PartialMessage<ContextOptions_GlobalContext>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ContextOptions.GlobalContext";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ContextOptions_GlobalContext {
    return new ContextOptions_GlobalContext().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ContextOptions_GlobalContext {
    return new ContextOptions_GlobalContext().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ContextOptions_GlobalContext {
    return new ContextOptions_GlobalContext().fromJsonString(jsonString, options);
  }

  static equals(a: ContextOptions_GlobalContext | PlainMessage<ContextOptions_GlobalContext> | undefined, b: ContextOptions_GlobalContext | PlainMessage<ContextOptions_GlobalContext> | undefined): boolean {
    return proto3.util.equals(ContextOptions_GlobalContext, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamCursorTutorRequest
 */
export class StreamCursorTutorRequest extends Message<StreamCursorTutorRequest> {
  /**
   * @generated from field: repeated aiserver.v1.ConversationMessage conversation = 1;
   */
  conversation: ConversationMessage[] = [];

  /**
   * @generated from field: aiserver.v1.ModelDetails model_details = 2;
   */
  modelDetails?: ModelDetails;

  constructor(data?: PartialMessage<StreamCursorTutorRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamCursorTutorRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "conversation", kind: "message", T: ConversationMessage, repeated: true },
    { no: 2, name: "model_details", kind: "message", T: ModelDetails },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamCursorTutorRequest {
    return new StreamCursorTutorRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamCursorTutorRequest {
    return new StreamCursorTutorRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamCursorTutorRequest {
    return new StreamCursorTutorRequest().fromJsonString(jsonString, options);
  }

  static equals(a: StreamCursorTutorRequest | PlainMessage<StreamCursorTutorRequest> | undefined, b: StreamCursorTutorRequest | PlainMessage<StreamCursorTutorRequest> | undefined): boolean {
    return proto3.util.equals(StreamCursorTutorRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamCursorTutorResponse
 */
export class StreamCursorTutorResponse extends Message<StreamCursorTutorResponse> {
  /**
   * @generated from field: string text = 1;
   */
  text = "";

  constructor(data?: PartialMessage<StreamCursorTutorResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamCursorTutorResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamCursorTutorResponse {
    return new StreamCursorTutorResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamCursorTutorResponse {
    return new StreamCursorTutorResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamCursorTutorResponse {
    return new StreamCursorTutorResponse().fromJsonString(jsonString, options);
  }

  static equals(a: StreamCursorTutorResponse | PlainMessage<StreamCursorTutorResponse> | undefined, b: StreamCursorTutorResponse | PlainMessage<StreamCursorTutorResponse> | undefined): boolean {
    return proto3.util.equals(StreamCursorTutorResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ModelQueryRequest
 */
export class ModelQueryRequest extends Message<ModelQueryRequest> {
  /**
   * We first get the model details for the query (which contains the api key)
   *
   * @generated from field: aiserver.v1.CurrentFileInfo current_file = 1;
   */
  currentFile?: CurrentFileInfo;

  /**
   * the query to be answered is the last human message in the conversation
   *
   * @generated from field: repeated aiserver.v1.ConversationMessage conversation = 2;
   */
  conversation: ConversationMessage[] = [];

  /**
   * @generated from field: repeated aiserver.v1.RepositoryInfo repositories = 3;
   */
  repositories: RepositoryInfo[] = [];

  /**
   * @generated from field: aiserver.v1.ExplicitContext explicit_context = 4;
   */
  explicitContext?: ExplicitContext;

  /**
   * @generated from field: optional string workspace_root_path = 5;
   */
  workspaceRootPath?: string;

  /**
   * Other code blocks to add in
   *
   * @generated from field: repeated aiserver.v1.CodeBlock code_blocks = 6;
   */
  codeBlocks: CodeBlock[] = [];

  /**
   * What model to use and api key to use if applicable
   *
   * @generated from field: aiserver.v1.ModelDetails model_details = 7;
   */
  modelDetails?: ModelDetails;

  /**
   * What type of query is this
   *
   * @generated from field: aiserver.v1.ModelQueryRequest.QueryType query_type = 8;
   */
  queryType = ModelQueryRequest_QueryType.UNSPECIFIED;

  constructor(data?: PartialMessage<ModelQueryRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ModelQueryRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "current_file", kind: "message", T: CurrentFileInfo },
    { no: 2, name: "conversation", kind: "message", T: ConversationMessage, repeated: true },
    { no: 3, name: "repositories", kind: "message", T: RepositoryInfo, repeated: true },
    { no: 4, name: "explicit_context", kind: "message", T: ExplicitContext },
    { no: 5, name: "workspace_root_path", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 6, name: "code_blocks", kind: "message", T: CodeBlock, repeated: true },
    { no: 7, name: "model_details", kind: "message", T: ModelDetails },
    { no: 8, name: "query_type", kind: "enum", T: proto3.getEnumType(ModelQueryRequest_QueryType) },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ModelQueryRequest {
    return new ModelQueryRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ModelQueryRequest {
    return new ModelQueryRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ModelQueryRequest {
    return new ModelQueryRequest().fromJsonString(jsonString, options);
  }

  static equals(a: ModelQueryRequest | PlainMessage<ModelQueryRequest> | undefined, b: ModelQueryRequest | PlainMessage<ModelQueryRequest> | undefined): boolean {
    return proto3.util.equals(ModelQueryRequest, a, b);
  }
}

/**
 * @generated from enum aiserver.v1.ModelQueryRequest.QueryType
 */
export enum ModelQueryRequest_QueryType {
  /**
   * @generated from enum value: QUERY_TYPE_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: QUERY_TYPE_KEYWORDS = 1;
   */
  KEYWORDS = 1,

  /**
   * @generated from enum value: QUERY_TYPE_EMBEDDINGS = 2;
   */
  EMBEDDINGS = 2,
}
// Retrieve enum metadata with: proto3.getEnumType(ModelQueryRequest_QueryType)
proto3.util.setEnumType(ModelQueryRequest_QueryType, "aiserver.v1.ModelQueryRequest.QueryType", [
  { no: 0, name: "QUERY_TYPE_UNSPECIFIED" },
  { no: 1, name: "QUERY_TYPE_KEYWORDS" },
  { no: 2, name: "QUERY_TYPE_EMBEDDINGS" },
]);

/**
 * @generated from message aiserver.v1.ModelQueryResponse
 */
export class ModelQueryResponse extends Message<ModelQueryResponse> {
  /**
   * The query we are answering
   *
   * @generated from field: repeated aiserver.v1.ModelQueryResponse.Query queries = 1;
   */
  queries: ModelQueryResponse_Query[] = [];

  constructor(data?: PartialMessage<ModelQueryResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ModelQueryResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "queries", kind: "message", T: ModelQueryResponse_Query, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ModelQueryResponse {
    return new ModelQueryResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ModelQueryResponse {
    return new ModelQueryResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ModelQueryResponse {
    return new ModelQueryResponse().fromJsonString(jsonString, options);
  }

  static equals(a: ModelQueryResponse | PlainMessage<ModelQueryResponse> | undefined, b: ModelQueryResponse | PlainMessage<ModelQueryResponse> | undefined): boolean {
    return proto3.util.equals(ModelQueryResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ModelQueryResponse.Query
 */
export class ModelQueryResponse_Query extends Message<ModelQueryResponse_Query> {
  /**
   * The actual string query to ask
   *
   * @generated from field: string query = 1;
   */
  query = "";

  /**
   * @generated from field: bool successful_parse = 2;
   */
  successfulParse = false;

  /**
   * Filenames
   *
   * @generated from field: repeated string good_file_extensions = 3;
   */
  goodFileExtensions: string[] = [];

  /**
   * @generated from field: repeated string bad_file_extensions = 4;
   */
  badFileExtensions: string[] = [];

  /**
   * Paths
   *
   * @generated from field: repeated string good_paths = 5;
   */
  goodPaths: string[] = [];

  /**
   * @generated from field: repeated string bad_paths = 6;
   */
  badPaths: string[] = [];

  constructor(data?: PartialMessage<ModelQueryResponse_Query>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ModelQueryResponse.Query";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "query", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "successful_parse", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 3, name: "good_file_extensions", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 4, name: "bad_file_extensions", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 5, name: "good_paths", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 6, name: "bad_paths", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ModelQueryResponse_Query {
    return new ModelQueryResponse_Query().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ModelQueryResponse_Query {
    return new ModelQueryResponse_Query().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ModelQueryResponse_Query {
    return new ModelQueryResponse_Query().fromJsonString(jsonString, options);
  }

  static equals(a: ModelQueryResponse_Query | PlainMessage<ModelQueryResponse_Query> | undefined, b: ModelQueryResponse_Query | PlainMessage<ModelQueryResponse_Query> | undefined): boolean {
    return proto3.util.equals(ModelQueryResponse_Query, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ApiDetails
 */
export class ApiDetails extends Message<ApiDetails> {
  /**
   * @generated from field: string api_key = 1;
   */
  apiKey = "";

  /**
   * @generated from field: optional bool enable_ghost_mode = 2;
   */
  enableGhostMode?: boolean;

  constructor(data?: PartialMessage<ApiDetails>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ApiDetails";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "api_key", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "enable_ghost_mode", kind: "scalar", T: 8 /* ScalarType.BOOL */, opt: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ApiDetails {
    return new ApiDetails().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ApiDetails {
    return new ApiDetails().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ApiDetails {
    return new ApiDetails().fromJsonString(jsonString, options);
  }

  static equals(a: ApiDetails | PlainMessage<ApiDetails> | undefined, b: ApiDetails | PlainMessage<ApiDetails> | undefined): boolean {
    return proto3.util.equals(ApiDetails, a, b);
  }
}

/**
 * @generated from message aiserver.v1.FullFileSearchResult
 */
export class FullFileSearchResult extends Message<FullFileSearchResult> {
  /**
   * @generated from field: repeated aiserver.v1.FileResult results = 1;
   */
  results: FileResult[] = [];

  constructor(data?: PartialMessage<FullFileSearchResult>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.FullFileSearchResult";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "results", kind: "message", T: FileResult, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): FullFileSearchResult {
    return new FullFileSearchResult().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): FullFileSearchResult {
    return new FullFileSearchResult().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): FullFileSearchResult {
    return new FullFileSearchResult().fromJsonString(jsonString, options);
  }

  static equals(a: FullFileSearchResult | PlainMessage<FullFileSearchResult> | undefined, b: FullFileSearchResult | PlainMessage<FullFileSearchResult> | undefined): boolean {
    return proto3.util.equals(FullFileSearchResult, a, b);
  }
}

/**
 * @generated from message aiserver.v1.CodeSearchResult
 */
export class CodeSearchResult extends Message<CodeSearchResult> {
  /**
   * @generated from field: repeated aiserver.v1.CodeResult results = 1;
   */
  results: CodeResult[] = [];

  constructor(data?: PartialMessage<CodeSearchResult>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.CodeSearchResult";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "results", kind: "message", T: CodeResult, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): CodeSearchResult {
    return new CodeSearchResult().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): CodeSearchResult {
    return new CodeSearchResult().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): CodeSearchResult {
    return new CodeSearchResult().fromJsonString(jsonString, options);
  }

  static equals(a: CodeSearchResult | PlainMessage<CodeSearchResult> | undefined, b: CodeSearchResult | PlainMessage<CodeSearchResult> | undefined): boolean {
    return proto3.util.equals(CodeSearchResult, a, b);
  }
}

/**
 * @generated from message aiserver.v1.RerankerRequest
 */
export class RerankerRequest extends Message<RerankerRequest> {
  /**
   * @generated from field: repeated aiserver.v1.CodeResult code_results = 1;
   */
  codeResults: CodeResult[] = [];

  /**
   * Then, we want the query and number of blocks to filter down to
   *
   * @generated from field: string query = 2;
   */
  query = "";

  /**
   * @generated from field: int32 num_blocks = 3;
   */
  numBlocks = 0;

  /**
   * Optionally, we want the CurrentFileInfo
   *
   * @generated from field: aiserver.v1.CurrentFileInfo current_file = 4;
   */
  currentFile?: CurrentFileInfo;

  /**
   * We also optionally want the conversation history
   *
   * @generated from field: repeated aiserver.v1.ConversationMessage conversation = 5;
   */
  conversation: ConversationMessage[] = [];

  /**
   * @generated from field: aiserver.v1.ApiDetails api_details = 6;
   */
  apiDetails?: ApiDetails;

  /**
   * @generated from oneof aiserver.v1.RerankerRequest.context_results
   */
  contextResults: {
    /**
     * We can either rerank file results
     *
     * @generated from field: aiserver.v1.FullFileSearchResult file_search_results = 7;
     */
    value: FullFileSearchResult;
    case: "fileSearchResults";
  } | {
    /**
     * Or rerank code results
     *
     * @generated from field: aiserver.v1.CodeSearchResult code_search_results = 8;
     */
    value: CodeSearchResult;
    case: "codeSearchResults";
  } | { case: undefined; value?: undefined } = { case: undefined };

  constructor(data?: PartialMessage<RerankerRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.RerankerRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "code_results", kind: "message", T: CodeResult, repeated: true },
    { no: 2, name: "query", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "num_blocks", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 4, name: "current_file", kind: "message", T: CurrentFileInfo },
    { no: 5, name: "conversation", kind: "message", T: ConversationMessage, repeated: true },
    { no: 6, name: "api_details", kind: "message", T: ApiDetails },
    { no: 7, name: "file_search_results", kind: "message", T: FullFileSearchResult, oneof: "context_results" },
    { no: 8, name: "code_search_results", kind: "message", T: CodeSearchResult, oneof: "context_results" },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): RerankerRequest {
    return new RerankerRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): RerankerRequest {
    return new RerankerRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): RerankerRequest {
    return new RerankerRequest().fromJsonString(jsonString, options);
  }

  static equals(a: RerankerRequest | PlainMessage<RerankerRequest> | undefined, b: RerankerRequest | PlainMessage<RerankerRequest> | undefined): boolean {
    return proto3.util.equals(RerankerRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.RerankerResponse
 */
export class RerankerResponse extends Message<RerankerResponse> {
  /**
   * @generated from field: repeated aiserver.v1.CodeResult results = 1;
   */
  results: CodeResult[] = [];

  constructor(data?: PartialMessage<RerankerResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.RerankerResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "results", kind: "message", T: CodeResult, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): RerankerResponse {
    return new RerankerResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): RerankerResponse {
    return new RerankerResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): RerankerResponse {
    return new RerankerResponse().fromJsonString(jsonString, options);
  }

  static equals(a: RerankerResponse | PlainMessage<RerankerResponse> | undefined, b: RerankerResponse | PlainMessage<RerankerResponse> | undefined): boolean {
    return proto3.util.equals(RerankerResponse, a, b);
  }
}

/**
 * we do not provide the context here. instead, the endpoint itself decides what
 * to search for and when
 *
 * @generated from message aiserver.v1.TaskStreamChatContextRequest
 */
export class TaskStreamChatContextRequest extends Message<TaskStreamChatContextRequest> {
  /**
   * @generated from field: aiserver.v1.CurrentFileInfo current_file = 1;
   */
  currentFile?: CurrentFileInfo;

  /**
   * the query to be answered is the last human message in the conversation
   *
   * @generated from field: repeated aiserver.v1.ConversationMessage conversation = 2;
   */
  conversation: ConversationMessage[] = [];

  /**
   * @generated from field: repeated aiserver.v1.RepositoryInfo repositories = 3;
   */
  repositories: RepositoryInfo[] = [];

  /**
   * @generated from field: aiserver.v1.ExplicitContext explicit_context = 4;
   */
  explicitContext?: ExplicitContext;

  /**
   * @generated from field: optional string workspace_root_path = 5;
   */
  workspaceRootPath?: string;

  /**
   * Other code blocks to add in
   *
   * @generated from field: repeated aiserver.v1.CodeBlock code_blocks = 6;
   */
  codeBlocks: CodeBlock[] = [];

  /**
   * What model to use and api key to use if applicable
   *
   * @generated from field: aiserver.v1.ModelDetails model_details = 7;
   */
  modelDetails?: ModelDetails;

  /**
   * @generated from field: repeated string documentation_identifiers = 8;
   */
  documentationIdentifiers: string[] = [];

  /**
   * @generated from field: aiserver.v1.LinterErrors linter_errors = 14;
   */
  linterErrors?: LinterErrors;

  /**
   * @generated from field: aiserver.v1.AdvancedCodebaseContextOptions advanced_codebase_context = 15;
   */
  advancedCodebaseContext?: AdvancedCodebaseContextOptions;

  constructor(data?: PartialMessage<TaskStreamChatContextRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskStreamChatContextRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "current_file", kind: "message", T: CurrentFileInfo },
    { no: 2, name: "conversation", kind: "message", T: ConversationMessage, repeated: true },
    { no: 3, name: "repositories", kind: "message", T: RepositoryInfo, repeated: true },
    { no: 4, name: "explicit_context", kind: "message", T: ExplicitContext },
    { no: 5, name: "workspace_root_path", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 6, name: "code_blocks", kind: "message", T: CodeBlock, repeated: true },
    { no: 7, name: "model_details", kind: "message", T: ModelDetails },
    { no: 8, name: "documentation_identifiers", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 14, name: "linter_errors", kind: "message", T: LinterErrors },
    { no: 15, name: "advanced_codebase_context", kind: "message", T: AdvancedCodebaseContextOptions },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskStreamChatContextRequest {
    return new TaskStreamChatContextRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskStreamChatContextRequest {
    return new TaskStreamChatContextRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskStreamChatContextRequest {
    return new TaskStreamChatContextRequest().fromJsonString(jsonString, options);
  }

  static equals(a: TaskStreamChatContextRequest | PlainMessage<TaskStreamChatContextRequest> | undefined, b: TaskStreamChatContextRequest | PlainMessage<TaskStreamChatContextRequest> | undefined): boolean {
    return proto3.util.equals(TaskStreamChatContextRequest, a, b);
  }
}

/**
 * this type is stored, too, so we want to be careful to ensure that it not
 * changed too often (see chatData.tsx)
 * TODO: maybe this is a bad idea because we want to be able to set things up
 * for experimentation much more... and we don't want to lock ourselves into
 * parameters like these. idk. it is useful for exploration, so let's do this
 * for now and refactor later
 *
 * @generated from message aiserver.v1.AdvancedCodebaseContextOptions
 */
export class AdvancedCodebaseContextOptions extends Message<AdvancedCodebaseContextOptions> {
  /**
   * this is the number of results per embedding search
   *
   * @generated from field: int32 num_results_per_search = 1;
   */
  numResultsPerSearch = 0;

  /**
   * not sure if these should ever be exposed to the user... feels like our
   * search should just be good enough for these not to be necessary at all tbh
   *
   * @generated from field: optional string include_pattern = 2;
   */
  includePattern?: string;

  /**
   * @generated from field: optional string exclude_pattern = 3;
   */
  excludePattern?: string;

  /**
   * @generated from field: aiserver.v1.RerankerAlgorithm reranker = 4;
   */
  reranker = RerankerAlgorithm.UNSPECIFIED;

  /**
   * if index_id is present, we only search over that specific index
   * index_id can be local in which case we use the local index
   * if index_id is null, then we search through all indexes that are present
   *
   * the index_id is currently defined as `${repoOwner}/${repoName}`
   * this is not truly unique once we add non-github repo providers
   * but it is fine for now
   *
   * @generated from field: optional string index_id = 5;
   */
  indexId?: string;

  /**
   * @generated from field: bool reasoning_step = 6;
   */
  reasoningStep = false;

  constructor(data?: PartialMessage<AdvancedCodebaseContextOptions>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.AdvancedCodebaseContextOptions";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "num_results_per_search", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 2, name: "include_pattern", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 3, name: "exclude_pattern", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 4, name: "reranker", kind: "enum", T: proto3.getEnumType(RerankerAlgorithm) },
    { no: 5, name: "index_id", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 6, name: "reasoning_step", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): AdvancedCodebaseContextOptions {
    return new AdvancedCodebaseContextOptions().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): AdvancedCodebaseContextOptions {
    return new AdvancedCodebaseContextOptions().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): AdvancedCodebaseContextOptions {
    return new AdvancedCodebaseContextOptions().fromJsonString(jsonString, options);
  }

  static equals(a: AdvancedCodebaseContextOptions | PlainMessage<AdvancedCodebaseContextOptions> | undefined, b: AdvancedCodebaseContextOptions | PlainMessage<AdvancedCodebaseContextOptions> | undefined): boolean {
    return proto3.util.equals(AdvancedCodebaseContextOptions, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskStreamChatContextResponse
 */
export class TaskStreamChatContextResponse extends Message<TaskStreamChatContextResponse> {
  /**
   * @generated from oneof aiserver.v1.TaskStreamChatContextResponse.response
   */
  response: {
    /**
     * @generated from field: aiserver.v1.TaskStreamChatContextResponse.Output output = 1;
     */
    value: TaskStreamChatContextResponse_Output;
    case: "output";
  } | {
    /**
     * @generated from field: aiserver.v1.TaskStreamChatContextResponse.GatheringStep gathering_step = 2;
     */
    value: TaskStreamChatContextResponse_GatheringStep;
    case: "gatheringStep";
  } | {
    /**
     * there will be A LOT of gathering_files
     *
     * @generated from field: aiserver.v1.TaskStreamChatContextResponse.GatheringFile gathering_file = 3;
     */
    value: TaskStreamChatContextResponse_GatheringFile;
    case: "gatheringFile";
  } | {
    /**
     * @generated from field: aiserver.v1.TaskStreamChatContextResponse.RerankingStep reranking_step = 4;
     */
    value: TaskStreamChatContextResponse_RerankingStep;
    case: "rerankingStep";
  } | {
    /**
     * @generated from field: aiserver.v1.TaskStreamChatContextResponse.RerankingFile reranking_file = 5;
     */
    value: TaskStreamChatContextResponse_RerankingFile;
    case: "rerankingFile";
  } | {
    /**
     * @generated from field: aiserver.v1.TaskStreamChatContextResponse.ReasoningStep reasoning_step = 6;
     */
    value: TaskStreamChatContextResponse_ReasoningStep;
    case: "reasoningStep";
  } | {
    /**
     * @generated from field: aiserver.v1.TaskStreamChatContextResponse.ReasoningSubstep reasoning_substep = 7;
     */
    value: TaskStreamChatContextResponse_ReasoningSubstep;
    case: "reasoningSubstep";
  } | { case: undefined; value?: undefined } = { case: undefined };

  constructor(data?: PartialMessage<TaskStreamChatContextResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskStreamChatContextResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "output", kind: "message", T: TaskStreamChatContextResponse_Output, oneof: "response" },
    { no: 2, name: "gathering_step", kind: "message", T: TaskStreamChatContextResponse_GatheringStep, oneof: "response" },
    { no: 3, name: "gathering_file", kind: "message", T: TaskStreamChatContextResponse_GatheringFile, oneof: "response" },
    { no: 4, name: "reranking_step", kind: "message", T: TaskStreamChatContextResponse_RerankingStep, oneof: "response" },
    { no: 5, name: "reranking_file", kind: "message", T: TaskStreamChatContextResponse_RerankingFile, oneof: "response" },
    { no: 6, name: "reasoning_step", kind: "message", T: TaskStreamChatContextResponse_ReasoningStep, oneof: "response" },
    { no: 7, name: "reasoning_substep", kind: "message", T: TaskStreamChatContextResponse_ReasoningSubstep, oneof: "response" },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskStreamChatContextResponse {
    return new TaskStreamChatContextResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskStreamChatContextResponse {
    return new TaskStreamChatContextResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskStreamChatContextResponse {
    return new TaskStreamChatContextResponse().fromJsonString(jsonString, options);
  }

  static equals(a: TaskStreamChatContextResponse | PlainMessage<TaskStreamChatContextResponse> | undefined, b: TaskStreamChatContextResponse | PlainMessage<TaskStreamChatContextResponse> | undefined): boolean {
    return proto3.util.equals(TaskStreamChatContextResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskStreamChatContextResponse.Output
 */
export class TaskStreamChatContextResponse_Output extends Message<TaskStreamChatContextResponse_Output> {
  /**
   * @generated from field: string text = 1;
   */
  text = "";

  constructor(data?: PartialMessage<TaskStreamChatContextResponse_Output>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskStreamChatContextResponse.Output";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskStreamChatContextResponse_Output {
    return new TaskStreamChatContextResponse_Output().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskStreamChatContextResponse_Output {
    return new TaskStreamChatContextResponse_Output().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskStreamChatContextResponse_Output {
    return new TaskStreamChatContextResponse_Output().fromJsonString(jsonString, options);
  }

  static equals(a: TaskStreamChatContextResponse_Output | PlainMessage<TaskStreamChatContextResponse_Output> | undefined, b: TaskStreamChatContextResponse_Output | PlainMessage<TaskStreamChatContextResponse_Output> | undefined): boolean {
    return proto3.util.equals(TaskStreamChatContextResponse_Output, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskStreamChatContextResponse.GatheringFile
 */
export class TaskStreamChatContextResponse_GatheringFile extends Message<TaskStreamChatContextResponse_GatheringFile> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * @generated from field: aiserver.v1.SimpleRange range = 2;
   */
  range?: SimpleRange;

  /**
   * @generated from field: int32 step_index = 3;
   */
  stepIndex = 0;

  /**
   * @generated from field: float score = 4;
   */
  score = 0;

  constructor(data?: PartialMessage<TaskStreamChatContextResponse_GatheringFile>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskStreamChatContextResponse.GatheringFile";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "range", kind: "message", T: SimpleRange },
    { no: 3, name: "step_index", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 4, name: "score", kind: "scalar", T: 2 /* ScalarType.FLOAT */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskStreamChatContextResponse_GatheringFile {
    return new TaskStreamChatContextResponse_GatheringFile().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskStreamChatContextResponse_GatheringFile {
    return new TaskStreamChatContextResponse_GatheringFile().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskStreamChatContextResponse_GatheringFile {
    return new TaskStreamChatContextResponse_GatheringFile().fromJsonString(jsonString, options);
  }

  static equals(a: TaskStreamChatContextResponse_GatheringFile | PlainMessage<TaskStreamChatContextResponse_GatheringFile> | undefined, b: TaskStreamChatContextResponse_GatheringFile | PlainMessage<TaskStreamChatContextResponse_GatheringFile> | undefined): boolean {
    return proto3.util.equals(TaskStreamChatContextResponse_GatheringFile, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskStreamChatContextResponse.GatheringStep
 */
export class TaskStreamChatContextResponse_GatheringStep extends Message<TaskStreamChatContextResponse_GatheringStep> {
  /**
   * @generated from field: string title = 1;
   */
  title = "";

  /**
   * usually starting at 1, but specifics don't matter. we
   *
   * @generated from field: int32 index = 2;
   */
  index = 0;

  /**
   * just sort on the frontend
   * TODO: add kind (hyde/embed/rg/etc) + the actual query being made.
   * probably needs a one_of here or something
   *
   * @generated from field: string query = 3;
   */
  query = "";

  constructor(data?: PartialMessage<TaskStreamChatContextResponse_GatheringStep>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskStreamChatContextResponse.GatheringStep";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "title", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "index", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "query", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskStreamChatContextResponse_GatheringStep {
    return new TaskStreamChatContextResponse_GatheringStep().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskStreamChatContextResponse_GatheringStep {
    return new TaskStreamChatContextResponse_GatheringStep().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskStreamChatContextResponse_GatheringStep {
    return new TaskStreamChatContextResponse_GatheringStep().fromJsonString(jsonString, options);
  }

  static equals(a: TaskStreamChatContextResponse_GatheringStep | PlainMessage<TaskStreamChatContextResponse_GatheringStep> | undefined, b: TaskStreamChatContextResponse_GatheringStep | PlainMessage<TaskStreamChatContextResponse_GatheringStep> | undefined): boolean {
    return proto3.util.equals(TaskStreamChatContextResponse_GatheringStep, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskStreamChatContextResponse.RerankingStep
 */
export class TaskStreamChatContextResponse_RerankingStep extends Message<TaskStreamChatContextResponse_RerankingStep> {
  /**
   * @generated from field: string title = 1;
   */
  title = "";

  /**
   * @generated from field: int32 index = 2;
   */
  index = 0;

  constructor(data?: PartialMessage<TaskStreamChatContextResponse_RerankingStep>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskStreamChatContextResponse.RerankingStep";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "title", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "index", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskStreamChatContextResponse_RerankingStep {
    return new TaskStreamChatContextResponse_RerankingStep().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskStreamChatContextResponse_RerankingStep {
    return new TaskStreamChatContextResponse_RerankingStep().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskStreamChatContextResponse_RerankingStep {
    return new TaskStreamChatContextResponse_RerankingStep().fromJsonString(jsonString, options);
  }

  static equals(a: TaskStreamChatContextResponse_RerankingStep | PlainMessage<TaskStreamChatContextResponse_RerankingStep> | undefined, b: TaskStreamChatContextResponse_RerankingStep | PlainMessage<TaskStreamChatContextResponse_RerankingStep> | undefined): boolean {
    return proto3.util.equals(TaskStreamChatContextResponse_RerankingStep, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskStreamChatContextResponse.RerankingFile
 */
export class TaskStreamChatContextResponse_RerankingFile extends Message<TaskStreamChatContextResponse_RerankingFile> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * @generated from field: aiserver.v1.SimpleRange range = 2;
   */
  range?: SimpleRange;

  /**
   * the reason is a markdown string that may sometimes be interesting
   *
   * @generated from field: string reason = 3;
   */
  reason = "";

  /**
   * @generated from field: bool failed = 4;
   */
  failed = false;

  /**
   * sometimes the reranker also has a score. either way there always has to
   * be a score for determining the ranking! higher score is better, i believe
   *
   * @generated from field: float score = 5;
   */
  score = 0;

  /**
   * @generated from field: int32 step_index = 6;
   */
  stepIndex = 0;

  constructor(data?: PartialMessage<TaskStreamChatContextResponse_RerankingFile>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskStreamChatContextResponse.RerankingFile";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "range", kind: "message", T: SimpleRange },
    { no: 3, name: "reason", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "failed", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 5, name: "score", kind: "scalar", T: 2 /* ScalarType.FLOAT */ },
    { no: 6, name: "step_index", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskStreamChatContextResponse_RerankingFile {
    return new TaskStreamChatContextResponse_RerankingFile().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskStreamChatContextResponse_RerankingFile {
    return new TaskStreamChatContextResponse_RerankingFile().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskStreamChatContextResponse_RerankingFile {
    return new TaskStreamChatContextResponse_RerankingFile().fromJsonString(jsonString, options);
  }

  static equals(a: TaskStreamChatContextResponse_RerankingFile | PlainMessage<TaskStreamChatContextResponse_RerankingFile> | undefined, b: TaskStreamChatContextResponse_RerankingFile | PlainMessage<TaskStreamChatContextResponse_RerankingFile> | undefined): boolean {
    return proto3.util.equals(TaskStreamChatContextResponse_RerankingFile, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskStreamChatContextResponse.ReasoningStep
 */
export class TaskStreamChatContextResponse_ReasoningStep extends Message<TaskStreamChatContextResponse_ReasoningStep> {
  /**
   * @generated from field: string title = 1;
   */
  title = "";

  /**
   * @generated from field: int32 index = 2;
   */
  index = 0;

  constructor(data?: PartialMessage<TaskStreamChatContextResponse_ReasoningStep>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskStreamChatContextResponse.ReasoningStep";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "title", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "index", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskStreamChatContextResponse_ReasoningStep {
    return new TaskStreamChatContextResponse_ReasoningStep().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskStreamChatContextResponse_ReasoningStep {
    return new TaskStreamChatContextResponse_ReasoningStep().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskStreamChatContextResponse_ReasoningStep {
    return new TaskStreamChatContextResponse_ReasoningStep().fromJsonString(jsonString, options);
  }

  static equals(a: TaskStreamChatContextResponse_ReasoningStep | PlainMessage<TaskStreamChatContextResponse_ReasoningStep> | undefined, b: TaskStreamChatContextResponse_ReasoningStep | PlainMessage<TaskStreamChatContextResponse_ReasoningStep> | undefined): boolean {
    return proto3.util.equals(TaskStreamChatContextResponse_ReasoningStep, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskStreamChatContextResponse.ReasoningSubstep
 */
export class TaskStreamChatContextResponse_ReasoningSubstep extends Message<TaskStreamChatContextResponse_ReasoningSubstep> {
  /**
   * @generated from field: string markdown_explanation = 1;
   */
  markdownExplanation = "";

  /**
   * @generated from field: int32 step_index = 2;
   */
  stepIndex = 0;

  constructor(data?: PartialMessage<TaskStreamChatContextResponse_ReasoningSubstep>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskStreamChatContextResponse.ReasoningSubstep";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "markdown_explanation", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "step_index", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskStreamChatContextResponse_ReasoningSubstep {
    return new TaskStreamChatContextResponse_ReasoningSubstep().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskStreamChatContextResponse_ReasoningSubstep {
    return new TaskStreamChatContextResponse_ReasoningSubstep().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskStreamChatContextResponse_ReasoningSubstep {
    return new TaskStreamChatContextResponse_ReasoningSubstep().fromJsonString(jsonString, options);
  }

  static equals(a: TaskStreamChatContextResponse_ReasoningSubstep | PlainMessage<TaskStreamChatContextResponse_ReasoningSubstep> | undefined, b: TaskStreamChatContextResponse_ReasoningSubstep | PlainMessage<TaskStreamChatContextResponse_ReasoningSubstep> | undefined): boolean {
    return proto3.util.equals(TaskStreamChatContextResponse_ReasoningSubstep, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskStreamChatContextResponseWrapped
 */
export class TaskStreamChatContextResponseWrapped extends Message<TaskStreamChatContextResponseWrapped> {
  /**
   * @generated from oneof aiserver.v1.TaskStreamChatContextResponseWrapped.response
   */
  response: {
    /**
     * @generated from field: aiserver.v1.TaskStreamChatContextResponse real_response = 1;
     */
    value: TaskStreamChatContextResponse;
    case: "realResponse";
  } | {
    /**
     * @generated from field: string background_task_uuid = 2;
     */
    value: string;
    case: "backgroundTaskUuid";
  } | { case: undefined; value?: undefined } = { case: undefined };

  constructor(data?: PartialMessage<TaskStreamChatContextResponseWrapped>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskStreamChatContextResponseWrapped";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "real_response", kind: "message", T: TaskStreamChatContextResponse, oneof: "response" },
    { no: 2, name: "background_task_uuid", kind: "scalar", T: 9 /* ScalarType.STRING */, oneof: "response" },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskStreamChatContextResponseWrapped {
    return new TaskStreamChatContextResponseWrapped().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskStreamChatContextResponseWrapped {
    return new TaskStreamChatContextResponseWrapped().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskStreamChatContextResponseWrapped {
    return new TaskStreamChatContextResponseWrapped().fromJsonString(jsonString, options);
  }

  static equals(a: TaskStreamChatContextResponseWrapped | PlainMessage<TaskStreamChatContextResponseWrapped> | undefined, b: TaskStreamChatContextResponseWrapped | PlainMessage<TaskStreamChatContextResponseWrapped> | undefined): boolean {
    return proto3.util.equals(TaskStreamChatContextResponseWrapped, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamChatContextRequest
 */
export class StreamChatContextRequest extends Message<StreamChatContextRequest> {
  /**
   * @generated from field: aiserver.v1.CurrentFileInfo current_file = 1;
   */
  currentFile?: CurrentFileInfo;

  /**
   * the query to be answered is the last human message in the conversation
   *
   * @generated from field: repeated aiserver.v1.ConversationMessage conversation = 2;
   */
  conversation: ConversationMessage[] = [];

  /**
   * @generated from field: repeated aiserver.v1.RepositoryInfo repositories = 3;
   */
  repositories: RepositoryInfo[] = [];

  /**
   * @generated from field: aiserver.v1.ExplicitContext explicit_context = 4;
   */
  explicitContext?: ExplicitContext;

  /**
   * @generated from field: optional string workspace_root_path = 5;
   */
  workspaceRootPath?: string;

  /**
   * Other code blocks to add in
   *
   * @generated from field: repeated aiserver.v1.CodeBlock code_blocks = 6;
   */
  codeBlocks: CodeBlock[] = [];

  /**
   * What model to use and api key to use if applicable
   *
   * @generated from field: aiserver.v1.ModelDetails model_details = 7;
   */
  modelDetails?: ModelDetails;

  /**
   * @generated from field: repeated string documentation_identifiers = 8;
   */
  documentationIdentifiers: string[] = [];

  /**
   * New additions to the context
   *
   * @generated from field: string query = 9;
   */
  query = "";

  /**
   * @generated from field: aiserver.v1.StreamChatContextRequest.CodeContext code_context = 10;
   */
  codeContext?: StreamChatContextRequest_CodeContext;

  /**
   * @generated from field: bool rerank_results = 11;
   */
  rerankResults = false;

  /**
   * @generated from oneof aiserver.v1.StreamChatContextRequest.context_results
   */
  contextResults: {
    /**
     * We can either rerank file results
     *
     * @generated from field: aiserver.v1.FullFileSearchResult file_search_results = 12;
     */
    value: FullFileSearchResult;
    case: "fileSearchResults";
  } | {
    /**
     * Or rerank code results
     *
     * @generated from field: aiserver.v1.CodeSearchResult code_search_results = 13;
     */
    value: CodeSearchResult;
    case: "codeSearchResults";
  } | { case: undefined; value?: undefined } = { case: undefined };

  /**
   * @generated from field: aiserver.v1.LinterErrors linter_errors = 14;
   */
  linterErrors?: LinterErrors;

  constructor(data?: PartialMessage<StreamChatContextRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamChatContextRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "current_file", kind: "message", T: CurrentFileInfo },
    { no: 2, name: "conversation", kind: "message", T: ConversationMessage, repeated: true },
    { no: 3, name: "repositories", kind: "message", T: RepositoryInfo, repeated: true },
    { no: 4, name: "explicit_context", kind: "message", T: ExplicitContext },
    { no: 5, name: "workspace_root_path", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 6, name: "code_blocks", kind: "message", T: CodeBlock, repeated: true },
    { no: 7, name: "model_details", kind: "message", T: ModelDetails },
    { no: 8, name: "documentation_identifiers", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 9, name: "query", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 10, name: "code_context", kind: "message", T: StreamChatContextRequest_CodeContext },
    { no: 11, name: "rerank_results", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 12, name: "file_search_results", kind: "message", T: FullFileSearchResult, oneof: "context_results" },
    { no: 13, name: "code_search_results", kind: "message", T: CodeSearchResult, oneof: "context_results" },
    { no: 14, name: "linter_errors", kind: "message", T: LinterErrors },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamChatContextRequest {
    return new StreamChatContextRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamChatContextRequest {
    return new StreamChatContextRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamChatContextRequest {
    return new StreamChatContextRequest().fromJsonString(jsonString, options);
  }

  static equals(a: StreamChatContextRequest | PlainMessage<StreamChatContextRequest> | undefined, b: StreamChatContextRequest | PlainMessage<StreamChatContextRequest> | undefined): boolean {
    return proto3.util.equals(StreamChatContextRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamChatContextRequest.CodeContext
 */
export class StreamChatContextRequest_CodeContext extends Message<StreamChatContextRequest_CodeContext> {
  /**
   * @generated from field: repeated aiserver.v1.CodeBlock chunks = 1;
   */
  chunks: CodeBlock[] = [];

  /**
   * @generated from field: repeated aiserver.v1.CodeResult scored_chunks = 2;
   */
  scoredChunks: CodeResult[] = [];

  constructor(data?: PartialMessage<StreamChatContextRequest_CodeContext>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamChatContextRequest.CodeContext";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "chunks", kind: "message", T: CodeBlock, repeated: true },
    { no: 2, name: "scored_chunks", kind: "message", T: CodeResult, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamChatContextRequest_CodeContext {
    return new StreamChatContextRequest_CodeContext().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamChatContextRequest_CodeContext {
    return new StreamChatContextRequest_CodeContext().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamChatContextRequest_CodeContext {
    return new StreamChatContextRequest_CodeContext().fromJsonString(jsonString, options);
  }

  static equals(a: StreamChatContextRequest_CodeContext | PlainMessage<StreamChatContextRequest_CodeContext> | undefined, b: StreamChatContextRequest_CodeContext | PlainMessage<StreamChatContextRequest_CodeContext> | undefined): boolean {
    return proto3.util.equals(StreamChatContextRequest_CodeContext, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamChatContextResponse
 */
export class StreamChatContextResponse extends Message<StreamChatContextResponse> {
  /**
   * @generated from field: string text = 1;
   */
  text = "";

  /**
   * we return the prompt for debugging purposes
   * only if the debug-chat-prompt flag is set on the server
   *
   * @generated from field: optional string debugging_only_chat_prompt = 2;
   */
  debuggingOnlyChatPrompt?: string;

  /**
   * @generated from field: optional int32 debugging_only_token_count = 3;
   */
  debuggingOnlyTokenCount?: number;

  /**
   * Return back cited documentation when applicable
   *
   * @generated from field: aiserver.v1.DocumentationCitation document_citation = 4;
   */
  documentCitation?: DocumentationCitation;

  /**
   * Also give back the prompt if possible
   *
   * @generated from field: optional string filled_prompt = 5;
   */
  filledPrompt?: string;

  /**
   * The code results used to generate this response
   * this is expected as the
   *
   * @generated from field: aiserver.v1.StreamChatContextResponse.UsedCode used_code = 6;
   */
  usedCode?: StreamChatContextResponse_UsedCode;

  /**
   * @generated from field: aiserver.v1.StreamChatContextResponse.CodeLink code_link = 7;
   */
  codeLink?: StreamChatContextResponse_CodeLink;

  /**
   * @generated from field: optional aiserver.v1.StreamChatContextResponse.ChunkIdentity chunk_identity = 8;
   */
  chunkIdentity?: StreamChatContextResponse_ChunkIdentity;

  constructor(data?: PartialMessage<StreamChatContextResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamChatContextResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "debugging_only_chat_prompt", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 3, name: "debugging_only_token_count", kind: "scalar", T: 5 /* ScalarType.INT32 */, opt: true },
    { no: 4, name: "document_citation", kind: "message", T: DocumentationCitation },
    { no: 5, name: "filled_prompt", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 6, name: "used_code", kind: "message", T: StreamChatContextResponse_UsedCode },
    { no: 7, name: "code_link", kind: "message", T: StreamChatContextResponse_CodeLink },
    { no: 8, name: "chunk_identity", kind: "message", T: StreamChatContextResponse_ChunkIdentity, opt: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamChatContextResponse {
    return new StreamChatContextResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamChatContextResponse {
    return new StreamChatContextResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamChatContextResponse {
    return new StreamChatContextResponse().fromJsonString(jsonString, options);
  }

  static equals(a: StreamChatContextResponse | PlainMessage<StreamChatContextResponse> | undefined, b: StreamChatContextResponse | PlainMessage<StreamChatContextResponse> | undefined): boolean {
    return proto3.util.equals(StreamChatContextResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamChatContextResponse.UsedCode
 */
export class StreamChatContextResponse_UsedCode extends Message<StreamChatContextResponse_UsedCode> {
  /**
   * @generated from field: repeated aiserver.v1.CodeResult code_results = 1;
   */
  codeResults: CodeResult[] = [];

  constructor(data?: PartialMessage<StreamChatContextResponse_UsedCode>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamChatContextResponse.UsedCode";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "code_results", kind: "message", T: CodeResult, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamChatContextResponse_UsedCode {
    return new StreamChatContextResponse_UsedCode().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamChatContextResponse_UsedCode {
    return new StreamChatContextResponse_UsedCode().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamChatContextResponse_UsedCode {
    return new StreamChatContextResponse_UsedCode().fromJsonString(jsonString, options);
  }

  static equals(a: StreamChatContextResponse_UsedCode | PlainMessage<StreamChatContextResponse_UsedCode> | undefined, b: StreamChatContextResponse_UsedCode | PlainMessage<StreamChatContextResponse_UsedCode> | undefined): boolean {
    return proto3.util.equals(StreamChatContextResponse_UsedCode, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamChatContextResponse.CodeLink
 */
export class StreamChatContextResponse_CodeLink extends Message<StreamChatContextResponse_CodeLink> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * @generated from field: int32 start_line_number = 2;
   */
  startLineNumber = 0;

  /**
   * @generated from field: int32 end_line_number = 3;
   */
  endLineNumber = 0;

  constructor(data?: PartialMessage<StreamChatContextResponse_CodeLink>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamChatContextResponse.CodeLink";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "start_line_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "end_line_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamChatContextResponse_CodeLink {
    return new StreamChatContextResponse_CodeLink().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamChatContextResponse_CodeLink {
    return new StreamChatContextResponse_CodeLink().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamChatContextResponse_CodeLink {
    return new StreamChatContextResponse_CodeLink().fromJsonString(jsonString, options);
  }

  static equals(a: StreamChatContextResponse_CodeLink | PlainMessage<StreamChatContextResponse_CodeLink> | undefined, b: StreamChatContextResponse_CodeLink | PlainMessage<StreamChatContextResponse_CodeLink> | undefined): boolean {
    return proto3.util.equals(StreamChatContextResponse_CodeLink, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamChatContextResponse.ChunkIdentity
 */
export class StreamChatContextResponse_ChunkIdentity extends Message<StreamChatContextResponse_ChunkIdentity> {
  /**
   * @generated from field: string file_name = 1;
   */
  fileName = "";

  /**
   * @generated from field: int32 start_line = 2;
   */
  startLine = 0;

  /**
   * @generated from field: int32 end_line = 3;
   */
  endLine = 0;

  /**
   * @generated from field: string text = 4;
   */
  text = "";

  /**
   * @generated from field: aiserver.v1.ChunkType chunk_type = 5;
   */
  chunkType = ChunkType.UNSPECIFIED;

  constructor(data?: PartialMessage<StreamChatContextResponse_ChunkIdentity>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamChatContextResponse.ChunkIdentity";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "file_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "start_line", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "end_line", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 4, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 5, name: "chunk_type", kind: "enum", T: proto3.getEnumType(ChunkType) },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamChatContextResponse_ChunkIdentity {
    return new StreamChatContextResponse_ChunkIdentity().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamChatContextResponse_ChunkIdentity {
    return new StreamChatContextResponse_ChunkIdentity().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamChatContextResponse_ChunkIdentity {
    return new StreamChatContextResponse_ChunkIdentity().fromJsonString(jsonString, options);
  }

  static equals(a: StreamChatContextResponse_ChunkIdentity | PlainMessage<StreamChatContextResponse_ChunkIdentity> | undefined, b: StreamChatContextResponse_ChunkIdentity | PlainMessage<StreamChatContextResponse_ChunkIdentity> | undefined): boolean {
    return proto3.util.equals(StreamChatContextResponse_ChunkIdentity, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamChatDeepContextRequest
 */
export class StreamChatDeepContextRequest extends Message<StreamChatDeepContextRequest> {
  /**
   * the query to be answered is the last human message in the conversation
   *
   * @generated from field: repeated aiserver.v1.ConversationMessage conversation = 1;
   */
  conversation: ConversationMessage[] = [];

  /**
   * @generated from field: aiserver.v1.ExplicitContext explicit_context = 2;
   */
  explicitContext?: ExplicitContext;

  /**
   * What model to use and api key to use if applicable
   *
   * @generated from field: aiserver.v1.ModelDetails model_details = 3;
   */
  modelDetails?: ModelDetails;

  /**
   * @generated from field: aiserver.v1.SearchRepositoryDeepContextResponse context_results = 4;
   */
  contextResults?: SearchRepositoryDeepContextResponse;

  /**
   * @generated from field: bool rerank_results = 5;
   */
  rerankResults = false;

  constructor(data?: PartialMessage<StreamChatDeepContextRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamChatDeepContextRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "conversation", kind: "message", T: ConversationMessage, repeated: true },
    { no: 2, name: "explicit_context", kind: "message", T: ExplicitContext },
    { no: 3, name: "model_details", kind: "message", T: ModelDetails },
    { no: 4, name: "context_results", kind: "message", T: SearchRepositoryDeepContextResponse },
    { no: 5, name: "rerank_results", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamChatDeepContextRequest {
    return new StreamChatDeepContextRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamChatDeepContextRequest {
    return new StreamChatDeepContextRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamChatDeepContextRequest {
    return new StreamChatDeepContextRequest().fromJsonString(jsonString, options);
  }

  static equals(a: StreamChatDeepContextRequest | PlainMessage<StreamChatDeepContextRequest> | undefined, b: StreamChatDeepContextRequest | PlainMessage<StreamChatDeepContextRequest> | undefined): boolean {
    return proto3.util.equals(StreamChatDeepContextRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamChatDeepContextResponse
 */
export class StreamChatDeepContextResponse extends Message<StreamChatDeepContextResponse> {
  /**
   * @generated from field: string text = 1;
   */
  text = "";

  constructor(data?: PartialMessage<StreamChatDeepContextResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamChatDeepContextResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamChatDeepContextResponse {
    return new StreamChatDeepContextResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamChatDeepContextResponse {
    return new StreamChatDeepContextResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamChatDeepContextResponse {
    return new StreamChatDeepContextResponse().fromJsonString(jsonString, options);
  }

  static equals(a: StreamChatDeepContextResponse | PlainMessage<StreamChatDeepContextResponse> | undefined, b: StreamChatDeepContextResponse | PlainMessage<StreamChatDeepContextResponse> | undefined): boolean {
    return proto3.util.equals(StreamChatDeepContextResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.DocumentationInfo
 */
export class DocumentationInfo extends Message<DocumentationInfo> {
  /**
   * @generated from field: string doc_identifier = 1;
   */
  docIdentifier = "";

  /**
   * @generated from field: aiserver.v1.DocumentationMetadata metadata = 2;
   */
  metadata?: DocumentationMetadata;

  constructor(data?: PartialMessage<DocumentationInfo>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.DocumentationInfo";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "doc_identifier", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "metadata", kind: "message", T: DocumentationMetadata },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): DocumentationInfo {
    return new DocumentationInfo().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): DocumentationInfo {
    return new DocumentationInfo().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): DocumentationInfo {
    return new DocumentationInfo().fromJsonString(jsonString, options);
  }

  static equals(a: DocumentationInfo | PlainMessage<DocumentationInfo> | undefined, b: DocumentationInfo | PlainMessage<DocumentationInfo> | undefined): boolean {
    return proto3.util.equals(DocumentationInfo, a, b);
  }
}

/**
 * @generated from message aiserver.v1.AvailableDocsRequest
 */
export class AvailableDocsRequest extends Message<AvailableDocsRequest> {
  /**
   * @generated from oneof aiserver.v1.AvailableDocsRequest.partial_doc
   */
  partialDoc: {
    /**
     * @generated from field: string partial_url = 1;
     */
    value: string;
    case: "partialUrl";
  } | {
    /**
     * @generated from field: string partial_doc_name = 2;
     */
    value: string;
    case: "partialDocName";
  } | {
    /**
     * empty value means we sort the first 100 docs score
     *
     * @generated from field: bool get_all = 3;
     */
    value: boolean;
    case: "getAll";
  } | { case: undefined; value?: undefined } = { case: undefined };

  /**
   * @generated from field: repeated string additional_doc_identifiers = 4;
   */
  additionalDocIdentifiers: string[] = [];

  constructor(data?: PartialMessage<AvailableDocsRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.AvailableDocsRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "partial_url", kind: "scalar", T: 9 /* ScalarType.STRING */, oneof: "partial_doc" },
    { no: 2, name: "partial_doc_name", kind: "scalar", T: 9 /* ScalarType.STRING */, oneof: "partial_doc" },
    { no: 3, name: "get_all", kind: "scalar", T: 8 /* ScalarType.BOOL */, oneof: "partial_doc" },
    { no: 4, name: "additional_doc_identifiers", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): AvailableDocsRequest {
    return new AvailableDocsRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): AvailableDocsRequest {
    return new AvailableDocsRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): AvailableDocsRequest {
    return new AvailableDocsRequest().fromJsonString(jsonString, options);
  }

  static equals(a: AvailableDocsRequest | PlainMessage<AvailableDocsRequest> | undefined, b: AvailableDocsRequest | PlainMessage<AvailableDocsRequest> | undefined): boolean {
    return proto3.util.equals(AvailableDocsRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.AvailableDocsResponse
 */
export class AvailableDocsResponse extends Message<AvailableDocsResponse> {
  /**
   * @generated from field: repeated aiserver.v1.DocumentationInfo docs = 1;
   */
  docs: DocumentationInfo[] = [];

  constructor(data?: PartialMessage<AvailableDocsResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.AvailableDocsResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "docs", kind: "message", T: DocumentationInfo, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): AvailableDocsResponse {
    return new AvailableDocsResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): AvailableDocsResponse {
    return new AvailableDocsResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): AvailableDocsResponse {
    return new AvailableDocsResponse().fromJsonString(jsonString, options);
  }

  static equals(a: AvailableDocsResponse | PlainMessage<AvailableDocsResponse> | undefined, b: AvailableDocsResponse | PlainMessage<AvailableDocsResponse> | undefined): boolean {
    return proto3.util.equals(AvailableDocsResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ThrowErrorCheckRequest
 */
export class ThrowErrorCheckRequest extends Message<ThrowErrorCheckRequest> {
  /**
   * @generated from field: aiserver.v1.ErrorDetails.Error error = 1;
   */
  error = ErrorDetails_Error.UNSPECIFIED;

  constructor(data?: PartialMessage<ThrowErrorCheckRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ThrowErrorCheckRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "error", kind: "enum", T: proto3.getEnumType(ErrorDetails_Error) },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ThrowErrorCheckRequest {
    return new ThrowErrorCheckRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ThrowErrorCheckRequest {
    return new ThrowErrorCheckRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ThrowErrorCheckRequest {
    return new ThrowErrorCheckRequest().fromJsonString(jsonString, options);
  }

  static equals(a: ThrowErrorCheckRequest | PlainMessage<ThrowErrorCheckRequest> | undefined, b: ThrowErrorCheckRequest | PlainMessage<ThrowErrorCheckRequest> | undefined): boolean {
    return proto3.util.equals(ThrowErrorCheckRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ThrowErrorCheckResponse
 */
export class ThrowErrorCheckResponse extends Message<ThrowErrorCheckResponse> {
  constructor(data?: PartialMessage<ThrowErrorCheckResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ThrowErrorCheckResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ThrowErrorCheckResponse {
    return new ThrowErrorCheckResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ThrowErrorCheckResponse {
    return new ThrowErrorCheckResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ThrowErrorCheckResponse {
    return new ThrowErrorCheckResponse().fromJsonString(jsonString, options);
  }

  static equals(a: ThrowErrorCheckResponse | PlainMessage<ThrowErrorCheckResponse> | undefined, b: ThrowErrorCheckResponse | PlainMessage<ThrowErrorCheckResponse> | undefined): boolean {
    return proto3.util.equals(ThrowErrorCheckResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ErrorDetails
 */
export class ErrorDetails extends Message<ErrorDetails> {
  /**
   * @generated from field: aiserver.v1.ErrorDetails.Error error = 1;
   */
  error = ErrorDetails_Error.UNSPECIFIED;

  constructor(data?: PartialMessage<ErrorDetails>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ErrorDetails";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "error", kind: "enum", T: proto3.getEnumType(ErrorDetails_Error) },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ErrorDetails {
    return new ErrorDetails().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ErrorDetails {
    return new ErrorDetails().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ErrorDetails {
    return new ErrorDetails().fromJsonString(jsonString, options);
  }

  static equals(a: ErrorDetails | PlainMessage<ErrorDetails> | undefined, b: ErrorDetails | PlainMessage<ErrorDetails> | undefined): boolean {
    return proto3.util.equals(ErrorDetails, a, b);
  }
}

/**
 * We have more specific error types than hose handled by grpc when necessary
 *
 * @generated from enum aiserver.v1.ErrorDetails.Error
 */
export enum ErrorDetails_Error {
  /**
   * @generated from enum value: ERROR_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * These are the 400 error subtypes
   * Not a valid openai api key
   *
   * @generated from enum value: ERROR_BAD_API_KEY = 1;
   */
  BAD_API_KEY = 1,

  /**
   * These are the 401 errors
   * Not logged in (and no key provided)
   *
   * @generated from enum value: ERROR_NOT_LOGGED_IN = 2;
   */
  NOT_LOGGED_IN = 2,

  /**
   * Not a valid auth id
   *
   * @generated from enum value: ERROR_INVALID_AUTH_ID = 3;
   */
  INVALID_AUTH_ID = 3,

  /**
   * Not high enough permissions (not paying)
   *
   * @generated from enum value: ERROR_NOT_HIGH_ENOUGH_PERMISSIONS = 4;
   */
  NOT_HIGH_ENOUGH_PERMISSIONS = 4,

  /**
   * LOGIN_NEEDED_FOR_TASKS
   *
   * @generated from enum value: ERROR_AGENT_REQUIRES_LOGIN = 18;
   */
  AGENT_REQUIRES_LOGIN = 18,

  /**
   * 404 error subtypes
   * Model not found
   *
   * @generated from enum value: ERROR_BAD_MODEL_NAME = 5;
   */
  BAD_MODEL_NAME = 5,

  /**
   * User not found
   *
   * @generated from enum value: ERROR_USER_NOT_FOUND = 6;
   */
  USER_NOT_FOUND = 6,

  /**
   * 429 error subtypes
   *  Free user requesting too many completions in a minute
   *
   * @generated from enum value: ERROR_FREE_USER_RATE_LIMIT_EXCEEDED = 7;
   */
  FREE_USER_RATE_LIMIT_EXCEEDED = 7,

  /**
   * Pro user requesting too many completions in a minute
   *
   * @generated from enum value: ERROR_PRO_USER_RATE_LIMIT_EXCEEDED = 8;
   */
  PRO_USER_RATE_LIMIT_EXCEEDED = 8,

  /**
   * Usage limit exceeded for free user for the given model
   *
   * @generated from enum value: ERROR_FREE_USER_USAGE_LIMIT = 9;
   */
  FREE_USER_USAGE_LIMIT = 9,

  /**
   * Usage limit exceeded for pro user for the given model
   *
   * @generated from enum value: ERROR_PRO_USER_USAGE_LIMIT = 10;
   */
  PRO_USER_USAGE_LIMIT = 10,

  /**
   * Back to 401 errors
   * Access token not found
   *
   * @generated from enum value: ERROR_AUTH_TOKEN_NOT_FOUND = 11;
   */
  AUTH_TOKEN_NOT_FOUND = 11,

  /**
   * @generated from enum value: ERROR_AUTH_TOKEN_EXPIRED = 12;
   */
  AUTH_TOKEN_EXPIRED = 12,

  /**
   * OpenAI errors
   *
   * @generated from enum value: ERROR_OPENAI = 13;
   */
  OPENAI = 13,

  /**
   * 429 Openai Error
   *
   * @generated from enum value: ERROR_OPENAI_RATE_LIMIT_EXCEEDED = 14;
   */
  OPENAI_RATE_LIMIT_EXCEEDED = 14,

  /**
   * 429 Account error
   *
   * @generated from enum value: ERROR_OPENAI_ACCOUNT_LIMIT_EXCEEDED = 15;
   */
  OPENAI_ACCOUNT_LIMIT_EXCEEDED = 15,

  /**
   * Task runner errors
   *
   * @generated from enum value: ERROR_TASK_UUID_NOT_FOUND = 16;
   */
  TASK_UUID_NOT_FOUND = 16,

  /**
   * @generated from enum value: ERROR_TASK_NO_PERMISSIONS = 17;
   */
  TASK_NO_PERMISSIONS = 17,

  /**
   * @generated from enum value: ERROR_AGENT_ENGINE_NOT_FOUND = 19;
   */
  AGENT_ENGINE_NOT_FOUND = 19,

  /**
   * @generated from enum value: ERROR_MAX_TOKENS = 20;
   */
  MAX_TOKENS = 20,

  /**
   * @generated from enum value: ERROR_USER_ABORTED_REQUEST = 21;
   */
  USER_ABORTED_REQUEST = 21,
}
// Retrieve enum metadata with: proto3.getEnumType(ErrorDetails_Error)
proto3.util.setEnumType(ErrorDetails_Error, "aiserver.v1.ErrorDetails.Error", [
  { no: 0, name: "ERROR_UNSPECIFIED" },
  { no: 1, name: "ERROR_BAD_API_KEY" },
  { no: 2, name: "ERROR_NOT_LOGGED_IN" },
  { no: 3, name: "ERROR_INVALID_AUTH_ID" },
  { no: 4, name: "ERROR_NOT_HIGH_ENOUGH_PERMISSIONS" },
  { no: 18, name: "ERROR_AGENT_REQUIRES_LOGIN" },
  { no: 5, name: "ERROR_BAD_MODEL_NAME" },
  { no: 6, name: "ERROR_USER_NOT_FOUND" },
  { no: 7, name: "ERROR_FREE_USER_RATE_LIMIT_EXCEEDED" },
  { no: 8, name: "ERROR_PRO_USER_RATE_LIMIT_EXCEEDED" },
  { no: 9, name: "ERROR_FREE_USER_USAGE_LIMIT" },
  { no: 10, name: "ERROR_PRO_USER_USAGE_LIMIT" },
  { no: 11, name: "ERROR_AUTH_TOKEN_NOT_FOUND" },
  { no: 12, name: "ERROR_AUTH_TOKEN_EXPIRED" },
  { no: 13, name: "ERROR_OPENAI" },
  { no: 14, name: "ERROR_OPENAI_RATE_LIMIT_EXCEEDED" },
  { no: 15, name: "ERROR_OPENAI_ACCOUNT_LIMIT_EXCEEDED" },
  { no: 16, name: "ERROR_TASK_UUID_NOT_FOUND" },
  { no: 17, name: "ERROR_TASK_NO_PERMISSIONS" },
  { no: 19, name: "ERROR_AGENT_ENGINE_NOT_FOUND" },
  { no: 20, name: "ERROR_MAX_TOKENS" },
  { no: 21, name: "ERROR_USER_ABORTED_REQUEST" },
]);

/**
 * @generated from message aiserver.v1.HealthCheckRequest
 */
export class HealthCheckRequest extends Message<HealthCheckRequest> {
  constructor(data?: PartialMessage<HealthCheckRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.HealthCheckRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): HealthCheckRequest {
    return new HealthCheckRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): HealthCheckRequest {
    return new HealthCheckRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): HealthCheckRequest {
    return new HealthCheckRequest().fromJsonString(jsonString, options);
  }

  static equals(a: HealthCheckRequest | PlainMessage<HealthCheckRequest> | undefined, b: HealthCheckRequest | PlainMessage<HealthCheckRequest> | undefined): boolean {
    return proto3.util.equals(HealthCheckRequest, a, b);
  }
}

/**
 * the health check always responds with Healthy if healthy
 * if unhealthy, we respond with a 503 status code
 *
 * @generated from message aiserver.v1.HealthCheckResponse
 */
export class HealthCheckResponse extends Message<HealthCheckResponse> {
  /**
   * @generated from field: aiserver.v1.HealthCheckResponse.Status status = 1;
   */
  status = HealthCheckResponse_Status.UNSPECIFIED;

  constructor(data?: PartialMessage<HealthCheckResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.HealthCheckResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "status", kind: "enum", T: proto3.getEnumType(HealthCheckResponse_Status) },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): HealthCheckResponse {
    return new HealthCheckResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): HealthCheckResponse {
    return new HealthCheckResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): HealthCheckResponse {
    return new HealthCheckResponse().fromJsonString(jsonString, options);
  }

  static equals(a: HealthCheckResponse | PlainMessage<HealthCheckResponse> | undefined, b: HealthCheckResponse | PlainMessage<HealthCheckResponse> | undefined): boolean {
    return proto3.util.equals(HealthCheckResponse, a, b);
  }
}

/**
 * @generated from enum aiserver.v1.HealthCheckResponse.Status
 */
export enum HealthCheckResponse_Status {
  /**
   * @generated from enum value: STATUS_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: STATUS_HEALTHY = 1;
   */
  HEALTHY = 1,
}
// Retrieve enum metadata with: proto3.getEnumType(HealthCheckResponse_Status)
proto3.util.setEnumType(HealthCheckResponse_Status, "aiserver.v1.HealthCheckResponse.Status", [
  { no: 0, name: "STATUS_UNSPECIFIED" },
  { no: 1, name: "STATUS_HEALTHY" },
]);

/**
 * @generated from message aiserver.v1.TimeLeftHealthCheckResponse
 */
export class TimeLeftHealthCheckResponse extends Message<TimeLeftHealthCheckResponse> {
  /**
   * @generated from field: string time_left = 1;
   */
  timeLeft = "";

  constructor(data?: PartialMessage<TimeLeftHealthCheckResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TimeLeftHealthCheckResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "time_left", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TimeLeftHealthCheckResponse {
    return new TimeLeftHealthCheckResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TimeLeftHealthCheckResponse {
    return new TimeLeftHealthCheckResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TimeLeftHealthCheckResponse {
    return new TimeLeftHealthCheckResponse().fromJsonString(jsonString, options);
  }

  static equals(a: TimeLeftHealthCheckResponse | PlainMessage<TimeLeftHealthCheckResponse> | undefined, b: TimeLeftHealthCheckResponse | PlainMessage<TimeLeftHealthCheckResponse> | undefined): boolean {
    return proto3.util.equals(TimeLeftHealthCheckResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ConversationMessage
 */
export class ConversationMessage extends Message<ConversationMessage> {
  /**
   * @generated from field: string text = 1;
   */
  text = "";

  /**
   * @generated from field: aiserver.v1.ConversationMessage.MessageType type = 2;
   */
  type = ConversationMessage_MessageType.UNSPECIFIED;

  /**
   * @generated from field: repeated aiserver.v1.ConversationMessage.CodeChunk attached_code_chunks = 3;
   */
  attachedCodeChunks: ConversationMessage_CodeChunk[] = [];

  /**
   * @generated from field: repeated aiserver.v1.CodeBlock codebase_context_chunks = 4;
   */
  codebaseContextChunks: CodeBlock[] = [];

  constructor(data?: PartialMessage<ConversationMessage>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ConversationMessage";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "type", kind: "enum", T: proto3.getEnumType(ConversationMessage_MessageType) },
    { no: 3, name: "attached_code_chunks", kind: "message", T: ConversationMessage_CodeChunk, repeated: true },
    { no: 4, name: "codebase_context_chunks", kind: "message", T: CodeBlock, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ConversationMessage {
    return new ConversationMessage().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ConversationMessage {
    return new ConversationMessage().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ConversationMessage {
    return new ConversationMessage().fromJsonString(jsonString, options);
  }

  static equals(a: ConversationMessage | PlainMessage<ConversationMessage> | undefined, b: ConversationMessage | PlainMessage<ConversationMessage> | undefined): boolean {
    return proto3.util.equals(ConversationMessage, a, b);
  }
}

/**
 * @generated from enum aiserver.v1.ConversationMessage.MessageType
 */
export enum ConversationMessage_MessageType {
  /**
   * @generated from enum value: MESSAGE_TYPE_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: MESSAGE_TYPE_HUMAN = 1;
   */
  HUMAN = 1,

  /**
   * @generated from enum value: MESSAGE_TYPE_AI = 2;
   */
  AI = 2,
}
// Retrieve enum metadata with: proto3.getEnumType(ConversationMessage_MessageType)
proto3.util.setEnumType(ConversationMessage_MessageType, "aiserver.v1.ConversationMessage.MessageType", [
  { no: 0, name: "MESSAGE_TYPE_UNSPECIFIED" },
  { no: 1, name: "MESSAGE_TYPE_HUMAN" },
  { no: 2, name: "MESSAGE_TYPE_AI" },
]);

/**
 * @generated from message aiserver.v1.ConversationMessage.CodeChunk
 */
export class ConversationMessage_CodeChunk extends Message<ConversationMessage_CodeChunk> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * the start_line is 1-indexed, and inclusive
   *
   * @generated from field: int32 start_line_number = 2;
   */
  startLineNumber = 0;

  /**
   * @generated from field: repeated string lines = 3;
   */
  lines: string[] = [];

  /**
   * @generated from field: optional aiserver.v1.ConversationMessage.CodeChunk.SummarizationStrategy summarization_strategy = 4;
   */
  summarizationStrategy?: ConversationMessage_CodeChunk_SummarizationStrategy;

  constructor(data?: PartialMessage<ConversationMessage_CodeChunk>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ConversationMessage.CodeChunk";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "start_line_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "lines", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 4, name: "summarization_strategy", kind: "enum", T: proto3.getEnumType(ConversationMessage_CodeChunk_SummarizationStrategy), opt: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ConversationMessage_CodeChunk {
    return new ConversationMessage_CodeChunk().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ConversationMessage_CodeChunk {
    return new ConversationMessage_CodeChunk().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ConversationMessage_CodeChunk {
    return new ConversationMessage_CodeChunk().fromJsonString(jsonString, options);
  }

  static equals(a: ConversationMessage_CodeChunk | PlainMessage<ConversationMessage_CodeChunk> | undefined, b: ConversationMessage_CodeChunk | PlainMessage<ConversationMessage_CodeChunk> | undefined): boolean {
    return proto3.util.equals(ConversationMessage_CodeChunk, a, b);
  }
}

/**
 * @generated from enum aiserver.v1.ConversationMessage.CodeChunk.SummarizationStrategy
 */
export enum ConversationMessage_CodeChunk_SummarizationStrategy {
  /**
   * @generated from enum value: SUMMARIZATION_STRATEGY_NONE_UNSPECIFIED = 0;
   */
  NONE_UNSPECIFIED = 0,

  /**
   * @generated from enum value: SUMMARIZATION_STRATEGY_SUMMARIZED = 1;
   */
  SUMMARIZED = 1,

  /**
   * @generated from enum value: SUMMARIZATION_STRATEGY_EMBEDDED = 2;
   */
  EMBEDDED = 2,
}
// Retrieve enum metadata with: proto3.getEnumType(ConversationMessage_CodeChunk_SummarizationStrategy)
proto3.util.setEnumType(ConversationMessage_CodeChunk_SummarizationStrategy, "aiserver.v1.ConversationMessage.CodeChunk.SummarizationStrategy", [
  { no: 0, name: "SUMMARIZATION_STRATEGY_NONE_UNSPECIFIED" },
  { no: 1, name: "SUMMARIZATION_STRATEGY_SUMMARIZED" },
  { no: 2, name: "SUMMARIZATION_STRATEGY_EMBEDDED" },
]);

/**
 * @generated from message aiserver.v1.StreamGenerateRequest
 */
export class StreamGenerateRequest extends Message<StreamGenerateRequest> {
  /**
   * @generated from field: aiserver.v1.CurrentFileInfo current_file = 1;
   */
  currentFile?: CurrentFileInfo;

  /**
   * @generated from field: repeated aiserver.v1.ConversationMessage conversation = 2;
   */
  conversation: ConversationMessage[] = [];

  /**
   * @generated from field: repeated aiserver.v1.RepositoryInfo repositories = 3;
   */
  repositories: RepositoryInfo[] = [];

  /**
   * @generated from field: aiserver.v1.ExplicitContext explicit_context = 4;
   */
  explicitContext?: ExplicitContext;

  /**
   * @generated from field: optional string workspace_root_path = 5;
   */
  workspaceRootPath?: string;

  /**
   * @generated from field: string query = 6;
   */
  query = "";

  /**
   * Other code blocks to add in
   *
   * @generated from field: repeated aiserver.v1.CodeBlock code_blocks = 7;
   */
  codeBlocks: CodeBlock[] = [];

  /**
   * What model to use and api key to use if applicable
   *
   * @generated from field: aiserver.v1.ModelDetails model_details = 9;
   */
  modelDetails?: ModelDetails;

  /**
   * @generated from field: repeated string documentation_identifiers = 10;
   */
  documentationIdentifiers: string[] = [];

  /**
   * @generated from field: aiserver.v1.LinterErrors linter_errors = 11;
   */
  linterErrors?: LinterErrors;

  /**
   * @generated from field: repeated aiserver.v1.CodeBlock prompt_code_blocks = 12;
   */
  promptCodeBlocks: CodeBlock[] = [];

  /**
   * the session ID is a uuid that is the same for all followups without closing
   * the cmd-k box
   *
   * @generated from field: string session_id = 14;
   */
  sessionId = "";

  /**
   * only sent up if the user has enabled the cmd-k debug info flag
   *
   * @generated from field: aiserver.v1.CmdKDebugInfo cmd_k_debug_info = 13;
   */
  cmdKDebugInfo?: CmdKDebugInfo;

  /**
   * if fast_mode is on, we try to use whatever is in the cache
   *
   * @generated from field: bool fast_mode = 15;
   */
  fastMode = false;

  /**
   * for followups, we send up the original request
   * the reason we send up the original request instead of just the text is that
   * we want as much caching to work as possible
   *
   * @generated from field: aiserver.v1.StreamGenerateRequest original_request = 16;
   */
  originalRequest?: StreamGenerateRequest;

  constructor(data?: PartialMessage<StreamGenerateRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamGenerateRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "current_file", kind: "message", T: CurrentFileInfo },
    { no: 2, name: "conversation", kind: "message", T: ConversationMessage, repeated: true },
    { no: 3, name: "repositories", kind: "message", T: RepositoryInfo, repeated: true },
    { no: 4, name: "explicit_context", kind: "message", T: ExplicitContext },
    { no: 5, name: "workspace_root_path", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 6, name: "query", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 7, name: "code_blocks", kind: "message", T: CodeBlock, repeated: true },
    { no: 9, name: "model_details", kind: "message", T: ModelDetails },
    { no: 10, name: "documentation_identifiers", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 11, name: "linter_errors", kind: "message", T: LinterErrors },
    { no: 12, name: "prompt_code_blocks", kind: "message", T: CodeBlock, repeated: true },
    { no: 14, name: "session_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 13, name: "cmd_k_debug_info", kind: "message", T: CmdKDebugInfo },
    { no: 15, name: "fast_mode", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 16, name: "original_request", kind: "message", T: StreamGenerateRequest },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamGenerateRequest {
    return new StreamGenerateRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamGenerateRequest {
    return new StreamGenerateRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamGenerateRequest {
    return new StreamGenerateRequest().fromJsonString(jsonString, options);
  }

  static equals(a: StreamGenerateRequest | PlainMessage<StreamGenerateRequest> | undefined, b: StreamGenerateRequest | PlainMessage<StreamGenerateRequest> | undefined): boolean {
    return proto3.util.equals(StreamGenerateRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamFastEditRequest
 */
export class StreamFastEditRequest extends Message<StreamFastEditRequest> {
  /**
   * @generated from field: aiserver.v1.CurrentFileInfo current_file = 1;
   */
  currentFile?: CurrentFileInfo;

  /**
   * @generated from field: repeated aiserver.v1.RepositoryInfo repositories = 3;
   */
  repositories: RepositoryInfo[] = [];

  /**
   * @generated from field: aiserver.v1.ExplicitContext explicit_context = 4;
   */
  explicitContext?: ExplicitContext;

  /**
   * @generated from field: optional string workspace_root_path = 5;
   */
  workspaceRootPath?: string;

  /**
   * @generated from field: string query = 6;
   */
  query = "";

  /**
   * Other code blocks to add in
   *
   * @generated from field: repeated aiserver.v1.CodeBlock code_blocks = 7;
   */
  codeBlocks: CodeBlock[] = [];

  /**
   * What model to use and api key to use if applicable
   *
   * @generated from field: aiserver.v1.ModelDetails model_details = 9;
   */
  modelDetails?: ModelDetails;

  /**
   * @generated from field: repeated string documentation_identifiers = 10;
   */
  documentationIdentifiers: string[] = [];

  /**
   * @generated from field: aiserver.v1.LinterErrors linter_errors = 11;
   */
  linterErrors?: LinterErrors;

  constructor(data?: PartialMessage<StreamFastEditRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamFastEditRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "current_file", kind: "message", T: CurrentFileInfo },
    { no: 3, name: "repositories", kind: "message", T: RepositoryInfo, repeated: true },
    { no: 4, name: "explicit_context", kind: "message", T: ExplicitContext },
    { no: 5, name: "workspace_root_path", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 6, name: "query", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 7, name: "code_blocks", kind: "message", T: CodeBlock, repeated: true },
    { no: 9, name: "model_details", kind: "message", T: ModelDetails },
    { no: 10, name: "documentation_identifiers", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 11, name: "linter_errors", kind: "message", T: LinterErrors },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamFastEditRequest {
    return new StreamFastEditRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamFastEditRequest {
    return new StreamFastEditRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamFastEditRequest {
    return new StreamFastEditRequest().fromJsonString(jsonString, options);
  }

  static equals(a: StreamFastEditRequest | PlainMessage<StreamFastEditRequest> | undefined, b: StreamFastEditRequest | PlainMessage<StreamFastEditRequest> | undefined): boolean {
    return proto3.util.equals(StreamFastEditRequest, a, b);
  }
}

/**
 * all line numbers refer to the old model
 *
 * @generated from message aiserver.v1.StreamFastEditResponse
 */
export class StreamFastEditResponse extends Message<StreamFastEditResponse> {
  /**
   * line number is 1-indexed
   *
   * @generated from field: int32 line_number = 2;
   */
  lineNumber = 0;

  /**
   * how many lines to replace. 0 means a pure insert
   *
   * @generated from field: int32 replace_num_lines = 3;
   */
  replaceNumLines = 0;

  /**
   * if the same edit uuid, then we are just updating the same edit
   *
   * @generated from field: string edit_uuid = 5;
   */
  editUuid = "";

  /**
   * @generated from field: optional bool done = 4;
   */
  done?: boolean;

  /**
   * @generated from field: optional string new_line = 6;
   */
  newLine?: string;

  /**
   * if this is true, then all previous new lines for this edit ID are removed,
   * and the diff is "restarted" this allows us to optimistically send up new
   * lines, and then remove them if we need to
   *
   * @generated from field: bool reset_new_lines = 7;
   */
  resetNewLines = false;

  constructor(data?: PartialMessage<StreamFastEditResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamFastEditResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 2, name: "line_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "replace_num_lines", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 5, name: "edit_uuid", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "done", kind: "scalar", T: 8 /* ScalarType.BOOL */, opt: true },
    { no: 6, name: "new_line", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 7, name: "reset_new_lines", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamFastEditResponse {
    return new StreamFastEditResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamFastEditResponse {
    return new StreamFastEditResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamFastEditResponse {
    return new StreamFastEditResponse().fromJsonString(jsonString, options);
  }

  static equals(a: StreamFastEditResponse | PlainMessage<StreamFastEditResponse> | undefined, b: StreamFastEditResponse | PlainMessage<StreamFastEditResponse> | undefined): boolean {
    return proto3.util.equals(StreamFastEditResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.CmdKDebugInfo
 */
export class CmdKDebugInfo extends Message<CmdKDebugInfo> {
  /**
   * we only support one remote URL for now. mostly internal
   *
   * @generated from field: string remote_url = 1;
   */
  remoteUrl = "";

  /**
   * @generated from field: string commit_id = 2;
   */
  commitId = "";

  /**
   * @generated from field: string git_patch = 3;
   */
  gitPatch = "";

  /**
   * @generated from field: repeated aiserver.v1.CmdKDebugInfo.UnsavedFiles unsaved_files = 4;
   */
  unsavedFiles: CmdKDebugInfo_UnsavedFiles[] = [];

  constructor(data?: PartialMessage<CmdKDebugInfo>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.CmdKDebugInfo";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "remote_url", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "commit_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "git_patch", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "unsaved_files", kind: "message", T: CmdKDebugInfo_UnsavedFiles, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): CmdKDebugInfo {
    return new CmdKDebugInfo().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): CmdKDebugInfo {
    return new CmdKDebugInfo().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): CmdKDebugInfo {
    return new CmdKDebugInfo().fromJsonString(jsonString, options);
  }

  static equals(a: CmdKDebugInfo | PlainMessage<CmdKDebugInfo> | undefined, b: CmdKDebugInfo | PlainMessage<CmdKDebugInfo> | undefined): boolean {
    return proto3.util.equals(CmdKDebugInfo, a, b);
  }
}

/**
 * @generated from message aiserver.v1.CmdKDebugInfo.UnsavedFiles
 */
export class CmdKDebugInfo_UnsavedFiles extends Message<CmdKDebugInfo_UnsavedFiles> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * @generated from field: string contents = 2;
   */
  contents = "";

  constructor(data?: PartialMessage<CmdKDebugInfo_UnsavedFiles>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.CmdKDebugInfo.UnsavedFiles";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "contents", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): CmdKDebugInfo_UnsavedFiles {
    return new CmdKDebugInfo_UnsavedFiles().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): CmdKDebugInfo_UnsavedFiles {
    return new CmdKDebugInfo_UnsavedFiles().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): CmdKDebugInfo_UnsavedFiles {
    return new CmdKDebugInfo_UnsavedFiles().fromJsonString(jsonString, options);
  }

  static equals(a: CmdKDebugInfo_UnsavedFiles | PlainMessage<CmdKDebugInfo_UnsavedFiles> | undefined, b: CmdKDebugInfo_UnsavedFiles | PlainMessage<CmdKDebugInfo_UnsavedFiles> | undefined): boolean {
    return proto3.util.equals(CmdKDebugInfo_UnsavedFiles, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamEditRequest
 */
export class StreamEditRequest extends Message<StreamEditRequest> {
  /**
   * @generated from field: aiserver.v1.CurrentFileInfo current_file = 1;
   */
  currentFile?: CurrentFileInfo;

  /**
   * @generated from field: repeated aiserver.v1.ConversationMessage conversation = 2;
   */
  conversation: ConversationMessage[] = [];

  /**
   * @generated from field: repeated aiserver.v1.RepositoryInfo repositories = 3;
   */
  repositories: RepositoryInfo[] = [];

  /**
   * @generated from field: aiserver.v1.ExplicitContext explicit_context = 4;
   */
  explicitContext?: ExplicitContext;

  /**
   * @generated from field: optional string workspace_root_path = 5;
   */
  workspaceRootPath?: string;

  /**
   * @generated from field: string query = 6;
   */
  query = "";

  /**
   * Other code blocks to add in
   *
   * @generated from field: repeated aiserver.v1.CodeBlock code_blocks = 7;
   */
  codeBlocks: CodeBlock[] = [];

  /**
   * What model to use and api key to use if applicable
   *
   * @generated from field: aiserver.v1.ModelDetails model_details = 9;
   */
  modelDetails?: ModelDetails;

  /**
   * @generated from field: repeated string documentation_identifiers = 10;
   */
  documentationIdentifiers: string[] = [];

  /**
   * @generated from field: aiserver.v1.LinterErrors linter_errors = 11;
   */
  linterErrors?: LinterErrors;

  /**
   * @generated from field: repeated aiserver.v1.CodeBlock prompt_code_blocks = 12;
   */
  promptCodeBlocks: CodeBlock[] = [];

  /**
   * the session ID is a uuid that is the same for all followups without closing
   * the cmd-k box
   *
   * @generated from field: string session_id = 14;
   */
  sessionId = "";

  /**
   * only sent up if the user has enabled the cmd-k debug info flag
   *
   * @generated from field: aiserver.v1.CmdKDebugInfo cmd_k_debug_info = 13;
   */
  cmdKDebugInfo?: CmdKDebugInfo;

  /**
   * if fast_mode is on, we try to use whatever is in the cache
   *
   * @generated from field: bool fast_mode = 15;
   */
  fastMode = false;

  /**
   * for followups, we send up the original request
   * the reason we send up the original request instead of just the text is that
   * we want as much caching to work as possible
   *
   * @generated from field: aiserver.v1.StreamEditRequest original_request = 16;
   */
  originalRequest?: StreamEditRequest;

  constructor(data?: PartialMessage<StreamEditRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamEditRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "current_file", kind: "message", T: CurrentFileInfo },
    { no: 2, name: "conversation", kind: "message", T: ConversationMessage, repeated: true },
    { no: 3, name: "repositories", kind: "message", T: RepositoryInfo, repeated: true },
    { no: 4, name: "explicit_context", kind: "message", T: ExplicitContext },
    { no: 5, name: "workspace_root_path", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 6, name: "query", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 7, name: "code_blocks", kind: "message", T: CodeBlock, repeated: true },
    { no: 9, name: "model_details", kind: "message", T: ModelDetails },
    { no: 10, name: "documentation_identifiers", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 11, name: "linter_errors", kind: "message", T: LinterErrors },
    { no: 12, name: "prompt_code_blocks", kind: "message", T: CodeBlock, repeated: true },
    { no: 14, name: "session_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 13, name: "cmd_k_debug_info", kind: "message", T: CmdKDebugInfo },
    { no: 15, name: "fast_mode", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 16, name: "original_request", kind: "message", T: StreamEditRequest },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamEditRequest {
    return new StreamEditRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamEditRequest {
    return new StreamEditRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamEditRequest {
    return new StreamEditRequest().fromJsonString(jsonString, options);
  }

  static equals(a: StreamEditRequest | PlainMessage<StreamEditRequest> | undefined, b: StreamEditRequest | PlainMessage<StreamEditRequest> | undefined): boolean {
    return proto3.util.equals(StreamEditRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.PreloadEditRequest
 */
export class PreloadEditRequest extends Message<PreloadEditRequest> {
  /**
   * TODO: eventually decouple maybe? idk things are messy
   *
   * @generated from field: aiserver.v1.StreamEditRequest req = 1;
   */
  req?: StreamEditRequest;

  constructor(data?: PartialMessage<PreloadEditRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.PreloadEditRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "req", kind: "message", T: StreamEditRequest },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): PreloadEditRequest {
    return new PreloadEditRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): PreloadEditRequest {
    return new PreloadEditRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): PreloadEditRequest {
    return new PreloadEditRequest().fromJsonString(jsonString, options);
  }

  static equals(a: PreloadEditRequest | PlainMessage<PreloadEditRequest> | undefined, b: PreloadEditRequest | PlainMessage<PreloadEditRequest> | undefined): boolean {
    return proto3.util.equals(PreloadEditRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.PreloadEditResponse
 */
export class PreloadEditResponse extends Message<PreloadEditResponse> {
  constructor(data?: PartialMessage<PreloadEditResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.PreloadEditResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): PreloadEditResponse {
    return new PreloadEditResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): PreloadEditResponse {
    return new PreloadEditResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): PreloadEditResponse {
    return new PreloadEditResponse().fromJsonString(jsonString, options);
  }

  static equals(a: PreloadEditResponse | PlainMessage<PreloadEditResponse> | undefined, b: PreloadEditResponse | PlainMessage<PreloadEditResponse> | undefined): boolean {
    return proto3.util.equals(PreloadEditResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamAiLintBugRequest
 */
export class StreamAiLintBugRequest extends Message<StreamAiLintBugRequest> {
  /**
   * TODO: it is possible that we always want to send up the files plus ranges.
   * then we need to be careful about cropping 10K-line files, though. and do
   * all the diff checking on the server for now, though, we just send up all
   * the chunks to analyze NOTE: these chunks may be quite long. In that case,
   * we may want to do some splitting on the server it is possible that we want
   * to store some kind of cache on the server for this, too, and instead just
   * send up files to analyze
   * TODO: ideally these should be semantically chunked? i.e. function bodies as
   * a whole, etc. this should be possible with code folding! and we should make
   * a service for this because it may be useful elsewhere too
   *
   * @generated from field: repeated aiserver.v1.StreamAiLintBugRequest.CodeChunk chunks_to_analyze = 1;
   */
  chunksToAnalyze: StreamAiLintBugRequest_CodeChunk[] = [];

  /**
   * @generated from field: aiserver.v1.ExplicitContext explicit_context = 4;
   */
  explicitContext?: ExplicitContext;

  /**
   * @generated from field: optional string workspace_root_path = 5;
   */
  workspaceRootPath?: string;

  /**
   * What model to use and api key to use if applicable
   * note that the linter doesn't use the model here. it just possibly needs the
   * api key
   *
   * @generated from field: aiserver.v1.ModelDetails model_details = 9;
   */
  modelDetails?: ModelDetails;

  /**
   * we do not want to re-generate dismissed bugs
   * we limit this list to the 100 or so dismissed bugs. probably that's enough
   *
   * @generated from field: repeated aiserver.v1.AiLintBug dismissed_bugs = 10;
   */
  dismissedBugs: AiLintBug[] = [];

  /**
   * if we do re-generate active bugs, we want to re-use the same uuid so that
   * they are auto-replaced
   *
   * @generated from field: repeated aiserver.v1.AiLintBug active_bugs = 11;
   */
  activeBugs: AiLintBug[] = [];

  /**
   * @generated from field: repeated aiserver.v1.AiLintRule lint_rules = 12;
   */
  lintRules: AiLintRule[] = [];

  /**
   * all references to all symbols in the affected chunk of code
   *
   * @generated from field: repeated aiserver.v1.StreamAiLintBugRequest.CodeChunkList clients = 14;
   */
  clients: StreamAiLintBugRequest_CodeChunkList[] = [];

  /**
   * @generated from field: repeated aiserver.v1.LintDiscriminator force_enable_discriminators = 17;
   */
  forceEnableDiscriminators: LintDiscriminator[] = [];

  /**
   * @generated from field: repeated aiserver.v1.LintDiscriminator force_disable_discriminators = 18;
   */
  forceDisableDiscriminators: LintDiscriminator[] = [];

  /**
   * @generated from field: repeated aiserver.v1.LintGenerator force_enable_generators = 19;
   */
  forceEnableGenerators: LintGenerator[] = [];

  /**
   * @generated from field: repeated aiserver.v1.LintGenerator force_disable_generators = 20;
   */
  forceDisableGenerators: LintGenerator[] = [];

  /**
   * @generated from field: int32 version = 21;
   */
  version = 0;

  /**
   * for debugging, we can turn off certain discriminators
   *
   * @generated from field: optional aiserver.v1.StreamAiLintBugRequest.DiscriminatorOptions discriminator_options = 15;
   */
  discriminatorOptions?: StreamAiLintBugRequest_DiscriminatorOptions;

  /**
   * ----- end of deprecated ------
   *
   * @generated from field: bool debug_mode = 16;
   */
  debugMode = false;

  constructor(data?: PartialMessage<StreamAiLintBugRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamAiLintBugRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "chunks_to_analyze", kind: "message", T: StreamAiLintBugRequest_CodeChunk, repeated: true },
    { no: 4, name: "explicit_context", kind: "message", T: ExplicitContext },
    { no: 5, name: "workspace_root_path", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 9, name: "model_details", kind: "message", T: ModelDetails },
    { no: 10, name: "dismissed_bugs", kind: "message", T: AiLintBug, repeated: true },
    { no: 11, name: "active_bugs", kind: "message", T: AiLintBug, repeated: true },
    { no: 12, name: "lint_rules", kind: "message", T: AiLintRule, repeated: true },
    { no: 14, name: "clients", kind: "message", T: StreamAiLintBugRequest_CodeChunkList, repeated: true },
    { no: 17, name: "force_enable_discriminators", kind: "enum", T: proto3.getEnumType(LintDiscriminator), repeated: true },
    { no: 18, name: "force_disable_discriminators", kind: "enum", T: proto3.getEnumType(LintDiscriminator), repeated: true },
    { no: 19, name: "force_enable_generators", kind: "enum", T: proto3.getEnumType(LintGenerator), repeated: true },
    { no: 20, name: "force_disable_generators", kind: "enum", T: proto3.getEnumType(LintGenerator), repeated: true },
    { no: 21, name: "version", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 15, name: "discriminator_options", kind: "message", T: StreamAiLintBugRequest_DiscriminatorOptions, opt: true },
    { no: 16, name: "debug_mode", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamAiLintBugRequest {
    return new StreamAiLintBugRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamAiLintBugRequest {
    return new StreamAiLintBugRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamAiLintBugRequest {
    return new StreamAiLintBugRequest().fromJsonString(jsonString, options);
  }

  static equals(a: StreamAiLintBugRequest | PlainMessage<StreamAiLintBugRequest> | undefined, b: StreamAiLintBugRequest | PlainMessage<StreamAiLintBugRequest> | undefined): boolean {
    return proto3.util.equals(StreamAiLintBugRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamAiLintBugRequest.CodeChunk
 */
export class StreamAiLintBugRequest_CodeChunk extends Message<StreamAiLintBugRequest_CodeChunk> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * the start_line is 1-indexed, and inclusive
   *
   * @generated from field: int32 start_line_number = 2;
   */
  startLineNumber = 0;

  /**
   * @generated from field: repeated string lines = 3;
   */
  lines: string[] = [];

  /**
   * we also send 10 context lines before and 10 context lines after since it
   * may be helpful
   *
   * @generated from field: repeated string context_lines_before = 4;
   */
  contextLinesBefore: string[] = [];

  /**
   * @generated from field: repeated string context_lines_after = 5;
   */
  contextLinesAfter: string[] = [];

  constructor(data?: PartialMessage<StreamAiLintBugRequest_CodeChunk>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamAiLintBugRequest.CodeChunk";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "start_line_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "lines", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 4, name: "context_lines_before", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 5, name: "context_lines_after", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamAiLintBugRequest_CodeChunk {
    return new StreamAiLintBugRequest_CodeChunk().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamAiLintBugRequest_CodeChunk {
    return new StreamAiLintBugRequest_CodeChunk().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamAiLintBugRequest_CodeChunk {
    return new StreamAiLintBugRequest_CodeChunk().fromJsonString(jsonString, options);
  }

  static equals(a: StreamAiLintBugRequest_CodeChunk | PlainMessage<StreamAiLintBugRequest_CodeChunk> | undefined, b: StreamAiLintBugRequest_CodeChunk | PlainMessage<StreamAiLintBugRequest_CodeChunk> | undefined): boolean {
    return proto3.util.equals(StreamAiLintBugRequest_CodeChunk, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamAiLintBugRequest.CodeChunkList
 */
export class StreamAiLintBugRequest_CodeChunkList extends Message<StreamAiLintBugRequest_CodeChunkList> {
  /**
   * @generated from field: repeated aiserver.v1.StreamAiLintBugRequest.CodeChunk chunks = 13;
   */
  chunks: StreamAiLintBugRequest_CodeChunk[] = [];

  /**
   * @generated from field: repeated int32 referred_start_lines = 14;
   */
  referredStartLines: number[] = [];

  /**
   * inclusive
   *
   * @generated from field: repeated int32 referred_end_lines = 15;
   */
  referredEndLines: number[] = [];

  constructor(data?: PartialMessage<StreamAiLintBugRequest_CodeChunkList>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamAiLintBugRequest.CodeChunkList";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 13, name: "chunks", kind: "message", T: StreamAiLintBugRequest_CodeChunk, repeated: true },
    { no: 14, name: "referred_start_lines", kind: "scalar", T: 5 /* ScalarType.INT32 */, repeated: true },
    { no: 15, name: "referred_end_lines", kind: "scalar", T: 5 /* ScalarType.INT32 */, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamAiLintBugRequest_CodeChunkList {
    return new StreamAiLintBugRequest_CodeChunkList().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamAiLintBugRequest_CodeChunkList {
    return new StreamAiLintBugRequest_CodeChunkList().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamAiLintBugRequest_CodeChunkList {
    return new StreamAiLintBugRequest_CodeChunkList().fromJsonString(jsonString, options);
  }

  static equals(a: StreamAiLintBugRequest_CodeChunkList | PlainMessage<StreamAiLintBugRequest_CodeChunkList> | undefined, b: StreamAiLintBugRequest_CodeChunkList | PlainMessage<StreamAiLintBugRequest_CodeChunkList> | undefined): boolean {
    return proto3.util.equals(StreamAiLintBugRequest_CodeChunkList, a, b);
  }
}

/**
 * ----- start of deprecated ------
 *
 * @generated from message aiserver.v1.StreamAiLintBugRequest.DiscriminatorOptions
 */
export class StreamAiLintBugRequest_DiscriminatorOptions extends Message<StreamAiLintBugRequest_DiscriminatorOptions> {
  /**
   * @generated from field: bool specific_rules = 1;
   */
  specificRules = false;

  /**
   * @generated from field: bool compile_errors = 2;
   */
  compileErrors = false;

  /**
   * @generated from field: bool change_behavior = 3;
   */
  changeBehavior = false;

  /**
   * @generated from field: bool match_code = 4;
   */
  matchCode = false;

  /**
   * @generated from field: bool relevance = 5;
   */
  relevance = false;

  /**
   * @generated from field: bool user_awareness = 6;
   */
  userAwareness = false;

  constructor(data?: PartialMessage<StreamAiLintBugRequest_DiscriminatorOptions>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamAiLintBugRequest.DiscriminatorOptions";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "specific_rules", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 2, name: "compile_errors", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 3, name: "change_behavior", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 4, name: "match_code", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 5, name: "relevance", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 6, name: "user_awareness", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamAiLintBugRequest_DiscriminatorOptions {
    return new StreamAiLintBugRequest_DiscriminatorOptions().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamAiLintBugRequest_DiscriminatorOptions {
    return new StreamAiLintBugRequest_DiscriminatorOptions().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamAiLintBugRequest_DiscriminatorOptions {
    return new StreamAiLintBugRequest_DiscriminatorOptions().fromJsonString(jsonString, options);
  }

  static equals(a: StreamAiLintBugRequest_DiscriminatorOptions | PlainMessage<StreamAiLintBugRequest_DiscriminatorOptions> | undefined, b: StreamAiLintBugRequest_DiscriminatorOptions | PlainMessage<StreamAiLintBugRequest_DiscriminatorOptions> | undefined): boolean {
    return proto3.util.equals(StreamAiLintBugRequest_DiscriminatorOptions, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamAiLintBugResponse
 */
export class StreamAiLintBugResponse extends Message<StreamAiLintBugResponse> {
  /**
   * @generated from oneof aiserver.v1.StreamAiLintBugResponse.response
   */
  response: {
    /**
     * @generated from field: aiserver.v1.AiLintBug bug = 1;
     */
    value: AiLintBug;
    case: "bug";
  } | {
    /**
     * the linter may decide to start a background task. we can attach to it
     * using the task Id this is used for more accurate involved bugs
     *
     * @generated from field: string background_task_uuid = 2;
     */
    value: string;
    case: "backgroundTaskUuid";
  } | { case: undefined; value?: undefined } = { case: undefined };

  constructor(data?: PartialMessage<StreamAiLintBugResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamAiLintBugResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "bug", kind: "message", T: AiLintBug, oneof: "response" },
    { no: 2, name: "background_task_uuid", kind: "scalar", T: 9 /* ScalarType.STRING */, oneof: "response" },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamAiLintBugResponse {
    return new StreamAiLintBugResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamAiLintBugResponse {
    return new StreamAiLintBugResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamAiLintBugResponse {
    return new StreamAiLintBugResponse().fromJsonString(jsonString, options);
  }

  static equals(a: StreamAiLintBugResponse | PlainMessage<StreamAiLintBugResponse> | undefined, b: StreamAiLintBugResponse | PlainMessage<StreamAiLintBugResponse> | undefined): boolean {
    return proto3.util.equals(StreamAiLintBugResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.LogUserLintReplyRequest
 */
export class LogUserLintReplyRequest extends Message<LogUserLintReplyRequest> {
  /**
   * @generated from field: string uuid = 1;
   */
  uuid = "";

  /**
   * @generated from field: string user_action = 2;
   */
  userAction = "";

  /**
   * @generated from field: bool debug_mode = 3;
   */
  debugMode = false;

  constructor(data?: PartialMessage<LogUserLintReplyRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.LogUserLintReplyRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "uuid", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "user_action", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "debug_mode", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): LogUserLintReplyRequest {
    return new LogUserLintReplyRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): LogUserLintReplyRequest {
    return new LogUserLintReplyRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): LogUserLintReplyRequest {
    return new LogUserLintReplyRequest().fromJsonString(jsonString, options);
  }

  static equals(a: LogUserLintReplyRequest | PlainMessage<LogUserLintReplyRequest> | undefined, b: LogUserLintReplyRequest | PlainMessage<LogUserLintReplyRequest> | undefined): boolean {
    return proto3.util.equals(LogUserLintReplyRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.LogUserLintReplyResponse
 */
export class LogUserLintReplyResponse extends Message<LogUserLintReplyResponse> {
  constructor(data?: PartialMessage<LogUserLintReplyResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.LogUserLintReplyResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): LogUserLintReplyResponse {
    return new LogUserLintReplyResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): LogUserLintReplyResponse {
    return new LogUserLintReplyResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): LogUserLintReplyResponse {
    return new LogUserLintReplyResponse().fromJsonString(jsonString, options);
  }

  static equals(a: LogUserLintReplyResponse | PlainMessage<LogUserLintReplyResponse> | undefined, b: LogUserLintReplyResponse | PlainMessage<LogUserLintReplyResponse> | undefined): boolean {
    return proto3.util.equals(LogUserLintReplyResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.LogLinterExplicitUserFeedbackRequest
 */
export class LogLinterExplicitUserFeedbackRequest extends Message<LogLinterExplicitUserFeedbackRequest> {
  /**
   * @generated from field: aiserver.v1.AiLintBug bug = 1;
   */
  bug?: AiLintBug;

  /**
   * @generated from field: aiserver.v1.LogLinterExplicitUserFeedbackRequest.LinterUserFeedback user_feedback = 3;
   */
  userFeedback = LogLinterExplicitUserFeedbackRequest_LinterUserFeedback.UNSPECIFIED;

  /**
   * @generated from field: string user_feedback_details = 4;
   */
  userFeedbackDetails = "";

  constructor(data?: PartialMessage<LogLinterExplicitUserFeedbackRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.LogLinterExplicitUserFeedbackRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "bug", kind: "message", T: AiLintBug },
    { no: 3, name: "user_feedback", kind: "enum", T: proto3.getEnumType(LogLinterExplicitUserFeedbackRequest_LinterUserFeedback) },
    { no: 4, name: "user_feedback_details", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): LogLinterExplicitUserFeedbackRequest {
    return new LogLinterExplicitUserFeedbackRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): LogLinterExplicitUserFeedbackRequest {
    return new LogLinterExplicitUserFeedbackRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): LogLinterExplicitUserFeedbackRequest {
    return new LogLinterExplicitUserFeedbackRequest().fromJsonString(jsonString, options);
  }

  static equals(a: LogLinterExplicitUserFeedbackRequest | PlainMessage<LogLinterExplicitUserFeedbackRequest> | undefined, b: LogLinterExplicitUserFeedbackRequest | PlainMessage<LogLinterExplicitUserFeedbackRequest> | undefined): boolean {
    return proto3.util.equals(LogLinterExplicitUserFeedbackRequest, a, b);
  }
}

/**
 * @generated from enum aiserver.v1.LogLinterExplicitUserFeedbackRequest.LinterUserFeedback
 */
export enum LogLinterExplicitUserFeedbackRequest_LinterUserFeedback {
  /**
   * @generated from enum value: LINTER_USER_FEEDBACK_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: LINTER_USER_FEEDBACK_CORRECT = 1;
   */
  CORRECT = 1,

  /**
   * @generated from enum value: LINTER_USER_FEEDBACK_INCORRECT = 2;
   */
  INCORRECT = 2,

  /**
   * @generated from enum value: LINTER_USER_FEEDBACK_OTHER = 3;
   */
  OTHER = 3,
}
// Retrieve enum metadata with: proto3.getEnumType(LogLinterExplicitUserFeedbackRequest_LinterUserFeedback)
proto3.util.setEnumType(LogLinterExplicitUserFeedbackRequest_LinterUserFeedback, "aiserver.v1.LogLinterExplicitUserFeedbackRequest.LinterUserFeedback", [
  { no: 0, name: "LINTER_USER_FEEDBACK_UNSPECIFIED" },
  { no: 1, name: "LINTER_USER_FEEDBACK_CORRECT" },
  { no: 2, name: "LINTER_USER_FEEDBACK_INCORRECT" },
  { no: 3, name: "LINTER_USER_FEEDBACK_OTHER" },
]);

/**
 * @generated from message aiserver.v1.LogLinterExplicitUserFeedbackResponse
 */
export class LogLinterExplicitUserFeedbackResponse extends Message<LogLinterExplicitUserFeedbackResponse> {
  constructor(data?: PartialMessage<LogLinterExplicitUserFeedbackResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.LogLinterExplicitUserFeedbackResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): LogLinterExplicitUserFeedbackResponse {
    return new LogLinterExplicitUserFeedbackResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): LogLinterExplicitUserFeedbackResponse {
    return new LogLinterExplicitUserFeedbackResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): LogLinterExplicitUserFeedbackResponse {
    return new LogLinterExplicitUserFeedbackResponse().fromJsonString(jsonString, options);
  }

  static equals(a: LogLinterExplicitUserFeedbackResponse | PlainMessage<LogLinterExplicitUserFeedbackResponse> | undefined, b: LogLinterExplicitUserFeedbackResponse | PlainMessage<LogLinterExplicitUserFeedbackResponse> | undefined): boolean {
    return proto3.util.equals(LogLinterExplicitUserFeedbackResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamNewRuleRequest
 */
export class StreamNewRuleRequest extends Message<StreamNewRuleRequest> {
  /**
   * @generated from field: string current_rules = 1;
   */
  currentRules = "";

  /**
   * @generated from field: string dismissed_bug = 2;
   */
  dismissedBug = "";

  constructor(data?: PartialMessage<StreamNewRuleRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamNewRuleRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "current_rules", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "dismissed_bug", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamNewRuleRequest {
    return new StreamNewRuleRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamNewRuleRequest {
    return new StreamNewRuleRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamNewRuleRequest {
    return new StreamNewRuleRequest().fromJsonString(jsonString, options);
  }

  static equals(a: StreamNewRuleRequest | PlainMessage<StreamNewRuleRequest> | undefined, b: StreamNewRuleRequest | PlainMessage<StreamNewRuleRequest> | undefined): boolean {
    return proto3.util.equals(StreamNewRuleRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamGPTFourEditRequest
 */
export class StreamGPTFourEditRequest extends Message<StreamGPTFourEditRequest> {
  /**
   * @generated from field: aiserver.v1.CurrentFileInfo current_file = 1;
   */
  currentFile?: CurrentFileInfo;

  /**
   * @generated from field: repeated aiserver.v1.ConversationMessage conversation = 2;
   */
  conversation: ConversationMessage[] = [];

  /**
   * @generated from field: repeated aiserver.v1.RepositoryInfo repositories = 3;
   */
  repositories: RepositoryInfo[] = [];

  /**
   * @generated from field: aiserver.v1.ExplicitContext explicit_context = 4;
   */
  explicitContext?: ExplicitContext;

  /**
   * @generated from field: optional string workspace_root_path = 5;
   */
  workspaceRootPath?: string;

  /**
   * @generated from field: string query = 6;
   */
  query = "";

  /**
   * Other code blocks to add in
   *
   * @generated from field: repeated aiserver.v1.CodeBlock code_blocks = 7;
   */
  codeBlocks: CodeBlock[] = [];

  /**
   * the session ID is a uuid that is the same for all followups without closing
   * the cmd-k box
   *
   * @generated from field: string session_id = 14;
   */
  sessionId = "";

  /**
   * What model to use and api key to use if applicable
   *
   * @generated from field: aiserver.v1.ModelDetails model_details = 9;
   */
  modelDetails?: ModelDetails;

  /**
   * @generated from field: repeated string documentation_identifiers = 10;
   */
  documentationIdentifiers: string[] = [];

  /**
   * @generated from field: aiserver.v1.LinterErrors linter_errors = 11;
   */
  linterErrors?: LinterErrors;

  /**
   * @generated from field: repeated aiserver.v1.CodeBlock prompt_code_blocks = 12;
   */
  promptCodeBlocks: CodeBlock[] = [];

  /**
   * @generated from field: bool fast_mode = 13;
   */
  fastMode = false;

  constructor(data?: PartialMessage<StreamGPTFourEditRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamGPTFourEditRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "current_file", kind: "message", T: CurrentFileInfo },
    { no: 2, name: "conversation", kind: "message", T: ConversationMessage, repeated: true },
    { no: 3, name: "repositories", kind: "message", T: RepositoryInfo, repeated: true },
    { no: 4, name: "explicit_context", kind: "message", T: ExplicitContext },
    { no: 5, name: "workspace_root_path", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 6, name: "query", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 7, name: "code_blocks", kind: "message", T: CodeBlock, repeated: true },
    { no: 14, name: "session_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 9, name: "model_details", kind: "message", T: ModelDetails },
    { no: 10, name: "documentation_identifiers", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 11, name: "linter_errors", kind: "message", T: LinterErrors },
    { no: 12, name: "prompt_code_blocks", kind: "message", T: CodeBlock, repeated: true },
    { no: 13, name: "fast_mode", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamGPTFourEditRequest {
    return new StreamGPTFourEditRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamGPTFourEditRequest {
    return new StreamGPTFourEditRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamGPTFourEditRequest {
    return new StreamGPTFourEditRequest().fromJsonString(jsonString, options);
  }

  static equals(a: StreamGPTFourEditRequest | PlainMessage<StreamGPTFourEditRequest> | undefined, b: StreamGPTFourEditRequest | PlainMessage<StreamGPTFourEditRequest> | undefined): boolean {
    return proto3.util.equals(StreamGPTFourEditRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamBackgroundEditRequest
 */
export class StreamBackgroundEditRequest extends Message<StreamBackgroundEditRequest> {
  /**
   * @generated from field: aiserver.v1.CurrentFileInfo current_file = 1;
   */
  currentFile?: CurrentFileInfo;

  /**
   * @generated from field: repeated aiserver.v1.RepositoryInfo repositories = 2;
   */
  repositories: RepositoryInfo[] = [];

  /**
   * @generated from field: aiserver.v1.ExplicitContext explicit_context = 3;
   */
  explicitContext?: ExplicitContext;

  /**
   * @generated from field: optional string workspace_root_path = 4;
   */
  workspaceRootPath?: string;

  /**
   * @generated from field: string git_diff = 5;
   */
  gitDiff = "";

  /**
   * @generated from field: repeated aiserver.v1.ConversationMessage conversation = 6;
   */
  conversation: ConversationMessage[] = [];

  /**
   * @generated from field: string query = 7;
   */
  query = "";

  /**
   * @generated from field: aiserver.v1.ModelDetails model_details = 8;
   */
  modelDetails?: ModelDetails;

  /**
   * @generated from field: string stop = 9;
   */
  stop = "";

  /**
   * @generated from field: int32 import_line_in_diff = 10;
   */
  importLineInDiff = 0;

  constructor(data?: PartialMessage<StreamBackgroundEditRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamBackgroundEditRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "current_file", kind: "message", T: CurrentFileInfo },
    { no: 2, name: "repositories", kind: "message", T: RepositoryInfo, repeated: true },
    { no: 3, name: "explicit_context", kind: "message", T: ExplicitContext },
    { no: 4, name: "workspace_root_path", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 5, name: "git_diff", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 6, name: "conversation", kind: "message", T: ConversationMessage, repeated: true },
    { no: 7, name: "query", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 8, name: "model_details", kind: "message", T: ModelDetails },
    { no: 9, name: "stop", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 10, name: "import_line_in_diff", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamBackgroundEditRequest {
    return new StreamBackgroundEditRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamBackgroundEditRequest {
    return new StreamBackgroundEditRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamBackgroundEditRequest {
    return new StreamBackgroundEditRequest().fromJsonString(jsonString, options);
  }

  static equals(a: StreamBackgroundEditRequest | PlainMessage<StreamBackgroundEditRequest> | undefined, b: StreamBackgroundEditRequest | PlainMessage<StreamBackgroundEditRequest> | undefined): boolean {
    return proto3.util.equals(StreamBackgroundEditRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.GetChatRequest
 */
export class GetChatRequest extends Message<GetChatRequest> {
  /**
   * @generated from field: aiserver.v1.CurrentFileInfo current_file = 1;
   */
  currentFile?: CurrentFileInfo;

  /**
   * the query to be answered is the last human message in the conversation
   *
   * @generated from field: repeated aiserver.v1.ConversationMessage conversation = 2;
   */
  conversation: ConversationMessage[] = [];

  /**
   * @generated from field: repeated aiserver.v1.RepositoryInfo repositories = 3;
   */
  repositories: RepositoryInfo[] = [];

  /**
   * @generated from field: aiserver.v1.ExplicitContext explicit_context = 4;
   */
  explicitContext?: ExplicitContext;

  /**
   * @generated from field: optional string workspace_root_path = 5;
   */
  workspaceRootPath?: string;

  /**
   * Other code blocks to add in
   *
   * @generated from field: repeated aiserver.v1.CodeBlock code_blocks = 6;
   */
  codeBlocks: CodeBlock[] = [];

  /**
   * What model to use and api key to use if applicable
   *
   * @generated from field: aiserver.v1.ModelDetails model_details = 7;
   */
  modelDetails?: ModelDetails;

  /**
   * @generated from field: repeated string documentation_identifiers = 8;
   */
  documentationIdentifiers: string[] = [];

  /**
   * the request_id is an identifier that's generated by the client for this
   * request in all client implementations this is a UUID we shouldn't rely on
   * it being a UUID on a server though, because a malicious client can send a
   * non-unique ID. hence we should only use it for debugging and logging
   * purposes
   *
   * @generated from field: string request_id = 9;
   */
  requestId = "";

  /**
   * @generated from field: aiserver.v1.LinterErrors linter_errors = 10;
   */
  linterErrors?: LinterErrors;

  /**
   * @generated from field: optional string summary = 11;
   */
  summary?: string;

  /**
   * @generated from field: optional int32 summary_up_until_index = 12;
   */
  summaryUpUntilIndex?: number;

  constructor(data?: PartialMessage<GetChatRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.GetChatRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "current_file", kind: "message", T: CurrentFileInfo },
    { no: 2, name: "conversation", kind: "message", T: ConversationMessage, repeated: true },
    { no: 3, name: "repositories", kind: "message", T: RepositoryInfo, repeated: true },
    { no: 4, name: "explicit_context", kind: "message", T: ExplicitContext },
    { no: 5, name: "workspace_root_path", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 6, name: "code_blocks", kind: "message", T: CodeBlock, repeated: true },
    { no: 7, name: "model_details", kind: "message", T: ModelDetails },
    { no: 8, name: "documentation_identifiers", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 9, name: "request_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 10, name: "linter_errors", kind: "message", T: LinterErrors },
    { no: 11, name: "summary", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 12, name: "summary_up_until_index", kind: "scalar", T: 5 /* ScalarType.INT32 */, opt: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GetChatRequest {
    return new GetChatRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GetChatRequest {
    return new GetChatRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GetChatRequest {
    return new GetChatRequest().fromJsonString(jsonString, options);
  }

  static equals(a: GetChatRequest | PlainMessage<GetChatRequest> | undefined, b: GetChatRequest | PlainMessage<GetChatRequest> | undefined): boolean {
    return proto3.util.equals(GetChatRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.CheckQueuePositionRequest
 */
export class CheckQueuePositionRequest extends Message<CheckQueuePositionRequest> {
  /**
   * @generated from field: string orig_request_id = 1;
   */
  origRequestId = "";

  /**
   * @generated from field: aiserver.v1.ModelDetails model_details = 2;
   */
  modelDetails?: ModelDetails;

  constructor(data?: PartialMessage<CheckQueuePositionRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.CheckQueuePositionRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "orig_request_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "model_details", kind: "message", T: ModelDetails },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): CheckQueuePositionRequest {
    return new CheckQueuePositionRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): CheckQueuePositionRequest {
    return new CheckQueuePositionRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): CheckQueuePositionRequest {
    return new CheckQueuePositionRequest().fromJsonString(jsonString, options);
  }

  static equals(a: CheckQueuePositionRequest | PlainMessage<CheckQueuePositionRequest> | undefined, b: CheckQueuePositionRequest | PlainMessage<CheckQueuePositionRequest> | undefined): boolean {
    return proto3.util.equals(CheckQueuePositionRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.CheckQueuePositionResponse
 */
export class CheckQueuePositionResponse extends Message<CheckQueuePositionResponse> {
  /**
   * @generated from field: int32 position = 1;
   */
  position = 0;

  constructor(data?: PartialMessage<CheckQueuePositionResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.CheckQueuePositionResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "position", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): CheckQueuePositionResponse {
    return new CheckQueuePositionResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): CheckQueuePositionResponse {
    return new CheckQueuePositionResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): CheckQueuePositionResponse {
    return new CheckQueuePositionResponse().fromJsonString(jsonString, options);
  }

  static equals(a: CheckQueuePositionResponse | PlainMessage<CheckQueuePositionResponse> | undefined, b: CheckQueuePositionResponse | PlainMessage<CheckQueuePositionResponse> | undefined): boolean {
    return proto3.util.equals(CheckQueuePositionResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.GetSimplePromptRequest
 */
export class GetSimplePromptRequest extends Message<GetSimplePromptRequest> {
  /**
   * @generated from field: string query = 1;
   */
  query = "";

  /**
   * @generated from field: string answer_placeholder = 2;
   */
  answerPlaceholder = "";

  constructor(data?: PartialMessage<GetSimplePromptRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.GetSimplePromptRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "query", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "answer_placeholder", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GetSimplePromptRequest {
    return new GetSimplePromptRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GetSimplePromptRequest {
    return new GetSimplePromptRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GetSimplePromptRequest {
    return new GetSimplePromptRequest().fromJsonString(jsonString, options);
  }

  static equals(a: GetSimplePromptRequest | PlainMessage<GetSimplePromptRequest> | undefined, b: GetSimplePromptRequest | PlainMessage<GetSimplePromptRequest> | undefined): boolean {
    return proto3.util.equals(GetSimplePromptRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.GetSimplePromptResponse
 */
export class GetSimplePromptResponse extends Message<GetSimplePromptResponse> {
  /**
   * @generated from field: string result = 1;
   */
  result = "";

  constructor(data?: PartialMessage<GetSimplePromptResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.GetSimplePromptResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "result", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GetSimplePromptResponse {
    return new GetSimplePromptResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GetSimplePromptResponse {
    return new GetSimplePromptResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GetSimplePromptResponse {
    return new GetSimplePromptResponse().fromJsonString(jsonString, options);
  }

  static equals(a: GetSimplePromptResponse | PlainMessage<GetSimplePromptResponse> | undefined, b: GetSimplePromptResponse | PlainMessage<GetSimplePromptResponse> | undefined): boolean {
    return proto3.util.equals(GetSimplePromptResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.GetEvaluationPromptRequest
 */
export class GetEvaluationPromptRequest extends Message<GetEvaluationPromptRequest> {
  /**
   * @generated from field: aiserver.v1.GetEvaluationPromptRequest.EvaluationPromptType prompt_type = 1;
   */
  promptType = GetEvaluationPromptRequest_EvaluationPromptType.UNSPECIFIED;

  /**
   * @generated from field: aiserver.v1.CurrentFileInfo current_file = 2;
   */
  currentFile?: CurrentFileInfo;

  /**
   * @generated from field: string query = 3;
   */
  query = "";

  /**
   * TODO: should this be the milvus ID or the bucket ID?
   *
   * @generated from field: string bucket_id = 4;
   */
  bucketId = "";

  /**
   * how to query the embedding index. see QueryStrategy in bucket_config.rs
   *
   * @generated from field: string query_strategy = 5;
   */
  queryStrategy = "";

  /**
   * defaults to 4K
   *
   * @generated from field: int32 token_limit = 6;
   */
  tokenLimit = 0;

  /**
   * @generated from field: aiserver.v1.GetEvaluationPromptRequest.RerankingStrategy reranking_strategy = 7;
   */
  rerankingStrategy = GetEvaluationPromptRequest_RerankingStrategy.UNSPECIFIED;

  constructor(data?: PartialMessage<GetEvaluationPromptRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.GetEvaluationPromptRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "prompt_type", kind: "enum", T: proto3.getEnumType(GetEvaluationPromptRequest_EvaluationPromptType) },
    { no: 2, name: "current_file", kind: "message", T: CurrentFileInfo },
    { no: 3, name: "query", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "bucket_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 5, name: "query_strategy", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 6, name: "token_limit", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 7, name: "reranking_strategy", kind: "enum", T: proto3.getEnumType(GetEvaluationPromptRequest_RerankingStrategy) },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GetEvaluationPromptRequest {
    return new GetEvaluationPromptRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GetEvaluationPromptRequest {
    return new GetEvaluationPromptRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GetEvaluationPromptRequest {
    return new GetEvaluationPromptRequest().fromJsonString(jsonString, options);
  }

  static equals(a: GetEvaluationPromptRequest | PlainMessage<GetEvaluationPromptRequest> | undefined, b: GetEvaluationPromptRequest | PlainMessage<GetEvaluationPromptRequest> | undefined): boolean {
    return proto3.util.equals(GetEvaluationPromptRequest, a, b);
  }
}

/**
 * @generated from enum aiserver.v1.GetEvaluationPromptRequest.EvaluationPromptType
 */
export enum GetEvaluationPromptRequest_EvaluationPromptType {
  /**
   * @generated from enum value: EVALUATION_PROMPT_TYPE_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: EVALUATION_PROMPT_TYPE_GENERATE = 1;
   */
  GENERATE = 1,

  /**
   * @generated from enum value: EVALUATION_PROMPT_TYPE_CHAT = 2;
   */
  CHAT = 2,
}
// Retrieve enum metadata with: proto3.getEnumType(GetEvaluationPromptRequest_EvaluationPromptType)
proto3.util.setEnumType(GetEvaluationPromptRequest_EvaluationPromptType, "aiserver.v1.GetEvaluationPromptRequest.EvaluationPromptType", [
  { no: 0, name: "EVALUATION_PROMPT_TYPE_UNSPECIFIED" },
  { no: 1, name: "EVALUATION_PROMPT_TYPE_GENERATE" },
  { no: 2, name: "EVALUATION_PROMPT_TYPE_CHAT" },
]);

/**
 * @generated from enum aiserver.v1.GetEvaluationPromptRequest.RerankingStrategy
 */
export enum GetEvaluationPromptRequest_RerankingStrategy {
  /**
   * @generated from enum value: RERANKING_STRATEGY_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: RERANKING_STRATEGY_DISTANCE_ONLY = 1;
   */
  DISTANCE_ONLY = 1,

  /**
   * @generated from enum value: RERANKING_STRATEGY_GPT4_RELEVANCE = 2;
   */
  GPT4_RELEVANCE = 2,
}
// Retrieve enum metadata with: proto3.getEnumType(GetEvaluationPromptRequest_RerankingStrategy)
proto3.util.setEnumType(GetEvaluationPromptRequest_RerankingStrategy, "aiserver.v1.GetEvaluationPromptRequest.RerankingStrategy", [
  { no: 0, name: "RERANKING_STRATEGY_UNSPECIFIED" },
  { no: 1, name: "RERANKING_STRATEGY_DISTANCE_ONLY" },
  { no: 2, name: "RERANKING_STRATEGY_GPT4_RELEVANCE" },
]);

/**
 * @generated from message aiserver.v1.GetEvaluationPromptResponse
 */
export class GetEvaluationPromptResponse extends Message<GetEvaluationPromptResponse> {
  /**
   * @generated from field: string prompt = 1;
   */
  prompt = "";

  /**
   * @generated from field: int32 token_count = 2;
   */
  tokenCount = 0;

  /**
   * @generated from field: int32 estimated_token_count = 3;
   */
  estimatedTokenCount = 0;

  constructor(data?: PartialMessage<GetEvaluationPromptResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.GetEvaluationPromptResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "prompt", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "token_count", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "estimated_token_count", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GetEvaluationPromptResponse {
    return new GetEvaluationPromptResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GetEvaluationPromptResponse {
    return new GetEvaluationPromptResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GetEvaluationPromptResponse {
    return new GetEvaluationPromptResponse().fromJsonString(jsonString, options);
  }

  static equals(a: GetEvaluationPromptResponse | PlainMessage<GetEvaluationPromptResponse> | undefined, b: GetEvaluationPromptResponse | PlainMessage<GetEvaluationPromptResponse> | undefined): boolean {
    return proto3.util.equals(GetEvaluationPromptResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamInlineEditsRequest
 */
export class StreamInlineEditsRequest extends Message<StreamInlineEditsRequest> {
  /**
   * @generated from field: aiserver.v1.CurrentFileInfo current_file = 1;
   */
  currentFile?: CurrentFileInfo;

  /**
   * @generated from field: string prompt = 2;
   */
  prompt = "";

  /**
   * @generated from field: repeated aiserver.v1.RepositoryInfo repositories = 3;
   */
  repositories: RepositoryInfo[] = [];

  /**
   * @generated from field: aiserver.v1.ExplicitContext explicit_context = 4;
   */
  explicitContext?: ExplicitContext;

  constructor(data?: PartialMessage<StreamInlineEditsRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamInlineEditsRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "current_file", kind: "message", T: CurrentFileInfo },
    { no: 2, name: "prompt", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "repositories", kind: "message", T: RepositoryInfo, repeated: true },
    { no: 4, name: "explicit_context", kind: "message", T: ExplicitContext },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamInlineEditsRequest {
    return new StreamInlineEditsRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamInlineEditsRequest {
    return new StreamInlineEditsRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamInlineEditsRequest {
    return new StreamInlineEditsRequest().fromJsonString(jsonString, options);
  }

  static equals(a: StreamInlineEditsRequest | PlainMessage<StreamInlineEditsRequest> | undefined, b: StreamInlineEditsRequest | PlainMessage<StreamInlineEditsRequest> | undefined): boolean {
    return proto3.util.equals(StreamInlineEditsRequest, a, b);
  }
}

/**
 * the range is streamed line by line
 *
 * @generated from message aiserver.v1.StreamInlineEditsResponse
 */
export class StreamInlineEditsResponse extends Message<StreamInlineEditsResponse> {
  /**
   * @generated from field: string line = 1;
   */
  line = "";

  /**
   * we return the prompt for debugging purposes
   * only if the debug-chat-prompt flag is set on the server
   *
   * @generated from field: optional string debugging_only_prompt = 2;
   */
  debuggingOnlyPrompt?: string;

  /**
   * @generated from field: optional int32 debugging_only_token_count = 3;
   */
  debuggingOnlyTokenCount?: number;

  constructor(data?: PartialMessage<StreamInlineEditsResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamInlineEditsResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "line", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "debugging_only_prompt", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 3, name: "debugging_only_token_count", kind: "scalar", T: 5 /* ScalarType.INT32 */, opt: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamInlineEditsResponse {
    return new StreamInlineEditsResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamInlineEditsResponse {
    return new StreamInlineEditsResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamInlineEditsResponse {
    return new StreamInlineEditsResponse().fromJsonString(jsonString, options);
  }

  static equals(a: StreamInlineEditsResponse | PlainMessage<StreamInlineEditsResponse> | undefined, b: StreamInlineEditsResponse | PlainMessage<StreamInlineEditsResponse> | undefined): boolean {
    return proto3.util.equals(StreamInlineEditsResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.SummarizeConversationResponse
 */
export class SummarizeConversationResponse extends Message<SummarizeConversationResponse> {
  /**
   * @generated from field: bool did_summarize = 1;
   */
  didSummarize = false;

  /**
   * @generated from field: int32 up_until_index = 2;
   */
  upUntilIndex = 0;

  /**
   * @generated from field: string summary = 3;
   */
  summary = "";

  constructor(data?: PartialMessage<SummarizeConversationResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.SummarizeConversationResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "did_summarize", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 2, name: "up_until_index", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "summary", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): SummarizeConversationResponse {
    return new SummarizeConversationResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): SummarizeConversationResponse {
    return new SummarizeConversationResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): SummarizeConversationResponse {
    return new SummarizeConversationResponse().fromJsonString(jsonString, options);
  }

  static equals(a: SummarizeConversationResponse | PlainMessage<SummarizeConversationResponse> | undefined, b: SummarizeConversationResponse | PlainMessage<SummarizeConversationResponse> | undefined): boolean {
    return proto3.util.equals(SummarizeConversationResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.GetChatTitleRequest
 */
export class GetChatTitleRequest extends Message<GetChatTitleRequest> {
  /**
   * @generated from field: repeated aiserver.v1.ConversationMessage conversation = 2;
   */
  conversation: ConversationMessage[] = [];

  constructor(data?: PartialMessage<GetChatTitleRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.GetChatTitleRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 2, name: "conversation", kind: "message", T: ConversationMessage, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GetChatTitleRequest {
    return new GetChatTitleRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GetChatTitleRequest {
    return new GetChatTitleRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GetChatTitleRequest {
    return new GetChatTitleRequest().fromJsonString(jsonString, options);
  }

  static equals(a: GetChatTitleRequest | PlainMessage<GetChatTitleRequest> | undefined, b: GetChatTitleRequest | PlainMessage<GetChatTitleRequest> | undefined): boolean {
    return proto3.util.equals(GetChatTitleRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.GetChatTitleResponse
 */
export class GetChatTitleResponse extends Message<GetChatTitleResponse> {
  /**
   * @generated from field: string title = 1;
   */
  title = "";

  constructor(data?: PartialMessage<GetChatTitleResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.GetChatTitleResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "title", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GetChatTitleResponse {
    return new GetChatTitleResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GetChatTitleResponse {
    return new GetChatTitleResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GetChatTitleResponse {
    return new GetChatTitleResponse().fromJsonString(jsonString, options);
  }

  static equals(a: GetChatTitleResponse | PlainMessage<GetChatTitleResponse> | undefined, b: GetChatTitleResponse | PlainMessage<GetChatTitleResponse> | undefined): boolean {
    return proto3.util.equals(GetChatTitleResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.GetChatPromptResponse
 */
export class GetChatPromptResponse extends Message<GetChatPromptResponse> {
  /**
   * @generated from field: string prompt = 1;
   */
  prompt = "";

  /**
   * @generated from field: int32 token_count = 2;
   */
  tokenCount = 0;

  constructor(data?: PartialMessage<GetChatPromptResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.GetChatPromptResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "prompt", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "token_count", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GetChatPromptResponse {
    return new GetChatPromptResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GetChatPromptResponse {
    return new GetChatPromptResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GetChatPromptResponse {
    return new GetChatPromptResponse().fromJsonString(jsonString, options);
  }

  static equals(a: GetChatPromptResponse | PlainMessage<GetChatPromptResponse> | undefined, b: GetChatPromptResponse | PlainMessage<GetChatPromptResponse> | undefined): boolean {
    return proto3.util.equals(GetChatPromptResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.DocumentationCitation
 */
export class DocumentationCitation extends Message<DocumentationCitation> {
  /**
   * @generated from field: repeated aiserver.v1.DocumentationChunk chunks = 1;
   */
  chunks: DocumentationChunk[] = [];

  constructor(data?: PartialMessage<DocumentationCitation>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.DocumentationCitation";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "chunks", kind: "message", T: DocumentationChunk, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): DocumentationCitation {
    return new DocumentationCitation().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): DocumentationCitation {
    return new DocumentationCitation().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): DocumentationCitation {
    return new DocumentationCitation().fromJsonString(jsonString, options);
  }

  static equals(a: DocumentationCitation | PlainMessage<DocumentationCitation> | undefined, b: DocumentationCitation | PlainMessage<DocumentationCitation> | undefined): boolean {
    return proto3.util.equals(DocumentationCitation, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamChatResponse
 */
export class StreamChatResponse extends Message<StreamChatResponse> {
  /**
   * @generated from field: string text = 1;
   */
  text = "";

  /**
   * we return the prompt for debugging purposes
   * only if the debug-chat-prompt flag is set on the server
   *
   * @generated from field: optional string debugging_only_chat_prompt = 2;
   */
  debuggingOnlyChatPrompt?: string;

  /**
   * @generated from field: optional int32 debugging_only_token_count = 3;
   */
  debuggingOnlyTokenCount?: number;

  /**
   * Return back cited documentation when applicable
   *
   * @generated from field: aiserver.v1.DocumentationCitation document_citation = 4;
   */
  documentCitation?: DocumentationCitation;

  /**
   * Also give back the prompt if possible
   *
   * @generated from field: optional string filled_prompt = 5;
   */
  filledPrompt?: string;

  /**
   * @generated from field: optional bool is_big_file = 6;
   */
  isBigFile?: boolean;

  /**
   * @generated from field: optional string intermediate_text = 7;
   */
  intermediateText?: string;

  /**
   * @generated from field: optional aiserver.v1.StreamChatResponse.ChunkIdentity chunk_identity = 8;
   */
  chunkIdentity?: StreamChatResponse_ChunkIdentity;

  constructor(data?: PartialMessage<StreamChatResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamChatResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "debugging_only_chat_prompt", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 3, name: "debugging_only_token_count", kind: "scalar", T: 5 /* ScalarType.INT32 */, opt: true },
    { no: 4, name: "document_citation", kind: "message", T: DocumentationCitation },
    { no: 5, name: "filled_prompt", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 6, name: "is_big_file", kind: "scalar", T: 8 /* ScalarType.BOOL */, opt: true },
    { no: 7, name: "intermediate_text", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 8, name: "chunk_identity", kind: "message", T: StreamChatResponse_ChunkIdentity, opt: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamChatResponse {
    return new StreamChatResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamChatResponse {
    return new StreamChatResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamChatResponse {
    return new StreamChatResponse().fromJsonString(jsonString, options);
  }

  static equals(a: StreamChatResponse | PlainMessage<StreamChatResponse> | undefined, b: StreamChatResponse | PlainMessage<StreamChatResponse> | undefined): boolean {
    return proto3.util.equals(StreamChatResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamChatResponse.ChunkIdentity
 */
export class StreamChatResponse_ChunkIdentity extends Message<StreamChatResponse_ChunkIdentity> {
  /**
   * @generated from field: string file_name = 1;
   */
  fileName = "";

  /**
   * @generated from field: int32 start_line = 2;
   */
  startLine = 0;

  /**
   * @generated from field: int32 end_line = 3;
   */
  endLine = 0;

  /**
   * @generated from field: string text = 4;
   */
  text = "";

  /**
   * @generated from field: aiserver.v1.ChunkType chunk_type = 5;
   */
  chunkType = ChunkType.UNSPECIFIED;

  constructor(data?: PartialMessage<StreamChatResponse_ChunkIdentity>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamChatResponse.ChunkIdentity";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "file_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "start_line", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "end_line", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 4, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 5, name: "chunk_type", kind: "enum", T: proto3.getEnumType(ChunkType) },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamChatResponse_ChunkIdentity {
    return new StreamChatResponse_ChunkIdentity().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamChatResponse_ChunkIdentity {
    return new StreamChatResponse_ChunkIdentity().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamChatResponse_ChunkIdentity {
    return new StreamChatResponse_ChunkIdentity().fromJsonString(jsonString, options);
  }

  static equals(a: StreamChatResponse_ChunkIdentity | PlainMessage<StreamChatResponse_ChunkIdentity> | undefined, b: StreamChatResponse_ChunkIdentity | PlainMessage<StreamChatResponse_ChunkIdentity> | undefined): boolean {
    return proto3.util.equals(StreamChatResponse_ChunkIdentity, a, b);
  }
}

/**
 * surrounding lines contains a few lines before and a few lines after (if they
 * exist) they are used in case the file syncing server is bad
 *
 * @generated from message aiserver.v1.SurroundingLines
 */
export class SurroundingLines extends Message<SurroundingLines> {
  /**
   * the start_line is 0-indexed
   *
   * @generated from field: int32 start_line = 1;
   */
  startLine = 0;

  /**
   * the content starts at the beginning of the start_line
   * the lines does NOT contain \n or \r\n
   *
   * @generated from field: repeated string lines = 2;
   */
  lines: string[] = [];

  constructor(data?: PartialMessage<SurroundingLines>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.SurroundingLines";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "start_line", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 2, name: "lines", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): SurroundingLines {
    return new SurroundingLines().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): SurroundingLines {
    return new SurroundingLines().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): SurroundingLines {
    return new SurroundingLines().fromJsonString(jsonString, options);
  }

  static equals(a: SurroundingLines | PlainMessage<SurroundingLines> | undefined, b: SurroundingLines | PlainMessage<SurroundingLines> | undefined): boolean {
    return proto3.util.equals(SurroundingLines, a, b);
  }
}

/**
 * @generated from message aiserver.v1.GetCompletionRequest
 */
export class GetCompletionRequest extends Message<GetCompletionRequest> {
  /**
   * TODO: transition this away from file identifier and into currentfile +
   * repositoryinfo?
   *
   * @generated from field: aiserver.v1.UniqueFileIdentifier file_identifier = 1;
   */
  fileIdentifier?: UniqueFileIdentifier;

  /**
   * @generated from field: aiserver.v1.CursorPosition cursor_position = 2;
   */
  cursorPosition?: CursorPosition;

  /**
   * @generated from field: aiserver.v1.SurroundingLines surrounding_lines = 3;
   */
  surroundingLines?: SurroundingLines;

  /**
   * @generated from field: aiserver.v1.ExplicitContext explicit_context = 4;
   */
  explicitContext?: ExplicitContext;

  /**
   * TODO: maybe this should also take in:
   * 1. the list of related tags to what the user is typing?
   * 2. the list of imports?
   * 3. trivially from tree sitter, all the mentions of a certain symbol on prev
   * lines in the file.
   *
   * @generated from field: repeated string suggestions_from_editor = 5;
   */
  suggestionsFromEditor: string[] = [];

  constructor(data?: PartialMessage<GetCompletionRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.GetCompletionRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "file_identifier", kind: "message", T: UniqueFileIdentifier },
    { no: 2, name: "cursor_position", kind: "message", T: CursorPosition },
    { no: 3, name: "surrounding_lines", kind: "message", T: SurroundingLines },
    { no: 4, name: "explicit_context", kind: "message", T: ExplicitContext },
    { no: 5, name: "suggestions_from_editor", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GetCompletionRequest {
    return new GetCompletionRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GetCompletionRequest {
    return new GetCompletionRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GetCompletionRequest {
    return new GetCompletionRequest().fromJsonString(jsonString, options);
  }

  static equals(a: GetCompletionRequest | PlainMessage<GetCompletionRequest> | undefined, b: GetCompletionRequest | PlainMessage<GetCompletionRequest> | undefined): boolean {
    return proto3.util.equals(GetCompletionRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.GetCompletionResponse
 */
export class GetCompletionResponse extends Message<GetCompletionResponse> {
  /**
   * the completion to insert at the current cursor_position
   * the local client should do some bracket matching magic
   *
   * @generated from field: string completion = 1;
   */
  completion = "";

  /**
   * score is between 0 and 1, 1 is best and 0 is worst
   *
   * @generated from field: float score = 2;
   */
  score = 0;

  /**
   * we return the completion_prompt for debugging purposes
   *
   * @generated from field: optional string debugging_only_completion_prompt = 3;
   */
  debuggingOnlyCompletionPrompt?: string;

  constructor(data?: PartialMessage<GetCompletionResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.GetCompletionResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "completion", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "score", kind: "scalar", T: 2 /* ScalarType.FLOAT */ },
    { no: 3, name: "debugging_only_completion_prompt", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GetCompletionResponse {
    return new GetCompletionResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GetCompletionResponse {
    return new GetCompletionResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GetCompletionResponse {
    return new GetCompletionResponse().fromJsonString(jsonString, options);
  }

  static equals(a: GetCompletionResponse | PlainMessage<GetCompletionResponse> | undefined, b: GetCompletionResponse | PlainMessage<GetCompletionResponse> | undefined): boolean {
    return proto3.util.equals(GetCompletionResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.GetSearchRequest
 */
export class GetSearchRequest extends Message<GetSearchRequest> {
  /**
   * @generated from field: string query = 1;
   */
  query = "";

  /**
   * @generated from field: repeated aiserver.v1.RepositoryInfo repositories = 2;
   */
  repositories: RepositoryInfo[] = [];

  /**
   * @generated from field: int32 top_k = 3;
   */
  topK = 0;

  /**
   * if not set, search all buckets
   *
   * @generated from field: repeated string restrict_to_buckets = 4;
   */
  restrictToBuckets: string[] = [];

  constructor(data?: PartialMessage<GetSearchRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.GetSearchRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "query", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "repositories", kind: "message", T: RepositoryInfo, repeated: true },
    { no: 3, name: "top_k", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 4, name: "restrict_to_buckets", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GetSearchRequest {
    return new GetSearchRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GetSearchRequest {
    return new GetSearchRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GetSearchRequest {
    return new GetSearchRequest().fromJsonString(jsonString, options);
  }

  static equals(a: GetSearchRequest | PlainMessage<GetSearchRequest> | undefined, b: GetSearchRequest | PlainMessage<GetSearchRequest> | undefined): boolean {
    return proto3.util.equals(GetSearchRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.FileSearchResult
 */
export class FileSearchResult extends Message<FileSearchResult> {
  /**
   * @generated from field: string repository_relative_workspace_path = 1;
   */
  repositoryRelativeWorkspacePath = "";

  /**
   * @generated from field: string file_relative_repository_path = 2;
   */
  fileRelativeRepositoryPath = "";

  /**
   * @generated from field: string chunk = 3;
   */
  chunk = "";

  /**
   * we always speak in terms of distances, wanting to minimize it
   * this currently assumes a distance (like L2) and not a similarity (like IP)
   *
   * @generated from field: float distance = 4;
   */
  distance = 0;

  constructor(data?: PartialMessage<FileSearchResult>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.FileSearchResult";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "repository_relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "file_relative_repository_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "chunk", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "distance", kind: "scalar", T: 2 /* ScalarType.FLOAT */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): FileSearchResult {
    return new FileSearchResult().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): FileSearchResult {
    return new FileSearchResult().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): FileSearchResult {
    return new FileSearchResult().fromJsonString(jsonString, options);
  }

  static equals(a: FileSearchResult | PlainMessage<FileSearchResult> | undefined, b: FileSearchResult | PlainMessage<FileSearchResult> | undefined): boolean {
    return proto3.util.equals(FileSearchResult, a, b);
  }
}

/**
 * @generated from message aiserver.v1.GetSearchResponse
 */
export class GetSearchResponse extends Message<GetSearchResponse> {
  /**
   * @generated from field: repeated aiserver.v1.FileSearchResult results = 1;
   */
  results: FileSearchResult[] = [];

  constructor(data?: PartialMessage<GetSearchResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.GetSearchResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "results", kind: "message", T: FileSearchResult, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GetSearchResponse {
    return new GetSearchResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GetSearchResponse {
    return new GetSearchResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GetSearchResponse {
    return new GetSearchResponse().fromJsonString(jsonString, options);
  }

  static equals(a: GetSearchResponse | PlainMessage<GetSearchResponse> | undefined, b: GetSearchResponse | PlainMessage<GetSearchResponse> | undefined): boolean {
    return proto3.util.equals(GetSearchResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.UniqueFileIdentifier
 */
export class UniqueFileIdentifier extends Message<UniqueFileIdentifier> {
  /**
   * project_uuid if often the same as a repo identifier
   *
   * @generated from field: string project_uuid = 1;
   */
  projectUuid = "";

  /**
   * the relative path is relative to the project root
   * it is NOT the relative path in a given VSCode workspace
   *
   * @generated from field: string relative_path = 2;
   */
  relativePath = "";

  /**
   * also include optional information about the language ID
   *
   * @generated from field: optional string language_id = 3;
   */
  languageId?: string;

  constructor(data?: PartialMessage<UniqueFileIdentifier>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.UniqueFileIdentifier";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "project_uuid", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "relative_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "language_id", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): UniqueFileIdentifier {
    return new UniqueFileIdentifier().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): UniqueFileIdentifier {
    return new UniqueFileIdentifier().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): UniqueFileIdentifier {
    return new UniqueFileIdentifier().fromJsonString(jsonString, options);
  }

  static equals(a: UniqueFileIdentifier | PlainMessage<UniqueFileIdentifier> | undefined, b: UniqueFileIdentifier | PlainMessage<UniqueFileIdentifier> | undefined): boolean {
    return proto3.util.equals(UniqueFileIdentifier, a, b);
  }
}

/**
 * authentication happens using token auth or cookie auth, so we should already
 * know the identity when we're here
 *
 * @generated from message aiserver.v1.GetUserInfoRequest
 */
export class GetUserInfoRequest extends Message<GetUserInfoRequest> {
  constructor(data?: PartialMessage<GetUserInfoRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.GetUserInfoRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GetUserInfoRequest {
    return new GetUserInfoRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GetUserInfoRequest {
    return new GetUserInfoRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GetUserInfoRequest {
    return new GetUserInfoRequest().fromJsonString(jsonString, options);
  }

  static equals(a: GetUserInfoRequest | PlainMessage<GetUserInfoRequest> | undefined, b: GetUserInfoRequest | PlainMessage<GetUserInfoRequest> | undefined): boolean {
    return proto3.util.equals(GetUserInfoRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.UsageData
 */
export class UsageData extends Message<UsageData> {
  /**
   * @generated from field: int32 gpt4_requests = 2;
   */
  gpt4Requests = 0;

  /**
   * @generated from field: int32 gpt4_max_requests = 3;
   */
  gpt4MaxRequests = 0;

  constructor(data?: PartialMessage<UsageData>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.UsageData";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 2, name: "gpt4_requests", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "gpt4_max_requests", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): UsageData {
    return new UsageData().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): UsageData {
    return new UsageData().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): UsageData {
    return new UsageData().fromJsonString(jsonString, options);
  }

  static equals(a: UsageData | PlainMessage<UsageData> | undefined, b: UsageData | PlainMessage<UsageData> | undefined): boolean {
    return proto3.util.equals(UsageData, a, b);
  }
}

/**
 * @generated from message aiserver.v1.GetUserInfoResponse
 */
export class GetUserInfoResponse extends Message<GetUserInfoResponse> {
  /**
   * @generated from field: string user_id = 1;
   */
  userId = "";

  /**
   * TODO: this is kind of Jupyter-specific, which is not great, but oh well.
   *
   * @generated from field: string jupyter_token = 2;
   */
  jupyterToken = "";

  /**
   * @generated from field: aiserver.v1.UsageData usage = 3;
   */
  usage?: UsageData;

  constructor(data?: PartialMessage<GetUserInfoResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.GetUserInfoResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "user_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "jupyter_token", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "usage", kind: "message", T: UsageData },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GetUserInfoResponse {
    return new GetUserInfoResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GetUserInfoResponse {
    return new GetUserInfoResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GetUserInfoResponse {
    return new GetUserInfoResponse().fromJsonString(jsonString, options);
  }

  static equals(a: GetUserInfoResponse | PlainMessage<GetUserInfoResponse> | undefined, b: GetUserInfoResponse | PlainMessage<GetUserInfoResponse> | undefined): boolean {
    return proto3.util.equals(GetUserInfoResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ClearAndRedoEntireBucketRequest
 */
export class ClearAndRedoEntireBucketRequest extends Message<ClearAndRedoEntireBucketRequest> {
  /**
   * @generated from field: string bucket_id = 1;
   */
  bucketId = "";

  /**
   * if a commit is specified, then that commit will be loaded into the bucket
   * if a commit is not specified, then the latest main branch of the repo will
   * be loaded instead
   *
   * @generated from field: optional string commit = 2;
   */
  commit?: string;

  constructor(data?: PartialMessage<ClearAndRedoEntireBucketRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ClearAndRedoEntireBucketRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "bucket_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "commit", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ClearAndRedoEntireBucketRequest {
    return new ClearAndRedoEntireBucketRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ClearAndRedoEntireBucketRequest {
    return new ClearAndRedoEntireBucketRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ClearAndRedoEntireBucketRequest {
    return new ClearAndRedoEntireBucketRequest().fromJsonString(jsonString, options);
  }

  static equals(a: ClearAndRedoEntireBucketRequest | PlainMessage<ClearAndRedoEntireBucketRequest> | undefined, b: ClearAndRedoEntireBucketRequest | PlainMessage<ClearAndRedoEntireBucketRequest> | undefined): boolean {
    return proto3.util.equals(ClearAndRedoEntireBucketRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ClearAndRedoEntireBucketResponse
 */
export class ClearAndRedoEntireBucketResponse extends Message<ClearAndRedoEntireBucketResponse> {
  constructor(data?: PartialMessage<ClearAndRedoEntireBucketResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ClearAndRedoEntireBucketResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ClearAndRedoEntireBucketResponse {
    return new ClearAndRedoEntireBucketResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ClearAndRedoEntireBucketResponse {
    return new ClearAndRedoEntireBucketResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ClearAndRedoEntireBucketResponse {
    return new ClearAndRedoEntireBucketResponse().fromJsonString(jsonString, options);
  }

  static equals(a: ClearAndRedoEntireBucketResponse | PlainMessage<ClearAndRedoEntireBucketResponse> | undefined, b: ClearAndRedoEntireBucketResponse | PlainMessage<ClearAndRedoEntireBucketResponse> | undefined): boolean {
    return proto3.util.equals(ClearAndRedoEntireBucketResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.DoThisForMeCheckRequest
 */
export class DoThisForMeCheckRequest extends Message<DoThisForMeCheckRequest> {
  /**
   * @generated from field: string generation_uuid = 1;
   */
  generationUuid = "";

  /**
   * @generated from field: string completion = 2;
   */
  completion = "";

  constructor(data?: PartialMessage<DoThisForMeCheckRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.DoThisForMeCheckRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "generation_uuid", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "completion", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): DoThisForMeCheckRequest {
    return new DoThisForMeCheckRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): DoThisForMeCheckRequest {
    return new DoThisForMeCheckRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): DoThisForMeCheckRequest {
    return new DoThisForMeCheckRequest().fromJsonString(jsonString, options);
  }

  static equals(a: DoThisForMeCheckRequest | PlainMessage<DoThisForMeCheckRequest> | undefined, b: DoThisForMeCheckRequest | PlainMessage<DoThisForMeCheckRequest> | undefined): boolean {
    return proto3.util.equals(DoThisForMeCheckRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.DoThisForMeCheckResponse
 */
export class DoThisForMeCheckResponse extends Message<DoThisForMeCheckResponse> {
  /**
   * @generated from oneof aiserver.v1.DoThisForMeCheckResponse.action
   */
  action: {
    /**
     * @generated from field: aiserver.v1.DoThisForMeCheckResponse.SkipAction skip_action = 1;
     */
    value: DoThisForMeCheckResponse_SkipAction;
    case: "skipAction";
  } | {
    /**
     * @generated from field: aiserver.v1.DoThisForMeCheckResponse.EditAction edit_action = 2;
     */
    value: DoThisForMeCheckResponse_EditAction;
    case: "editAction";
  } | {
    /**
     * @generated from field: aiserver.v1.DoThisForMeCheckResponse.CreateAction create_action = 3;
     */
    value: DoThisForMeCheckResponse_CreateAction;
    case: "createAction";
  } | {
    /**
     * @generated from field: aiserver.v1.DoThisForMeCheckResponse.RunAction run_action = 4;
     */
    value: DoThisForMeCheckResponse_RunAction;
    case: "runAction";
  } | { case: undefined; value?: undefined } = { case: undefined };

  /**
   * @generated from field: string reasoning = 5;
   */
  reasoning = "";

  constructor(data?: PartialMessage<DoThisForMeCheckResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.DoThisForMeCheckResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "skip_action", kind: "message", T: DoThisForMeCheckResponse_SkipAction, oneof: "action" },
    { no: 2, name: "edit_action", kind: "message", T: DoThisForMeCheckResponse_EditAction, oneof: "action" },
    { no: 3, name: "create_action", kind: "message", T: DoThisForMeCheckResponse_CreateAction, oneof: "action" },
    { no: 4, name: "run_action", kind: "message", T: DoThisForMeCheckResponse_RunAction, oneof: "action" },
    { no: 5, name: "reasoning", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): DoThisForMeCheckResponse {
    return new DoThisForMeCheckResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): DoThisForMeCheckResponse {
    return new DoThisForMeCheckResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): DoThisForMeCheckResponse {
    return new DoThisForMeCheckResponse().fromJsonString(jsonString, options);
  }

  static equals(a: DoThisForMeCheckResponse | PlainMessage<DoThisForMeCheckResponse> | undefined, b: DoThisForMeCheckResponse | PlainMessage<DoThisForMeCheckResponse> | undefined): boolean {
    return proto3.util.equals(DoThisForMeCheckResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.DoThisForMeCheckResponse.SkipAction
 */
export class DoThisForMeCheckResponse_SkipAction extends Message<DoThisForMeCheckResponse_SkipAction> {
  constructor(data?: PartialMessage<DoThisForMeCheckResponse_SkipAction>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.DoThisForMeCheckResponse.SkipAction";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): DoThisForMeCheckResponse_SkipAction {
    return new DoThisForMeCheckResponse_SkipAction().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): DoThisForMeCheckResponse_SkipAction {
    return new DoThisForMeCheckResponse_SkipAction().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): DoThisForMeCheckResponse_SkipAction {
    return new DoThisForMeCheckResponse_SkipAction().fromJsonString(jsonString, options);
  }

  static equals(a: DoThisForMeCheckResponse_SkipAction | PlainMessage<DoThisForMeCheckResponse_SkipAction> | undefined, b: DoThisForMeCheckResponse_SkipAction | PlainMessage<DoThisForMeCheckResponse_SkipAction> | undefined): boolean {
    return proto3.util.equals(DoThisForMeCheckResponse_SkipAction, a, b);
  }
}

/**
 * @generated from message aiserver.v1.DoThisForMeCheckResponse.EditAction
 */
export class DoThisForMeCheckResponse_EditAction extends Message<DoThisForMeCheckResponse_EditAction> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  constructor(data?: PartialMessage<DoThisForMeCheckResponse_EditAction>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.DoThisForMeCheckResponse.EditAction";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): DoThisForMeCheckResponse_EditAction {
    return new DoThisForMeCheckResponse_EditAction().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): DoThisForMeCheckResponse_EditAction {
    return new DoThisForMeCheckResponse_EditAction().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): DoThisForMeCheckResponse_EditAction {
    return new DoThisForMeCheckResponse_EditAction().fromJsonString(jsonString, options);
  }

  static equals(a: DoThisForMeCheckResponse_EditAction | PlainMessage<DoThisForMeCheckResponse_EditAction> | undefined, b: DoThisForMeCheckResponse_EditAction | PlainMessage<DoThisForMeCheckResponse_EditAction> | undefined): boolean {
    return proto3.util.equals(DoThisForMeCheckResponse_EditAction, a, b);
  }
}

/**
 * @generated from message aiserver.v1.DoThisForMeCheckResponse.CreateAction
 */
export class DoThisForMeCheckResponse_CreateAction extends Message<DoThisForMeCheckResponse_CreateAction> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  constructor(data?: PartialMessage<DoThisForMeCheckResponse_CreateAction>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.DoThisForMeCheckResponse.CreateAction";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): DoThisForMeCheckResponse_CreateAction {
    return new DoThisForMeCheckResponse_CreateAction().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): DoThisForMeCheckResponse_CreateAction {
    return new DoThisForMeCheckResponse_CreateAction().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): DoThisForMeCheckResponse_CreateAction {
    return new DoThisForMeCheckResponse_CreateAction().fromJsonString(jsonString, options);
  }

  static equals(a: DoThisForMeCheckResponse_CreateAction | PlainMessage<DoThisForMeCheckResponse_CreateAction> | undefined, b: DoThisForMeCheckResponse_CreateAction | PlainMessage<DoThisForMeCheckResponse_CreateAction> | undefined): boolean {
    return proto3.util.equals(DoThisForMeCheckResponse_CreateAction, a, b);
  }
}

/**
 * @generated from message aiserver.v1.DoThisForMeCheckResponse.RunAction
 */
export class DoThisForMeCheckResponse_RunAction extends Message<DoThisForMeCheckResponse_RunAction> {
  /**
   * @generated from field: string command = 1;
   */
  command = "";

  constructor(data?: PartialMessage<DoThisForMeCheckResponse_RunAction>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.DoThisForMeCheckResponse.RunAction";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "command", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): DoThisForMeCheckResponse_RunAction {
    return new DoThisForMeCheckResponse_RunAction().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): DoThisForMeCheckResponse_RunAction {
    return new DoThisForMeCheckResponse_RunAction().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): DoThisForMeCheckResponse_RunAction {
    return new DoThisForMeCheckResponse_RunAction().fromJsonString(jsonString, options);
  }

  static equals(a: DoThisForMeCheckResponse_RunAction | PlainMessage<DoThisForMeCheckResponse_RunAction> | undefined, b: DoThisForMeCheckResponse_RunAction | PlainMessage<DoThisForMeCheckResponse_RunAction> | undefined): boolean {
    return proto3.util.equals(DoThisForMeCheckResponse_RunAction, a, b);
  }
}

/**
 * @generated from message aiserver.v1.DoThisForMeRequest
 */
export class DoThisForMeRequest extends Message<DoThisForMeRequest> {
  /**
   * @generated from field: string generation_uuid = 1;
   */
  generationUuid = "";

  /**
   * @generated from field: string completion = 2;
   */
  completion = "";

  /**
   * @generated from field: aiserver.v1.DoThisForMeCheckResponse action = 3;
   */
  action?: DoThisForMeCheckResponse;

  constructor(data?: PartialMessage<DoThisForMeRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.DoThisForMeRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "generation_uuid", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "completion", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "action", kind: "message", T: DoThisForMeCheckResponse },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): DoThisForMeRequest {
    return new DoThisForMeRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): DoThisForMeRequest {
    return new DoThisForMeRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): DoThisForMeRequest {
    return new DoThisForMeRequest().fromJsonString(jsonString, options);
  }

  static equals(a: DoThisForMeRequest | PlainMessage<DoThisForMeRequest> | undefined, b: DoThisForMeRequest | PlainMessage<DoThisForMeRequest> | undefined): boolean {
    return proto3.util.equals(DoThisForMeRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.DoThisForMeResponse
 */
export class DoThisForMeResponse extends Message<DoThisForMeResponse> {
  /**
   * @generated from oneof aiserver.v1.DoThisForMeResponse.event
   */
  event: {
    /**
     * @generated from field: aiserver.v1.DoThisForMeResponse.UpdateStatus update_status = 1;
     */
    value: DoThisForMeResponse_UpdateStatus;
    case: "updateStatus";
  } | { case: undefined; value?: undefined } = { case: undefined };

  constructor(data?: PartialMessage<DoThisForMeResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.DoThisForMeResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "update_status", kind: "message", T: DoThisForMeResponse_UpdateStatus, oneof: "event" },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): DoThisForMeResponse {
    return new DoThisForMeResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): DoThisForMeResponse {
    return new DoThisForMeResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): DoThisForMeResponse {
    return new DoThisForMeResponse().fromJsonString(jsonString, options);
  }

  static equals(a: DoThisForMeResponse | PlainMessage<DoThisForMeResponse> | undefined, b: DoThisForMeResponse | PlainMessage<DoThisForMeResponse> | undefined): boolean {
    return proto3.util.equals(DoThisForMeResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.DoThisForMeResponse.UpdateStatus
 */
export class DoThisForMeResponse_UpdateStatus extends Message<DoThisForMeResponse_UpdateStatus> {
  /**
   * @generated from field: string status = 1;
   */
  status = "";

  constructor(data?: PartialMessage<DoThisForMeResponse_UpdateStatus>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.DoThisForMeResponse.UpdateStatus";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "status", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): DoThisForMeResponse_UpdateStatus {
    return new DoThisForMeResponse_UpdateStatus().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): DoThisForMeResponse_UpdateStatus {
    return new DoThisForMeResponse_UpdateStatus().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): DoThisForMeResponse_UpdateStatus {
    return new DoThisForMeResponse_UpdateStatus().fromJsonString(jsonString, options);
  }

  static equals(a: DoThisForMeResponse_UpdateStatus | PlainMessage<DoThisForMeResponse_UpdateStatus> | undefined, b: DoThisForMeResponse_UpdateStatus | PlainMessage<DoThisForMeResponse_UpdateStatus> | undefined): boolean {
    return proto3.util.equals(DoThisForMeResponse_UpdateStatus, a, b);
  }
}

/**
 * @generated from message aiserver.v1.DoThisForMeResponseWrapped
 */
export class DoThisForMeResponseWrapped extends Message<DoThisForMeResponseWrapped> {
  /**
   * @generated from oneof aiserver.v1.DoThisForMeResponseWrapped.response
   */
  response: {
    /**
     * @generated from field: aiserver.v1.DoThisForMeResponse real_response = 1;
     */
    value: DoThisForMeResponse;
    case: "realResponse";
  } | {
    /**
     * @generated from field: string background_task_uuid = 2;
     */
    value: string;
    case: "backgroundTaskUuid";
  } | { case: undefined; value?: undefined } = { case: undefined };

  constructor(data?: PartialMessage<DoThisForMeResponseWrapped>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.DoThisForMeResponseWrapped";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "real_response", kind: "message", T: DoThisForMeResponse, oneof: "response" },
    { no: 2, name: "background_task_uuid", kind: "scalar", T: 9 /* ScalarType.STRING */, oneof: "response" },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): DoThisForMeResponseWrapped {
    return new DoThisForMeResponseWrapped().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): DoThisForMeResponseWrapped {
    return new DoThisForMeResponseWrapped().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): DoThisForMeResponseWrapped {
    return new DoThisForMeResponseWrapped().fromJsonString(jsonString, options);
  }

  static equals(a: DoThisForMeResponseWrapped | PlainMessage<DoThisForMeResponseWrapped> | undefined, b: DoThisForMeResponseWrapped | PlainMessage<DoThisForMeResponseWrapped> | undefined): boolean {
    return proto3.util.equals(DoThisForMeResponseWrapped, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamChatToolformerContinueRequest
 */
export class StreamChatToolformerContinueRequest extends Message<StreamChatToolformerContinueRequest> {
  /**
   * the session ID identifies the session and lets the model continue from
   * where it was
   *
   * @generated from field: string toolformer_session_id = 1;
   */
  toolformerSessionId = "";

  /**
   * the continue request returns a tool_result formatted as a json
   * TODO: should this have builtin success/error codes? or should that be
   * handled per-tool?
   *
   * @generated from field: aiserver.v1.ToolResult tool_result = 2;
   */
  toolResult?: ToolResult;

  constructor(data?: PartialMessage<StreamChatToolformerContinueRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamChatToolformerContinueRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "toolformer_session_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "tool_result", kind: "message", T: ToolResult },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamChatToolformerContinueRequest {
    return new StreamChatToolformerContinueRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamChatToolformerContinueRequest {
    return new StreamChatToolformerContinueRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamChatToolformerContinueRequest {
    return new StreamChatToolformerContinueRequest().fromJsonString(jsonString, options);
  }

  static equals(a: StreamChatToolformerContinueRequest | PlainMessage<StreamChatToolformerContinueRequest> | undefined, b: StreamChatToolformerContinueRequest | PlainMessage<StreamChatToolformerContinueRequest> | undefined): boolean {
    return proto3.util.equals(StreamChatToolformerContinueRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamChatToolformerResponse
 */
export class StreamChatToolformerResponse extends Message<StreamChatToolformerResponse> {
  /**
   * @generated from field: optional string toolformer_session_id = 1;
   */
  toolformerSessionId?: string;

  /**
   * INVARIANT: there will be exactly one response with a tool_action, and it
   * will be the last message in the stream
   *
   * @generated from oneof aiserver.v1.StreamChatToolformerResponse.response_type
   */
  responseType: {
    /**
     * @generated from field: aiserver.v1.StreamChatToolformerResponse.Output output = 2;
     */
    value: StreamChatToolformerResponse_Output;
    case: "output";
  } | {
    /**
     * @generated from field: aiserver.v1.StreamChatToolformerResponse.ToolAction tool_action = 3;
     */
    value: StreamChatToolformerResponse_ToolAction;
    case: "toolAction";
  } | {
    /**
     * @generated from field: aiserver.v1.StreamChatToolformerResponse.Thought thought = 4;
     */
    value: StreamChatToolformerResponse_Thought;
    case: "thought";
  } | { case: undefined; value?: undefined } = { case: undefined };

  constructor(data?: PartialMessage<StreamChatToolformerResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamChatToolformerResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "toolformer_session_id", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 2, name: "output", kind: "message", T: StreamChatToolformerResponse_Output, oneof: "response_type" },
    { no: 3, name: "tool_action", kind: "message", T: StreamChatToolformerResponse_ToolAction, oneof: "response_type" },
    { no: 4, name: "thought", kind: "message", T: StreamChatToolformerResponse_Thought, oneof: "response_type" },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamChatToolformerResponse {
    return new StreamChatToolformerResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamChatToolformerResponse {
    return new StreamChatToolformerResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamChatToolformerResponse {
    return new StreamChatToolformerResponse().fromJsonString(jsonString, options);
  }

  static equals(a: StreamChatToolformerResponse | PlainMessage<StreamChatToolformerResponse> | undefined, b: StreamChatToolformerResponse | PlainMessage<StreamChatToolformerResponse> | undefined): boolean {
    return proto3.util.equals(StreamChatToolformerResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamChatToolformerResponse.Output
 */
export class StreamChatToolformerResponse_Output extends Message<StreamChatToolformerResponse_Output> {
  /**
   * @generated from field: string text = 1;
   */
  text = "";

  constructor(data?: PartialMessage<StreamChatToolformerResponse_Output>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamChatToolformerResponse.Output";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamChatToolformerResponse_Output {
    return new StreamChatToolformerResponse_Output().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamChatToolformerResponse_Output {
    return new StreamChatToolformerResponse_Output().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamChatToolformerResponse_Output {
    return new StreamChatToolformerResponse_Output().fromJsonString(jsonString, options);
  }

  static equals(a: StreamChatToolformerResponse_Output | PlainMessage<StreamChatToolformerResponse_Output> | undefined, b: StreamChatToolformerResponse_Output | PlainMessage<StreamChatToolformerResponse_Output> | undefined): boolean {
    return proto3.util.equals(StreamChatToolformerResponse_Output, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamChatToolformerResponse.Thought
 */
export class StreamChatToolformerResponse_Thought extends Message<StreamChatToolformerResponse_Thought> {
  /**
   * @generated from field: string text = 1;
   */
  text = "";

  constructor(data?: PartialMessage<StreamChatToolformerResponse_Thought>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamChatToolformerResponse.Thought";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamChatToolformerResponse_Thought {
    return new StreamChatToolformerResponse_Thought().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamChatToolformerResponse_Thought {
    return new StreamChatToolformerResponse_Thought().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamChatToolformerResponse_Thought {
    return new StreamChatToolformerResponse_Thought().fromJsonString(jsonString, options);
  }

  static equals(a: StreamChatToolformerResponse_Thought | PlainMessage<StreamChatToolformerResponse_Thought> | undefined, b: StreamChatToolformerResponse_Thought | PlainMessage<StreamChatToolformerResponse_Thought> | undefined): boolean {
    return proto3.util.equals(StreamChatToolformerResponse_Thought, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamChatToolformerResponse.ToolAction
 */
export class StreamChatToolformerResponse_ToolAction extends Message<StreamChatToolformerResponse_ToolAction> {
  /**
   * the user facing text is what to show the user
   *
   * @generated from field: string user_facing_text = 1;
   */
  userFacingText = "";

  /**
   * the raw model output is whatever is inside the <Action> tag. this is
   * needed for when the server forgets the conversation, and we want to make
   * sure the model does not get prior-ed into wrong tool use behavior
   *
   * @generated from field: string raw_model_output = 3;
   */
  rawModelOutput = "";

  /**
   * @generated from field: aiserver.v1.ToolCall tool_call = 2;
   */
  toolCall?: ToolCall;

  /**
   * whether the client should wait for another action before returning the
   * result
   *
   * @generated from field: bool more_to_come = 4;
   */
  moreToCome = false;

  constructor(data?: PartialMessage<StreamChatToolformerResponse_ToolAction>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamChatToolformerResponse.ToolAction";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "user_facing_text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "raw_model_output", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "tool_call", kind: "message", T: ToolCall },
    { no: 4, name: "more_to_come", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamChatToolformerResponse_ToolAction {
    return new StreamChatToolformerResponse_ToolAction().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamChatToolformerResponse_ToolAction {
    return new StreamChatToolformerResponse_ToolAction().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamChatToolformerResponse_ToolAction {
    return new StreamChatToolformerResponse_ToolAction().fromJsonString(jsonString, options);
  }

  static equals(a: StreamChatToolformerResponse_ToolAction | PlainMessage<StreamChatToolformerResponse_ToolAction> | undefined, b: StreamChatToolformerResponse_ToolAction | PlainMessage<StreamChatToolformerResponse_ToolAction> | undefined): boolean {
    return proto3.util.equals(StreamChatToolformerResponse_ToolAction, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskInstruction
 */
export class TaskInstruction extends Message<TaskInstruction> {
  /**
   * @generated from field: string text = 1;
   */
  text = "";

  /**
   * @generated from field: repeated aiserver.v1.TaskInstruction.CodeChunk attached_code_chunks = 2;
   */
  attachedCodeChunks: TaskInstruction_CodeChunk[] = [];

  /**
   * @generated from field: aiserver.v1.CurrentFileInfo current_file = 3;
   */
  currentFile?: CurrentFileInfo;

  /**
   * @generated from field: repeated aiserver.v1.RepositoryInfo repositories = 4;
   */
  repositories: RepositoryInfo[] = [];

  /**
   * @generated from field: aiserver.v1.ExplicitContext explicit_context = 5;
   */
  explicitContext?: ExplicitContext;

  constructor(data?: PartialMessage<TaskInstruction>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskInstruction";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "attached_code_chunks", kind: "message", T: TaskInstruction_CodeChunk, repeated: true },
    { no: 3, name: "current_file", kind: "message", T: CurrentFileInfo },
    { no: 4, name: "repositories", kind: "message", T: RepositoryInfo, repeated: true },
    { no: 5, name: "explicit_context", kind: "message", T: ExplicitContext },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskInstruction {
    return new TaskInstruction().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskInstruction {
    return new TaskInstruction().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskInstruction {
    return new TaskInstruction().fromJsonString(jsonString, options);
  }

  static equals(a: TaskInstruction | PlainMessage<TaskInstruction> | undefined, b: TaskInstruction | PlainMessage<TaskInstruction> | undefined): boolean {
    return proto3.util.equals(TaskInstruction, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskInstruction.CodeChunk
 */
export class TaskInstruction_CodeChunk extends Message<TaskInstruction_CodeChunk> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * the start_line is 1-indexed, and inclusive
   *
   * @generated from field: int32 start_line_number = 2;
   */
  startLineNumber = 0;

  /**
   * @generated from field: repeated string lines = 3;
   */
  lines: string[] = [];

  constructor(data?: PartialMessage<TaskInstruction_CodeChunk>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskInstruction.CodeChunk";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "start_line_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "lines", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskInstruction_CodeChunk {
    return new TaskInstruction_CodeChunk().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskInstruction_CodeChunk {
    return new TaskInstruction_CodeChunk().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskInstruction_CodeChunk {
    return new TaskInstruction_CodeChunk().fromJsonString(jsonString, options);
  }

  static equals(a: TaskInstruction_CodeChunk | PlainMessage<TaskInstruction_CodeChunk> | undefined, b: TaskInstruction_CodeChunk | PlainMessage<TaskInstruction_CodeChunk> | undefined): boolean {
    return proto3.util.equals(TaskInstruction_CodeChunk, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskUserMessage
 */
export class TaskUserMessage extends Message<TaskUserMessage> {
  /**
   * @generated from field: string text = 1;
   */
  text = "";

  /**
   * @generated from field: repeated aiserver.v1.TaskUserMessage.CodeChunk attached_code_chunks = 2;
   */
  attachedCodeChunks: TaskUserMessage_CodeChunk[] = [];

  constructor(data?: PartialMessage<TaskUserMessage>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskUserMessage";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "attached_code_chunks", kind: "message", T: TaskUserMessage_CodeChunk, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskUserMessage {
    return new TaskUserMessage().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskUserMessage {
    return new TaskUserMessage().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskUserMessage {
    return new TaskUserMessage().fromJsonString(jsonString, options);
  }

  static equals(a: TaskUserMessage | PlainMessage<TaskUserMessage> | undefined, b: TaskUserMessage | PlainMessage<TaskUserMessage> | undefined): boolean {
    return proto3.util.equals(TaskUserMessage, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskUserMessage.CodeChunk
 */
export class TaskUserMessage_CodeChunk extends Message<TaskUserMessage_CodeChunk> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * the start_line is 1-indexed, and inclusive
   *
   * @generated from field: int32 start_line_number = 2;
   */
  startLineNumber = 0;

  /**
   * @generated from field: repeated string lines = 3;
   */
  lines: string[] = [];

  constructor(data?: PartialMessage<TaskUserMessage_CodeChunk>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskUserMessage.CodeChunk";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "start_line_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "lines", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskUserMessage_CodeChunk {
    return new TaskUserMessage_CodeChunk().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskUserMessage_CodeChunk {
    return new TaskUserMessage_CodeChunk().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskUserMessage_CodeChunk {
    return new TaskUserMessage_CodeChunk().fromJsonString(jsonString, options);
  }

  static equals(a: TaskUserMessage_CodeChunk | PlainMessage<TaskUserMessage_CodeChunk> | undefined, b: TaskUserMessage_CodeChunk | PlainMessage<TaskUserMessage_CodeChunk> | undefined): boolean {
    return proto3.util.equals(TaskUserMessage_CodeChunk, a, b);
  }
}

/**
 * @generated from message aiserver.v1.CheckDoableAsTaskRequest
 */
export class CheckDoableAsTaskRequest extends Message<CheckDoableAsTaskRequest> {
  /**
   * @generated from field: string model_output = 1;
   */
  modelOutput = "";

  /**
   * @generated from field: aiserver.v1.ModelDetails model_details = 2;
   */
  modelDetails?: ModelDetails;

  constructor(data?: PartialMessage<CheckDoableAsTaskRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.CheckDoableAsTaskRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "model_output", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "model_details", kind: "message", T: ModelDetails },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): CheckDoableAsTaskRequest {
    return new CheckDoableAsTaskRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): CheckDoableAsTaskRequest {
    return new CheckDoableAsTaskRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): CheckDoableAsTaskRequest {
    return new CheckDoableAsTaskRequest().fromJsonString(jsonString, options);
  }

  static equals(a: CheckDoableAsTaskRequest | PlainMessage<CheckDoableAsTaskRequest> | undefined, b: CheckDoableAsTaskRequest | PlainMessage<CheckDoableAsTaskRequest> | undefined): boolean {
    return proto3.util.equals(CheckDoableAsTaskRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.CheckDoableAsTaskResponse
 */
export class CheckDoableAsTaskResponse extends Message<CheckDoableAsTaskResponse> {
  /**
   * @generated from field: bool doable_as_task = 1;
   */
  doableAsTask = false;

  constructor(data?: PartialMessage<CheckDoableAsTaskResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.CheckDoableAsTaskResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "doable_as_task", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): CheckDoableAsTaskResponse {
    return new CheckDoableAsTaskResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): CheckDoableAsTaskResponse {
    return new CheckDoableAsTaskResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): CheckDoableAsTaskResponse {
    return new CheckDoableAsTaskResponse().fromJsonString(jsonString, options);
  }

  static equals(a: CheckDoableAsTaskResponse | PlainMessage<CheckDoableAsTaskResponse> | undefined, b: CheckDoableAsTaskResponse | PlainMessage<CheckDoableAsTaskResponse> | undefined): boolean {
    return proto3.util.equals(CheckDoableAsTaskResponse, a, b);
  }
}

/**
 * TODO: figure out if we want this to just go directly into the taskInitRequest
 * or what doing that may make it easier o display the task... we'll see
 *
 * @generated from message aiserver.v1.InterfaceAgentInitRequest
 */
export class InterfaceAgentInitRequest extends Message<InterfaceAgentInitRequest> {
  /**
   * What model to use and api key to use if applicable
   *
   * @generated from field: aiserver.v1.ModelDetails model_details = 1;
   */
  modelDetails?: ModelDetails;

  /**
   * whether to enable priompt live mode
   *
   * @generated from field: bool debugging_only_live_mode = 2;
   */
  debuggingOnlyLiveMode = false;

  /**
   * @generated from field: aiserver.v1.InterfaceAgentClientState interface_agent_client_state = 3;
   */
  interfaceAgentClientState?: InterfaceAgentClientState;

  constructor(data?: PartialMessage<InterfaceAgentInitRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.InterfaceAgentInitRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "model_details", kind: "message", T: ModelDetails },
    { no: 2, name: "debugging_only_live_mode", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 3, name: "interface_agent_client_state", kind: "message", T: InterfaceAgentClientState },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): InterfaceAgentInitRequest {
    return new InterfaceAgentInitRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): InterfaceAgentInitRequest {
    return new InterfaceAgentInitRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): InterfaceAgentInitRequest {
    return new InterfaceAgentInitRequest().fromJsonString(jsonString, options);
  }

  static equals(a: InterfaceAgentInitRequest | PlainMessage<InterfaceAgentInitRequest> | undefined, b: InterfaceAgentInitRequest | PlainMessage<InterfaceAgentInitRequest> | undefined): boolean {
    return proto3.util.equals(InterfaceAgentInitRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.InterfaceAgentInitResponse
 */
export class InterfaceAgentInitResponse extends Message<InterfaceAgentInitResponse> {
  /**
   * this is the server-assigned task uuid that identifies the task
   *
   * @generated from field: string task_uuid = 1;
   */
  taskUuid = "";

  /**
   * the human readable title for the task!
   *
   * @generated from field: string human_readable_title = 2;
   */
  humanReadableTitle = "";

  constructor(data?: PartialMessage<InterfaceAgentInitResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.InterfaceAgentInitResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "task_uuid", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "human_readable_title", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): InterfaceAgentInitResponse {
    return new InterfaceAgentInitResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): InterfaceAgentInitResponse {
    return new InterfaceAgentInitResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): InterfaceAgentInitResponse {
    return new InterfaceAgentInitResponse().fromJsonString(jsonString, options);
  }

  static equals(a: InterfaceAgentInitResponse | PlainMessage<InterfaceAgentInitResponse> | undefined, b: InterfaceAgentInitResponse | PlainMessage<InterfaceAgentInitResponse> | undefined): boolean {
    return proto3.util.equals(InterfaceAgentInitResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamInterfaceAgentStatusRequest
 */
export class StreamInterfaceAgentStatusRequest extends Message<StreamInterfaceAgentStatusRequest> {
  /**
   * the server-assigned task uuid
   *
   * @generated from field: string task_uuid = 1;
   */
  taskUuid = "";

  constructor(data?: PartialMessage<StreamInterfaceAgentStatusRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamInterfaceAgentStatusRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "task_uuid", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamInterfaceAgentStatusRequest {
    return new StreamInterfaceAgentStatusRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamInterfaceAgentStatusRequest {
    return new StreamInterfaceAgentStatusRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamInterfaceAgentStatusRequest {
    return new StreamInterfaceAgentStatusRequest().fromJsonString(jsonString, options);
  }

  static equals(a: StreamInterfaceAgentStatusRequest | PlainMessage<StreamInterfaceAgentStatusRequest> | undefined, b: StreamInterfaceAgentStatusRequest | PlainMessage<StreamInterfaceAgentStatusRequest> | undefined): boolean {
    return proto3.util.equals(StreamInterfaceAgentStatusRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.StreamInterfaceAgentStatusResponse
 */
export class StreamInterfaceAgentStatusResponse extends Message<StreamInterfaceAgentStatusResponse> {
  /**
   * the current state of the interface agent
   *
   * @generated from field: aiserver.v1.InterfaceAgentStatus status = 1;
   */
  status?: InterfaceAgentStatus;

  constructor(data?: PartialMessage<StreamInterfaceAgentStatusResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamInterfaceAgentStatusResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "status", kind: "message", T: InterfaceAgentStatus },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamInterfaceAgentStatusResponse {
    return new StreamInterfaceAgentStatusResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamInterfaceAgentStatusResponse {
    return new StreamInterfaceAgentStatusResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamInterfaceAgentStatusResponse {
    return new StreamInterfaceAgentStatusResponse().fromJsonString(jsonString, options);
  }

  static equals(a: StreamInterfaceAgentStatusResponse | PlainMessage<StreamInterfaceAgentStatusResponse> | undefined, b: StreamInterfaceAgentStatusResponse | PlainMessage<StreamInterfaceAgentStatusResponse> | undefined): boolean {
    return proto3.util.equals(StreamInterfaceAgentStatusResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskGetInterfaceAgentStatusRequest
 */
export class TaskGetInterfaceAgentStatusRequest extends Message<TaskGetInterfaceAgentStatusRequest> {
  /**
   * @generated from field: aiserver.v1.InterfaceAgentClientState interface_agent_client_state = 1;
   */
  interfaceAgentClientState?: InterfaceAgentClientState;

  constructor(data?: PartialMessage<TaskGetInterfaceAgentStatusRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskGetInterfaceAgentStatusRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "interface_agent_client_state", kind: "message", T: InterfaceAgentClientState },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskGetInterfaceAgentStatusRequest {
    return new TaskGetInterfaceAgentStatusRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskGetInterfaceAgentStatusRequest {
    return new TaskGetInterfaceAgentStatusRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskGetInterfaceAgentStatusRequest {
    return new TaskGetInterfaceAgentStatusRequest().fromJsonString(jsonString, options);
  }

  static equals(a: TaskGetInterfaceAgentStatusRequest | PlainMessage<TaskGetInterfaceAgentStatusRequest> | undefined, b: TaskGetInterfaceAgentStatusRequest | PlainMessage<TaskGetInterfaceAgentStatusRequest> | undefined): boolean {
    return proto3.util.equals(TaskGetInterfaceAgentStatusRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskGetInterfaceAgentStatusResponse
 */
export class TaskGetInterfaceAgentStatusResponse extends Message<TaskGetInterfaceAgentStatusResponse> {
  /**
   * the current state of the interface agent
   *
   * @generated from field: aiserver.v1.InterfaceAgentStatus status = 1;
   */
  status?: InterfaceAgentStatus;

  constructor(data?: PartialMessage<TaskGetInterfaceAgentStatusResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskGetInterfaceAgentStatusResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "status", kind: "message", T: InterfaceAgentStatus },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskGetInterfaceAgentStatusResponse {
    return new TaskGetInterfaceAgentStatusResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskGetInterfaceAgentStatusResponse {
    return new TaskGetInterfaceAgentStatusResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskGetInterfaceAgentStatusResponse {
    return new TaskGetInterfaceAgentStatusResponse().fromJsonString(jsonString, options);
  }

  static equals(a: TaskGetInterfaceAgentStatusResponse | PlainMessage<TaskGetInterfaceAgentStatusResponse> | undefined, b: TaskGetInterfaceAgentStatusResponse | PlainMessage<TaskGetInterfaceAgentStatusResponse> | undefined): boolean {
    return proto3.util.equals(TaskGetInterfaceAgentStatusResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskGetInterfaceAgentStatusResponseWrapped
 */
export class TaskGetInterfaceAgentStatusResponseWrapped extends Message<TaskGetInterfaceAgentStatusResponseWrapped> {
  /**
   * @generated from oneof aiserver.v1.TaskGetInterfaceAgentStatusResponseWrapped.response
   */
  response: {
    /**
     * @generated from field: aiserver.v1.TaskGetInterfaceAgentStatusResponse real_response = 1;
     */
    value: TaskGetInterfaceAgentStatusResponse;
    case: "realResponse";
  } | {
    /**
     * @generated from field: string background_task_uuid = 2;
     */
    value: string;
    case: "backgroundTaskUuid";
  } | { case: undefined; value?: undefined } = { case: undefined };

  constructor(data?: PartialMessage<TaskGetInterfaceAgentStatusResponseWrapped>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskGetInterfaceAgentStatusResponseWrapped";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "real_response", kind: "message", T: TaskGetInterfaceAgentStatusResponse, oneof: "response" },
    { no: 2, name: "background_task_uuid", kind: "scalar", T: 9 /* ScalarType.STRING */, oneof: "response" },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskGetInterfaceAgentStatusResponseWrapped {
    return new TaskGetInterfaceAgentStatusResponseWrapped().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskGetInterfaceAgentStatusResponseWrapped {
    return new TaskGetInterfaceAgentStatusResponseWrapped().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskGetInterfaceAgentStatusResponseWrapped {
    return new TaskGetInterfaceAgentStatusResponseWrapped().fromJsonString(jsonString, options);
  }

  static equals(a: TaskGetInterfaceAgentStatusResponseWrapped | PlainMessage<TaskGetInterfaceAgentStatusResponseWrapped> | undefined, b: TaskGetInterfaceAgentStatusResponseWrapped | PlainMessage<TaskGetInterfaceAgentStatusResponseWrapped> | undefined): boolean {
    return proto3.util.equals(TaskGetInterfaceAgentStatusResponseWrapped, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskInitRequest
 */
export class TaskInitRequest extends Message<TaskInitRequest> {
  /**
   * @generated from field: aiserver.v1.TaskInstruction instruction = 1;
   */
  instruction?: TaskInstruction;

  /**
   * What model to use and api key to use if applicable
   *
   * @generated from field: aiserver.v1.ModelDetails model_details = 2;
   */
  modelDetails?: ModelDetails;

  /**
   * whether to enable priompt live mode
   *
   * @generated from field: bool debugging_only_live_mode = 3;
   */
  debuggingOnlyLiveMode = false;

  /**
   * if you want to use a specific engine, you can!
   * if this is not set, then the server will pick the default engine
   *
   * @generated from field: optional string engine_id = 4;
   */
  engineId?: string;

  constructor(data?: PartialMessage<TaskInitRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskInitRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "instruction", kind: "message", T: TaskInstruction },
    { no: 2, name: "model_details", kind: "message", T: ModelDetails },
    { no: 3, name: "debugging_only_live_mode", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 4, name: "engine_id", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskInitRequest {
    return new TaskInitRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskInitRequest {
    return new TaskInitRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskInitRequest {
    return new TaskInitRequest().fromJsonString(jsonString, options);
  }

  static equals(a: TaskInitRequest | PlainMessage<TaskInitRequest> | undefined, b: TaskInitRequest | PlainMessage<TaskInitRequest> | undefined): boolean {
    return proto3.util.equals(TaskInitRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskInitResponse
 */
export class TaskInitResponse extends Message<TaskInitResponse> {
  /**
   * this is the server-assigned task uuid that identifies the task
   *
   * @generated from field: string task_uuid = 1;
   */
  taskUuid = "";

  /**
   * the human readable title for the task!
   *
   * @generated from field: string human_readable_title = 2;
   */
  humanReadableTitle = "";

  constructor(data?: PartialMessage<TaskInitResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskInitResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "task_uuid", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "human_readable_title", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskInitResponse {
    return new TaskInitResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskInitResponse {
    return new TaskInitResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskInitResponse {
    return new TaskInitResponse().fromJsonString(jsonString, options);
  }

  static equals(a: TaskInitResponse | PlainMessage<TaskInitResponse> | undefined, b: TaskInitResponse | PlainMessage<TaskInitResponse> | undefined): boolean {
    return proto3.util.equals(TaskInitResponse, a, b);
  }
}

/**
 * listen to the append-only task log
 *
 * @generated from message aiserver.v1.TaskStreamLogRequest
 */
export class TaskStreamLogRequest extends Message<TaskStreamLogRequest> {
  /**
   * the server-assigned task uuid
   *
   * @generated from field: string task_uuid = 1;
   */
  taskUuid = "";

  /**
   * a start sequence number to start from
   * to start from the beginning, set this to 0.
   *
   * @generated from field: int32 start_sequence_number = 2;
   */
  startSequenceNumber = 0;

  constructor(data?: PartialMessage<TaskStreamLogRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskStreamLogRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "task_uuid", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "start_sequence_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskStreamLogRequest {
    return new TaskStreamLogRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskStreamLogRequest {
    return new TaskStreamLogRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskStreamLogRequest {
    return new TaskStreamLogRequest().fromJsonString(jsonString, options);
  }

  static equals(a: TaskStreamLogRequest | PlainMessage<TaskStreamLogRequest> | undefined, b: TaskStreamLogRequest | PlainMessage<TaskStreamLogRequest> | undefined): boolean {
    return proto3.util.equals(TaskStreamLogRequest, a, b);
  }
}

/**
 * can be streamed. if so, just append the text together
 *
 * @generated from message aiserver.v1.TaskLogOutput
 */
export class TaskLogOutput extends Message<TaskLogOutput> {
  /**
   * @generated from field: string text = 1;
   */
  text = "";

  constructor(data?: PartialMessage<TaskLogOutput>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskLogOutput";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskLogOutput {
    return new TaskLogOutput().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskLogOutput {
    return new TaskLogOutput().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskLogOutput {
    return new TaskLogOutput().fromJsonString(jsonString, options);
  }

  static equals(a: TaskLogOutput | PlainMessage<TaskLogOutput> | undefined, b: TaskLogOutput | PlainMessage<TaskLogOutput> | undefined): boolean {
    return proto3.util.equals(TaskLogOutput, a, b);
  }
}

/**
 * may be streamed in certain cases (eg edits)
 * this is handled within the tool call itself
 *
 * @generated from message aiserver.v1.TaskLogToolAction
 */
export class TaskLogToolAction extends Message<TaskLogToolAction> {
  /**
   * the user facing text is what to show the user
   * when the log item is streamed, this is appended to itself
   *
   * @generated from field: string user_facing_text = 1;
   */
  userFacingText = "";

  /**
   * the raw model output is whatever is inside the <Action> tag
   * this is somewhat useful for debugging
   * it is only sent if the log item is done
   *
   * @generated from field: string raw_model_output = 3;
   */
  rawModelOutput = "";

  /**
   * this may be undefined or defined
   * the tool handler on the client will respond to the call once the log item
   * is done
   *
   * @generated from field: aiserver.v1.ToolCall tool_call = 2;
   */
  toolCall?: ToolCall;

  constructor(data?: PartialMessage<TaskLogToolAction>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskLogToolAction";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "user_facing_text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "raw_model_output", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "tool_call", kind: "message", T: ToolCall },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskLogToolAction {
    return new TaskLogToolAction().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskLogToolAction {
    return new TaskLogToolAction().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskLogToolAction {
    return new TaskLogToolAction().fromJsonString(jsonString, options);
  }

  static equals(a: TaskLogToolAction | PlainMessage<TaskLogToolAction> | undefined, b: TaskLogToolAction | PlainMessage<TaskLogToolAction> | undefined): boolean {
    return proto3.util.equals(TaskLogToolAction, a, b);
  }
}

/**
 * can be streamed. if so, just append the text together
 *
 * @generated from message aiserver.v1.TaskLogThought
 */
export class TaskLogThought extends Message<TaskLogThought> {
  /**
   * @generated from field: string text = 1;
   */
  text = "";

  constructor(data?: PartialMessage<TaskLogThought>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskLogThought";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "text", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskLogThought {
    return new TaskLogThought().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskLogThought {
    return new TaskLogThought().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskLogThought {
    return new TaskLogThought().fromJsonString(jsonString, options);
  }

  static equals(a: TaskLogThought | PlainMessage<TaskLogThought> | undefined, b: TaskLogThought | PlainMessage<TaskLogThought> | undefined): boolean {
    return proto3.util.equals(TaskLogThought, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskLogToolResult
 */
export class TaskLogToolResult extends Message<TaskLogToolResult> {
  /**
   * @generated from field: aiserver.v1.ToolResult tool_result = 1;
   */
  toolResult?: ToolResult;

  /**
   * the action this result is in response to
   *
   * @generated from field: int32 action_sequence_number = 2;
   */
  actionSequenceNumber = 0;

  constructor(data?: PartialMessage<TaskLogToolResult>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskLogToolResult";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "tool_result", kind: "message", T: ToolResult },
    { no: 2, name: "action_sequence_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskLogToolResult {
    return new TaskLogToolResult().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskLogToolResult {
    return new TaskLogToolResult().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskLogToolResult {
    return new TaskLogToolResult().fromJsonString(jsonString, options);
  }

  static equals(a: TaskLogToolResult | PlainMessage<TaskLogToolResult> | undefined, b: TaskLogToolResult | PlainMessage<TaskLogToolResult> | undefined): boolean {
    return proto3.util.equals(TaskLogToolResult, a, b);
  }
}

/**
 * streamable log items should have a well-defined addition operator
 *
 * @generated from message aiserver.v1.TaskLogItem
 */
export class TaskLogItem extends Message<TaskLogItem> {
  /**
   * each log item has a sequence number
   * this sequence number is increasing, and allows the user to listen given a
   * starting point for log items that are streamable (eg outputs), the sequence
   * number is the same for each response object that is, when reading the
   * stream, the sequence number will not strictly increase
   *
   * @generated from field: int32 sequence_number = 1;
   */
  sequenceNumber = 0;

  /**
   * this is set to true if the log item is not done with this response
   * if this is true, the next response will have the same sequence number as
   * this if this is false, this guarantees that the next sequence number will
   * be strictly greater than the current one
   *
   * @generated from field: bool is_not_done = 2;
   */
  isNotDone = false;

  /**
   * @generated from oneof aiserver.v1.TaskLogItem.log_item
   */
  logItem: {
    /**
     * streamable
     *
     * @generated from field: aiserver.v1.TaskLogOutput output = 3;
     */
    value: TaskLogOutput;
    case: "output";
  } | {
    /**
     * streamable depending on the action
     *
     * @generated from field: aiserver.v1.TaskLogToolAction tool_action = 4;
     */
    value: TaskLogToolAction;
    case: "toolAction";
  } | {
    /**
     * streamable
     *
     * @generated from field: aiserver.v1.TaskLogThought thought = 5;
     */
    value: TaskLogThought;
    case: "thought";
  } | {
    /**
     * not streamable
     *
     * @generated from field: aiserver.v1.TaskUserMessage user_message = 6;
     */
    value: TaskUserMessage;
    case: "userMessage";
  } | {
    /**
     * not streamable
     *
     * @generated from field: aiserver.v1.TaskInstruction instruction = 7;
     */
    value: TaskInstruction;
    case: "instruction";
  } | {
    /**
     * not streamable
     *
     * streamable - TODO implement this for streaming the
     * tool result to the server
     * TaskLogToolResult streamed_tool_result = 9;
     *
     * @generated from field: aiserver.v1.TaskLogToolResult tool_result = 8;
     */
    value: TaskLogToolResult;
    case: "toolResult";
  } | { case: undefined; value?: undefined } = { case: undefined };

  constructor(data?: PartialMessage<TaskLogItem>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskLogItem";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "sequence_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 2, name: "is_not_done", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 3, name: "output", kind: "message", T: TaskLogOutput, oneof: "log_item" },
    { no: 4, name: "tool_action", kind: "message", T: TaskLogToolAction, oneof: "log_item" },
    { no: 5, name: "thought", kind: "message", T: TaskLogThought, oneof: "log_item" },
    { no: 6, name: "user_message", kind: "message", T: TaskUserMessage, oneof: "log_item" },
    { no: 7, name: "instruction", kind: "message", T: TaskInstruction, oneof: "log_item" },
    { no: 8, name: "tool_result", kind: "message", T: TaskLogToolResult, oneof: "log_item" },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskLogItem {
    return new TaskLogItem().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskLogItem {
    return new TaskLogItem().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskLogItem {
    return new TaskLogItem().fromJsonString(jsonString, options);
  }

  static equals(a: TaskLogItem | PlainMessage<TaskLogItem> | undefined, b: TaskLogItem | PlainMessage<TaskLogItem> | undefined): boolean {
    return proto3.util.equals(TaskLogItem, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskInfoRequest
 */
export class TaskInfoRequest extends Message<TaskInfoRequest> {
  /**
   * @generated from field: string task_uuid = 1;
   */
  taskUuid = "";

  constructor(data?: PartialMessage<TaskInfoRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskInfoRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "task_uuid", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskInfoRequest {
    return new TaskInfoRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskInfoRequest {
    return new TaskInfoRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskInfoRequest {
    return new TaskInfoRequest().fromJsonString(jsonString, options);
  }

  static equals(a: TaskInfoRequest | PlainMessage<TaskInfoRequest> | undefined, b: TaskInfoRequest | PlainMessage<TaskInfoRequest> | undefined): boolean {
    return proto3.util.equals(TaskInfoRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskPauseRequest
 */
export class TaskPauseRequest extends Message<TaskPauseRequest> {
  /**
   * @generated from field: string task_uuid = 1;
   */
  taskUuid = "";

  constructor(data?: PartialMessage<TaskPauseRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskPauseRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "task_uuid", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskPauseRequest {
    return new TaskPauseRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskPauseRequest {
    return new TaskPauseRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskPauseRequest {
    return new TaskPauseRequest().fromJsonString(jsonString, options);
  }

  static equals(a: TaskPauseRequest | PlainMessage<TaskPauseRequest> | undefined, b: TaskPauseRequest | PlainMessage<TaskPauseRequest> | undefined): boolean {
    return proto3.util.equals(TaskPauseRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskPauseResponse
 */
export class TaskPauseResponse extends Message<TaskPauseResponse> {
  constructor(data?: PartialMessage<TaskPauseResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskPauseResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskPauseResponse {
    return new TaskPauseResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskPauseResponse {
    return new TaskPauseResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskPauseResponse {
    return new TaskPauseResponse().fromJsonString(jsonString, options);
  }

  static equals(a: TaskPauseResponse | PlainMessage<TaskPauseResponse> | undefined, b: TaskPauseResponse | PlainMessage<TaskPauseResponse> | undefined): boolean {
    return proto3.util.equals(TaskPauseResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskInfoResponse
 */
export class TaskInfoResponse extends Message<TaskInfoResponse> {
  /**
   * @generated from field: string human_readable_title = 1;
   */
  humanReadableTitle = "";

  /**
   * @generated from field: aiserver.v1.TaskStatus task_status = 2;
   */
  taskStatus = TaskStatus.UNSPECIFIED;

  /**
   * TODO: what if the log is not completed?
   * returns -1 if there is no log
   *
   * @generated from field: int32 last_log_sequence_number = 3;
   */
  lastLogSequenceNumber = 0;

  constructor(data?: PartialMessage<TaskInfoResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskInfoResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "human_readable_title", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "task_status", kind: "enum", T: proto3.getEnumType(TaskStatus) },
    { no: 3, name: "last_log_sequence_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskInfoResponse {
    return new TaskInfoResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskInfoResponse {
    return new TaskInfoResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskInfoResponse {
    return new TaskInfoResponse().fromJsonString(jsonString, options);
  }

  static equals(a: TaskInfoResponse | PlainMessage<TaskInfoResponse> | undefined, b: TaskInfoResponse | PlainMessage<TaskInfoResponse> | undefined): boolean {
    return proto3.util.equals(TaskInfoResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskStreamLogResponse
 */
export class TaskStreamLogResponse extends Message<TaskStreamLogResponse> {
  /**
   * @generated from oneof aiserver.v1.TaskStreamLogResponse.response
   */
  response: {
    /**
     * @generated from field: aiserver.v1.TaskLogItem streamed_log_item = 1;
     */
    value: TaskLogItem;
    case: "streamedLogItem";
  } | {
    /**
     * @generated from field: aiserver.v1.TaskStreamLogResponse.InfoUpdate info_update = 2;
     */
    value: TaskStreamLogResponse_InfoUpdate;
    case: "infoUpdate";
  } | {
    /**
     * the initial task info is always sent at the start, such that the updates
     * make sense the task info is for the *current* state of the task (not the
     * state of the task at the time of the given log item)
     *
     * @generated from field: aiserver.v1.TaskInfoResponse initial_task_info = 3;
     */
    value: TaskInfoResponse;
    case: "initialTaskInfo";
  } | { case: undefined; value?: undefined } = { case: undefined };

  constructor(data?: PartialMessage<TaskStreamLogResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskStreamLogResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "streamed_log_item", kind: "message", T: TaskLogItem, oneof: "response" },
    { no: 2, name: "info_update", kind: "message", T: TaskStreamLogResponse_InfoUpdate, oneof: "response" },
    { no: 3, name: "initial_task_info", kind: "message", T: TaskInfoResponse, oneof: "response" },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskStreamLogResponse {
    return new TaskStreamLogResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskStreamLogResponse {
    return new TaskStreamLogResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskStreamLogResponse {
    return new TaskStreamLogResponse().fromJsonString(jsonString, options);
  }

  static equals(a: TaskStreamLogResponse | PlainMessage<TaskStreamLogResponse> | undefined, b: TaskStreamLogResponse | PlainMessage<TaskStreamLogResponse> | undefined): boolean {
    return proto3.util.equals(TaskStreamLogResponse, a, b);
  }
}

/**
 * if null, then that field is not updated
 *
 * @generated from message aiserver.v1.TaskStreamLogResponse.InfoUpdate
 */
export class TaskStreamLogResponse_InfoUpdate extends Message<TaskStreamLogResponse_InfoUpdate> {
  /**
   * @generated from field: optional string human_readable_title = 1;
   */
  humanReadableTitle?: string;

  /**
   * @generated from field: optional aiserver.v1.TaskStatus task_status = 2;
   */
  taskStatus?: TaskStatus;

  constructor(data?: PartialMessage<TaskStreamLogResponse_InfoUpdate>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskStreamLogResponse.InfoUpdate";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "human_readable_title", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 2, name: "task_status", kind: "enum", T: proto3.getEnumType(TaskStatus), opt: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskStreamLogResponse_InfoUpdate {
    return new TaskStreamLogResponse_InfoUpdate().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskStreamLogResponse_InfoUpdate {
    return new TaskStreamLogResponse_InfoUpdate().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskStreamLogResponse_InfoUpdate {
    return new TaskStreamLogResponse_InfoUpdate().fromJsonString(jsonString, options);
  }

  static equals(a: TaskStreamLogResponse_InfoUpdate | PlainMessage<TaskStreamLogResponse_InfoUpdate> | undefined, b: TaskStreamLogResponse_InfoUpdate | PlainMessage<TaskStreamLogResponse_InfoUpdate> | undefined): boolean {
    return proto3.util.equals(TaskStreamLogResponse_InfoUpdate, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskProvideResultRequest
 */
export class TaskProvideResultRequest extends Message<TaskProvideResultRequest> {
  /**
   * @generated from field: string task_uuid = 1;
   */
  taskUuid = "";

  /**
   * a given action will have a sequence number in the log, and here we are
   * providing a result to a specific action
   *
   * @generated from field: int32 action_sequence_number = 2;
   */
  actionSequenceNumber = 0;

  /**
   * @generated from field: aiserver.v1.ToolResult tool_result = 3;
   */
  toolResult?: ToolResult;

  constructor(data?: PartialMessage<TaskProvideResultRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskProvideResultRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "task_uuid", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "action_sequence_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "tool_result", kind: "message", T: ToolResult },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskProvideResultRequest {
    return new TaskProvideResultRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskProvideResultRequest {
    return new TaskProvideResultRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskProvideResultRequest {
    return new TaskProvideResultRequest().fromJsonString(jsonString, options);
  }

  static equals(a: TaskProvideResultRequest | PlainMessage<TaskProvideResultRequest> | undefined, b: TaskProvideResultRequest | PlainMessage<TaskProvideResultRequest> | undefined): boolean {
    return proto3.util.equals(TaskProvideResultRequest, a, b);
  }
}

/**
 * nothing in particular needed here, I think
 *
 * @generated from message aiserver.v1.TaskProvideResultResponse
 */
export class TaskProvideResultResponse extends Message<TaskProvideResultResponse> {
  constructor(data?: PartialMessage<TaskProvideResultResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskProvideResultResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskProvideResultResponse {
    return new TaskProvideResultResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskProvideResultResponse {
    return new TaskProvideResultResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskProvideResultResponse {
    return new TaskProvideResultResponse().fromJsonString(jsonString, options);
  }

  static equals(a: TaskProvideResultResponse | PlainMessage<TaskProvideResultResponse> | undefined, b: TaskProvideResultResponse | PlainMessage<TaskProvideResultResponse> | undefined): boolean {
    return proto3.util.equals(TaskProvideResultResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.TaskSendMessageRequest
 */
export class TaskSendMessageRequest extends Message<TaskSendMessageRequest> {
  /**
   * @generated from field: string task_uuid = 1;
   */
  taskUuid = "";

  /**
   * @generated from field: aiserver.v1.TaskUserMessage user_message = 2;
   */
  userMessage?: TaskUserMessage;

  /**
   * the message can be sent either as an interruption or not
   *
   * @generated from field: bool wants_attention_right_now = 3;
   */
  wantsAttentionRightNow = false;

  constructor(data?: PartialMessage<TaskSendMessageRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskSendMessageRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "task_uuid", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "user_message", kind: "message", T: TaskUserMessage },
    { no: 3, name: "wants_attention_right_now", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskSendMessageRequest {
    return new TaskSendMessageRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskSendMessageRequest {
    return new TaskSendMessageRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskSendMessageRequest {
    return new TaskSendMessageRequest().fromJsonString(jsonString, options);
  }

  static equals(a: TaskSendMessageRequest | PlainMessage<TaskSendMessageRequest> | undefined, b: TaskSendMessageRequest | PlainMessage<TaskSendMessageRequest> | undefined): boolean {
    return proto3.util.equals(TaskSendMessageRequest, a, b);
  }
}

/**
 * nothing in particular needed here, I think
 *
 * @generated from message aiserver.v1.TaskSendMessageResponse
 */
export class TaskSendMessageResponse extends Message<TaskSendMessageResponse> {
  constructor(data?: PartialMessage<TaskSendMessageResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.TaskSendMessageResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TaskSendMessageResponse {
    return new TaskSendMessageResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TaskSendMessageResponse {
    return new TaskSendMessageResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TaskSendMessageResponse {
    return new TaskSendMessageResponse().fromJsonString(jsonString, options);
  }

  static equals(a: TaskSendMessageResponse | PlainMessage<TaskSendMessageResponse> | undefined, b: TaskSendMessageResponse | PlainMessage<TaskSendMessageResponse> | undefined): boolean {
    return proto3.util.equals(TaskSendMessageResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ReportFeedbackRequest
 */
export class ReportFeedbackRequest extends Message<ReportFeedbackRequest> {
  /**
   * @generated from field: string feedback = 1;
   */
  feedback = "";

  /**
   * @generated from field: aiserver.v1.ReportFeedbackRequest.FeedbackType feedback_type = 2;
   */
  feedbackType = ReportFeedbackRequest_FeedbackType.UNSPECIFIED;

  constructor(data?: PartialMessage<ReportFeedbackRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ReportFeedbackRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "feedback", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "feedback_type", kind: "enum", T: proto3.getEnumType(ReportFeedbackRequest_FeedbackType) },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ReportFeedbackRequest {
    return new ReportFeedbackRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ReportFeedbackRequest {
    return new ReportFeedbackRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ReportFeedbackRequest {
    return new ReportFeedbackRequest().fromJsonString(jsonString, options);
  }

  static equals(a: ReportFeedbackRequest | PlainMessage<ReportFeedbackRequest> | undefined, b: ReportFeedbackRequest | PlainMessage<ReportFeedbackRequest> | undefined): boolean {
    return proto3.util.equals(ReportFeedbackRequest, a, b);
  }
}

/**
 * @generated from enum aiserver.v1.ReportFeedbackRequest.FeedbackType
 */
export enum ReportFeedbackRequest_FeedbackType {
  /**
   * @generated from enum value: FEEDBACK_TYPE_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: FEEDBACK_TYPE_LOW_PRIORITY = 1;
   */
  LOW_PRIORITY = 1,

  /**
   * @generated from enum value: FEEDBACK_TYPE_HIGH_PRIORITY = 2;
   */
  HIGH_PRIORITY = 2,
}
// Retrieve enum metadata with: proto3.getEnumType(ReportFeedbackRequest_FeedbackType)
proto3.util.setEnumType(ReportFeedbackRequest_FeedbackType, "aiserver.v1.ReportFeedbackRequest.FeedbackType", [
  { no: 0, name: "FEEDBACK_TYPE_UNSPECIFIED" },
  { no: 1, name: "FEEDBACK_TYPE_LOW_PRIORITY" },
  { no: 2, name: "FEEDBACK_TYPE_HIGH_PRIORITY" },
]);

/**
 * @generated from message aiserver.v1.ReportFeedbackResponse
 */
export class ReportFeedbackResponse extends Message<ReportFeedbackResponse> {
  constructor(data?: PartialMessage<ReportFeedbackResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ReportFeedbackResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ReportFeedbackResponse {
    return new ReportFeedbackResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ReportFeedbackResponse {
    return new ReportFeedbackResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ReportFeedbackResponse {
    return new ReportFeedbackResponse().fromJsonString(jsonString, options);
  }

  static equals(a: ReportFeedbackResponse | PlainMessage<ReportFeedbackResponse> | undefined, b: ReportFeedbackResponse | PlainMessage<ReportFeedbackResponse> | undefined): boolean {
    return proto3.util.equals(ReportFeedbackResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.LogFile
 */
export class LogFile extends Message<LogFile> {
  /**
   * @generated from field: string relative_path_to_cursor_folder = 1;
   */
  relativePathToCursorFolder = "";

  /**
   * @generated from field: string contents = 2;
   */
  contents = "";

  constructor(data?: PartialMessage<LogFile>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.LogFile";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_path_to_cursor_folder", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "contents", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): LogFile {
    return new LogFile().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): LogFile {
    return new LogFile().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): LogFile {
    return new LogFile().fromJsonString(jsonString, options);
  }

  static equals(a: LogFile | PlainMessage<LogFile> | undefined, b: LogFile | PlainMessage<LogFile> | undefined): boolean {
    return proto3.util.equals(LogFile, a, b);
  }
}

/**
 * @generated from message aiserver.v1.BugContext
 */
export class BugContext extends Message<BugContext> {
  /**
   * @generated from field: repeated string screenshots = 1;
   */
  screenshots: string[] = [];

  /**
   * @generated from field: aiserver.v1.CurrentFileInfo current_file = 2;
   */
  currentFile?: CurrentFileInfo;

  /**
   * @generated from field: repeated aiserver.v1.ConversationMessage conversation = 3;
   */
  conversation: ConversationMessage[] = [];

  /**
   * @generated from field: repeated aiserver.v1.LogFile logs = 4;
   */
  logs: LogFile[] = [];

  /**
   * @generated from field: string console_logs = 5;
   */
  consoleLogs = "";

  /**
   * @generated from field: string cursor_version = 6;
   */
  cursorVersion = "";

  /**
   * @generated from field: string os = 7;
   */
  os = "";

  constructor(data?: PartialMessage<BugContext>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.BugContext";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "screenshots", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 2, name: "current_file", kind: "message", T: CurrentFileInfo },
    { no: 3, name: "conversation", kind: "message", T: ConversationMessage, repeated: true },
    { no: 4, name: "logs", kind: "message", T: LogFile, repeated: true },
    { no: 5, name: "console_logs", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 6, name: "cursor_version", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 7, name: "os", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): BugContext {
    return new BugContext().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): BugContext {
    return new BugContext().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): BugContext {
    return new BugContext().fromJsonString(jsonString, options);
  }

  static equals(a: BugContext | PlainMessage<BugContext> | undefined, b: BugContext | PlainMessage<BugContext> | undefined): boolean {
    return proto3.util.equals(BugContext, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ReportBugRequest
 */
export class ReportBugRequest extends Message<ReportBugRequest> {
  /**
   * @generated from field: string bug = 1;
   */
  bug = "";

  /**
   * @generated from field: aiserver.v1.ReportBugRequest.BugType bug_type = 2;
   */
  bugType = ReportBugRequest_BugType.UNSPECIFIED;

  /**
   * @generated from field: aiserver.v1.BugContext context = 3;
   */
  context?: BugContext;

  /**
   * @generated from field: string contact_email = 4;
   */
  contactEmail = "";

  constructor(data?: PartialMessage<ReportBugRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ReportBugRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "bug", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "bug_type", kind: "enum", T: proto3.getEnumType(ReportBugRequest_BugType) },
    { no: 3, name: "context", kind: "message", T: BugContext },
    { no: 4, name: "contact_email", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ReportBugRequest {
    return new ReportBugRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ReportBugRequest {
    return new ReportBugRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ReportBugRequest {
    return new ReportBugRequest().fromJsonString(jsonString, options);
  }

  static equals(a: ReportBugRequest | PlainMessage<ReportBugRequest> | undefined, b: ReportBugRequest | PlainMessage<ReportBugRequest> | undefined): boolean {
    return proto3.util.equals(ReportBugRequest, a, b);
  }
}

/**
 * @generated from enum aiserver.v1.ReportBugRequest.BugType
 */
export enum ReportBugRequest_BugType {
  /**
   * @generated from enum value: BUG_TYPE_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: BUG_TYPE_LOW = 1;
   */
  LOW = 1,

  /**
   * @generated from enum value: BUG_TYPE_MEDIUM = 2;
   */
  MEDIUM = 2,

  /**
   * @generated from enum value: BUG_TYPE_URGENT = 3;
   */
  URGENT = 3,

  /**
   * @generated from enum value: BUG_TYPE_CRASH = 4;
   */
  CRASH = 4,
}
// Retrieve enum metadata with: proto3.getEnumType(ReportBugRequest_BugType)
proto3.util.setEnumType(ReportBugRequest_BugType, "aiserver.v1.ReportBugRequest.BugType", [
  { no: 0, name: "BUG_TYPE_UNSPECIFIED" },
  { no: 1, name: "BUG_TYPE_LOW" },
  { no: 2, name: "BUG_TYPE_MEDIUM" },
  { no: 3, name: "BUG_TYPE_URGENT" },
  { no: 4, name: "BUG_TYPE_CRASH" },
]);

/**
 * @generated from message aiserver.v1.ReportBugResponse
 */
export class ReportBugResponse extends Message<ReportBugResponse> {
  constructor(data?: PartialMessage<ReportBugResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ReportBugResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ReportBugResponse {
    return new ReportBugResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ReportBugResponse {
    return new ReportBugResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ReportBugResponse {
    return new ReportBugResponse().fromJsonString(jsonString, options);
  }

  static equals(a: ReportBugResponse | PlainMessage<ReportBugResponse> | undefined, b: ReportBugResponse | PlainMessage<ReportBugResponse> | undefined): boolean {
    return proto3.util.equals(ReportBugResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.FixMarkersRequest
 */
export class FixMarkersRequest extends Message<FixMarkersRequest> {
  /**
   * @generated from field: repeated aiserver.v1.FixMarkersRequest.Marker markers = 1;
   */
  markers: FixMarkersRequest_Marker[] = [];

  /**
   * @generated from field: aiserver.v1.ModelDetails model_details = 2;
   */
  modelDetails?: ModelDetails;

  /**
   * not used in prompt, but should be logged
   *
   * @generated from field: int32 iteration_number = 3;
   */
  iterationNumber = 0;

  /**
   * identifies requests which originate from the same trigger
   *
   * @generated from field: string sequence_id = 4;
   */
  sequenceId = "";

  /**
   * we let user give some instructions
   *
   * @generated from field: string user_instruction = 5;
   */
  userInstruction = "";

  constructor(data?: PartialMessage<FixMarkersRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.FixMarkersRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "markers", kind: "message", T: FixMarkersRequest_Marker, repeated: true },
    { no: 2, name: "model_details", kind: "message", T: ModelDetails },
    { no: 3, name: "iteration_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 4, name: "sequence_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 5, name: "user_instruction", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): FixMarkersRequest {
    return new FixMarkersRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): FixMarkersRequest {
    return new FixMarkersRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): FixMarkersRequest {
    return new FixMarkersRequest().fromJsonString(jsonString, options);
  }

  static equals(a: FixMarkersRequest | PlainMessage<FixMarkersRequest> | undefined, b: FixMarkersRequest | PlainMessage<FixMarkersRequest> | undefined): boolean {
    return proto3.util.equals(FixMarkersRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.FixMarkersRequest.Marker
 */
export class FixMarkersRequest_Marker extends Message<FixMarkersRequest_Marker> {
  /**
   * this is all the lines in current file
   *
   * @generated from field: repeated string lines = 1;
   */
  lines: string[] = [];

  /**
   * @generated from field: int32 start_line = 2;
   */
  startLine = 0;

  /**
   * @generated from field: int32 end_line_inclusive = 3;
   */
  endLineInclusive = 0;

  /**
   * @generated from field: string message = 4;
   */
  message = "";

  /**
   * @generated from field: string relative_workspace_path = 5;
   */
  relativeWorkspacePath = "";

  /**
   * @generated from field: repeated aiserver.v1.FixMarkersRequest.Marker.RelatedInformation related_information = 6;
   */
  relatedInformation: FixMarkersRequest_Marker_RelatedInformation[] = [];

  /**
   * @generated from field: repeated aiserver.v1.FixMarkersRequest.Marker.ContextRange context_ranges = 7;
   */
  contextRanges: FixMarkersRequest_Marker_ContextRange[] = [];

  /**
   * @generated from field: repeated aiserver.v1.FixMarkersRequest.Marker.AncestorTypeDefinition ancestor_type_definitions = 8;
   */
  ancestorTypeDefinitions: FixMarkersRequest_Marker_AncestorTypeDefinition[] = [];

  /**
   * this is the type of symbol that the previous AI model told us about
   *
   * @generated from field: repeated aiserver.v1.FixMarkersRequest.Marker.InsertedSymbolType inserted_symbol_types = 9;
   */
  insertedSymbolTypes: FixMarkersRequest_Marker_InsertedSymbolType[] = [];

  /**
   * @generated from field: repeated aiserver.v1.FixMarkersRequest.Marker.QuickFix quick_fixes = 10;
   */
  quickFixes: FixMarkersRequest_Marker_QuickFix[] = [];

  /**
   * @generated from field: int32 start_column = 11;
   */
  startColumn = 0;

  /**
   * @generated from field: int32 end_column_inclusive = 12;
   */
  endColumnInclusive = 0;

  /**
   * @generated from field: repeated aiserver.v1.FixMarkersRequest.Marker.ClassInformation class_information = 13;
   */
  classInformation: FixMarkersRequest_Marker_ClassInformation[] = [];

  /**
   * @generated from field: repeated aiserver.v1.FixMarkersRequest.Marker.FunctionSignature function_signatures = 14;
   */
  functionSignatures: FixMarkersRequest_Marker_FunctionSignature[] = [];

  /**
   * also not used, represents state of the repo at the
   *
   * @generated from field: int32 snapshot = 15;
   */
  snapshot = 0;

  constructor(data?: PartialMessage<FixMarkersRequest_Marker>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.FixMarkersRequest.Marker";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "lines", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 2, name: "start_line", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "end_line_inclusive", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 4, name: "message", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 5, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 6, name: "related_information", kind: "message", T: FixMarkersRequest_Marker_RelatedInformation, repeated: true },
    { no: 7, name: "context_ranges", kind: "message", T: FixMarkersRequest_Marker_ContextRange, repeated: true },
    { no: 8, name: "ancestor_type_definitions", kind: "message", T: FixMarkersRequest_Marker_AncestorTypeDefinition, repeated: true },
    { no: 9, name: "inserted_symbol_types", kind: "message", T: FixMarkersRequest_Marker_InsertedSymbolType, repeated: true },
    { no: 10, name: "quick_fixes", kind: "message", T: FixMarkersRequest_Marker_QuickFix, repeated: true },
    { no: 11, name: "start_column", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 12, name: "end_column_inclusive", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 13, name: "class_information", kind: "message", T: FixMarkersRequest_Marker_ClassInformation, repeated: true },
    { no: 14, name: "function_signatures", kind: "message", T: FixMarkersRequest_Marker_FunctionSignature, repeated: true },
    { no: 15, name: "snapshot", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): FixMarkersRequest_Marker {
    return new FixMarkersRequest_Marker().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker {
    return new FixMarkersRequest_Marker().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker {
    return new FixMarkersRequest_Marker().fromJsonString(jsonString, options);
  }

  static equals(a: FixMarkersRequest_Marker | PlainMessage<FixMarkersRequest_Marker> | undefined, b: FixMarkersRequest_Marker | PlainMessage<FixMarkersRequest_Marker> | undefined): boolean {
    return proto3.util.equals(FixMarkersRequest_Marker, a, b);
  }
}

/**
 * @generated from message aiserver.v1.FixMarkersRequest.Marker.RelatedInformation
 */
export class FixMarkersRequest_Marker_RelatedInformation extends Message<FixMarkersRequest_Marker_RelatedInformation> {
  /**
   * @generated from field: string message = 1;
   */
  message = "";

  /**
   * @generated from field: string relative_workspace_path = 2;
   */
  relativeWorkspacePath = "";

  /**
   * @generated from field: repeated string relevant_lines = 3;
   */
  relevantLines: string[] = [];

  /**
   * start line number of relevant code
   *
   * @generated from field: int32 start_line = 4;
   */
  startLine = 0;

  constructor(data?: PartialMessage<FixMarkersRequest_Marker_RelatedInformation>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.FixMarkersRequest.Marker.RelatedInformation";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "message", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "relevant_lines", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 4, name: "start_line", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): FixMarkersRequest_Marker_RelatedInformation {
    return new FixMarkersRequest_Marker_RelatedInformation().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_RelatedInformation {
    return new FixMarkersRequest_Marker_RelatedInformation().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_RelatedInformation {
    return new FixMarkersRequest_Marker_RelatedInformation().fromJsonString(jsonString, options);
  }

  static equals(a: FixMarkersRequest_Marker_RelatedInformation | PlainMessage<FixMarkersRequest_Marker_RelatedInformation> | undefined, b: FixMarkersRequest_Marker_RelatedInformation | PlainMessage<FixMarkersRequest_Marker_RelatedInformation> | undefined): boolean {
    return proto3.util.equals(FixMarkersRequest_Marker_RelatedInformation, a, b);
  }
}

/**
 * e.g. class, function headers; we might want to make changes to this
 *
 * @generated from message aiserver.v1.FixMarkersRequest.Marker.ContextRange
 */
export class FixMarkersRequest_Marker_ContextRange extends Message<FixMarkersRequest_Marker_ContextRange> {
  /**
   * @generated from field: int32 start_line = 1;
   */
  startLine = 0;

  /**
   * @generated from field: int32 end_line_inclusive = 2;
   */
  endLineInclusive = 0;

  constructor(data?: PartialMessage<FixMarkersRequest_Marker_ContextRange>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.FixMarkersRequest.Marker.ContextRange";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "start_line", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 2, name: "end_line_inclusive", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): FixMarkersRequest_Marker_ContextRange {
    return new FixMarkersRequest_Marker_ContextRange().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_ContextRange {
    return new FixMarkersRequest_Marker_ContextRange().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_ContextRange {
    return new FixMarkersRequest_Marker_ContextRange().fromJsonString(jsonString, options);
  }

  static equals(a: FixMarkersRequest_Marker_ContextRange | PlainMessage<FixMarkersRequest_Marker_ContextRange> | undefined, b: FixMarkersRequest_Marker_ContextRange | PlainMessage<FixMarkersRequest_Marker_ContextRange> | undefined): boolean {
    return proto3.util.equals(FixMarkersRequest_Marker_ContextRange, a, b);
  }
}

/**
 * @generated from message aiserver.v1.FixMarkersRequest.Marker.AncestorTypeDefinition
 */
export class FixMarkersRequest_Marker_AncestorTypeDefinition extends Message<FixMarkersRequest_Marker_AncestorTypeDefinition> {
  /**
   * name of the symbol we're defining type for
   *
   * @generated from field: string name = 1;
   */
  name = "";

  /**
   * path to the file where the symbol is defined
   *
   * @generated from field: string relative_workspace_path = 2;
   */
  relativeWorkspacePath = "";

  /**
   * this is just a chunk of lines, unlike code-folded
   * class information, because for ancestor types we
   * shouldn't need to know what the type contains
   *
   * @generated from field: int32 start_line = 3;
   */
  startLine = 0;

  /**
   * just the lines in the definition, lines[0]
   * is the line on start_line
   *
   * @generated from field: repeated string lines = 4;
   */
  lines: string[] = [];

  constructor(data?: PartialMessage<FixMarkersRequest_Marker_AncestorTypeDefinition>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.FixMarkersRequest.Marker.AncestorTypeDefinition";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "start_line", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 4, name: "lines", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): FixMarkersRequest_Marker_AncestorTypeDefinition {
    return new FixMarkersRequest_Marker_AncestorTypeDefinition().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_AncestorTypeDefinition {
    return new FixMarkersRequest_Marker_AncestorTypeDefinition().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_AncestorTypeDefinition {
    return new FixMarkersRequest_Marker_AncestorTypeDefinition().fromJsonString(jsonString, options);
  }

  static equals(a: FixMarkersRequest_Marker_AncestorTypeDefinition | PlainMessage<FixMarkersRequest_Marker_AncestorTypeDefinition> | undefined, b: FixMarkersRequest_Marker_AncestorTypeDefinition | PlainMessage<FixMarkersRequest_Marker_AncestorTypeDefinition> | undefined): boolean {
    return proto3.util.equals(FixMarkersRequest_Marker_AncestorTypeDefinition, a, b);
  }
}

/**
 * this gives us types of symbols that the AI model
 *
 * @generated from message aiserver.v1.FixMarkersRequest.Marker.InsertedSymbolType
 */
export class FixMarkersRequest_Marker_InsertedSymbolType extends Message<FixMarkersRequest_Marker_InsertedSymbolType> {
  /**
   * might have inserted during its last run
   *
   * @generated from field: string symbol_name = 1;
   */
  symbolName = "";

  /**
   * @generated from field: string symbol_type = 2;
   */
  symbolType = "";

  /**
   * @generated from field: string relative_workspace_path = 3;
   */
  relativeWorkspacePath = "";

  /**
   * @generated from field: int32 symbol_line = 4;
   */
  symbolLine = 0;

  constructor(data?: PartialMessage<FixMarkersRequest_Marker_InsertedSymbolType>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.FixMarkersRequest.Marker.InsertedSymbolType";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "symbol_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "symbol_type", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "symbol_line", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): FixMarkersRequest_Marker_InsertedSymbolType {
    return new FixMarkersRequest_Marker_InsertedSymbolType().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_InsertedSymbolType {
    return new FixMarkersRequest_Marker_InsertedSymbolType().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_InsertedSymbolType {
    return new FixMarkersRequest_Marker_InsertedSymbolType().fromJsonString(jsonString, options);
  }

  static equals(a: FixMarkersRequest_Marker_InsertedSymbolType | PlainMessage<FixMarkersRequest_Marker_InsertedSymbolType> | undefined, b: FixMarkersRequest_Marker_InsertedSymbolType | PlainMessage<FixMarkersRequest_Marker_InsertedSymbolType> | undefined): boolean {
    return proto3.util.equals(FixMarkersRequest_Marker_InsertedSymbolType, a, b);
  }
}

/**
 * @generated from message aiserver.v1.FixMarkersRequest.Marker.QuickFix
 */
export class FixMarkersRequest_Marker_QuickFix extends Message<FixMarkersRequest_Marker_QuickFix> {
  /**
   * @generated from field: string message = 1;
   */
  message = "";

  /**
   * @generated from field: string kind = 2;
   */
  kind = "";

  /**
   * @generated from field: bool is_preferred = 3;
   */
  isPreferred = false;

  /**
   * @generated from field: repeated aiserver.v1.FixMarkersRequest.Marker.QuickFix.Edit edits = 4;
   */
  edits: FixMarkersRequest_Marker_QuickFix_Edit[] = [];

  constructor(data?: PartialMessage<FixMarkersRequest_Marker_QuickFix>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.FixMarkersRequest.Marker.QuickFix";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "message", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "kind", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "is_preferred", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 4, name: "edits", kind: "message", T: FixMarkersRequest_Marker_QuickFix_Edit, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): FixMarkersRequest_Marker_QuickFix {
    return new FixMarkersRequest_Marker_QuickFix().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_QuickFix {
    return new FixMarkersRequest_Marker_QuickFix().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_QuickFix {
    return new FixMarkersRequest_Marker_QuickFix().fromJsonString(jsonString, options);
  }

  static equals(a: FixMarkersRequest_Marker_QuickFix | PlainMessage<FixMarkersRequest_Marker_QuickFix> | undefined, b: FixMarkersRequest_Marker_QuickFix | PlainMessage<FixMarkersRequest_Marker_QuickFix> | undefined): boolean {
    return proto3.util.equals(FixMarkersRequest_Marker_QuickFix, a, b);
  }
}

/**
 * @generated from message aiserver.v1.FixMarkersRequest.Marker.QuickFix.Edit
 */
export class FixMarkersRequest_Marker_QuickFix_Edit extends Message<FixMarkersRequest_Marker_QuickFix_Edit> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * @generated from field: int32 start_line = 2;
   */
  startLine = 0;

  /**
   * @generated from field: int32 end_line_inclusive = 3;
   */
  endLineInclusive = 0;

  /**
   * @generated from field: repeated string deleted_lines = 4;
   */
  deletedLines: string[] = [];

  /**
   * @generated from field: repeated string add_lines = 5;
   */
  addLines: string[] = [];

  /**
   * @generated from field: int32 snapshot = 6;
   */
  snapshot = 0;

  constructor(data?: PartialMessage<FixMarkersRequest_Marker_QuickFix_Edit>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.FixMarkersRequest.Marker.QuickFix.Edit";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "start_line", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "end_line_inclusive", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 4, name: "deleted_lines", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 5, name: "add_lines", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 6, name: "snapshot", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): FixMarkersRequest_Marker_QuickFix_Edit {
    return new FixMarkersRequest_Marker_QuickFix_Edit().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_QuickFix_Edit {
    return new FixMarkersRequest_Marker_QuickFix_Edit().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_QuickFix_Edit {
    return new FixMarkersRequest_Marker_QuickFix_Edit().fromJsonString(jsonString, options);
  }

  static equals(a: FixMarkersRequest_Marker_QuickFix_Edit | PlainMessage<FixMarkersRequest_Marker_QuickFix_Edit> | undefined, b: FixMarkersRequest_Marker_QuickFix_Edit | PlainMessage<FixMarkersRequest_Marker_QuickFix_Edit> | undefined): boolean {
    return proto3.util.equals(FixMarkersRequest_Marker_QuickFix_Edit, a, b);
  }
}

/**
 * @generated from message aiserver.v1.FixMarkersRequest.Marker.ClassInformation
 */
export class FixMarkersRequest_Marker_ClassInformation extends Message<FixMarkersRequest_Marker_ClassInformation> {
  /**
   * @generated from field: string class_name = 1;
   */
  className = "";

  /**
   * @generated from field: int32 start_line = 2;
   */
  startLine = 0;

  /**
   * lines that don't go away after code folding
   *
   * @generated from field: repeated int32 top_level_lines = 3;
   */
  topLevelLines: number[] = [];

  /**
   * @generated from field: repeated string lines = 4;
   */
  lines: string[] = [];

  /**
   * @generated from field: repeated aiserver.v1.FixMarkersRequest.Marker.ClassInformation.Constructor constructors = 5;
   */
  constructors: FixMarkersRequest_Marker_ClassInformation_Constructor[] = [];

  /**
   * @generated from field: string detail = 6;
   */
  detail = "";

  constructor(data?: PartialMessage<FixMarkersRequest_Marker_ClassInformation>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.FixMarkersRequest.Marker.ClassInformation";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "class_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "start_line", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "top_level_lines", kind: "scalar", T: 5 /* ScalarType.INT32 */, repeated: true },
    { no: 4, name: "lines", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 5, name: "constructors", kind: "message", T: FixMarkersRequest_Marker_ClassInformation_Constructor, repeated: true },
    { no: 6, name: "detail", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): FixMarkersRequest_Marker_ClassInformation {
    return new FixMarkersRequest_Marker_ClassInformation().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_ClassInformation {
    return new FixMarkersRequest_Marker_ClassInformation().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_ClassInformation {
    return new FixMarkersRequest_Marker_ClassInformation().fromJsonString(jsonString, options);
  }

  static equals(a: FixMarkersRequest_Marker_ClassInformation | PlainMessage<FixMarkersRequest_Marker_ClassInformation> | undefined, b: FixMarkersRequest_Marker_ClassInformation | PlainMessage<FixMarkersRequest_Marker_ClassInformation> | undefined): boolean {
    return proto3.util.equals(FixMarkersRequest_Marker_ClassInformation, a, b);
  }
}

/**
 * @generated from message aiserver.v1.FixMarkersRequest.Marker.ClassInformation.Constructor
 */
export class FixMarkersRequest_Marker_ClassInformation_Constructor extends Message<FixMarkersRequest_Marker_ClassInformation_Constructor> {
  /**
   * @generated from field: int32 start_line = 1;
   */
  startLine = 0;

  /**
   * @generated from field: int32 end_line_inclusive = 2;
   */
  endLineInclusive = 0;

  constructor(data?: PartialMessage<FixMarkersRequest_Marker_ClassInformation_Constructor>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.FixMarkersRequest.Marker.ClassInformation.Constructor";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "start_line", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 2, name: "end_line_inclusive", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): FixMarkersRequest_Marker_ClassInformation_Constructor {
    return new FixMarkersRequest_Marker_ClassInformation_Constructor().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_ClassInformation_Constructor {
    return new FixMarkersRequest_Marker_ClassInformation_Constructor().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_ClassInformation_Constructor {
    return new FixMarkersRequest_Marker_ClassInformation_Constructor().fromJsonString(jsonString, options);
  }

  static equals(a: FixMarkersRequest_Marker_ClassInformation_Constructor | PlainMessage<FixMarkersRequest_Marker_ClassInformation_Constructor> | undefined, b: FixMarkersRequest_Marker_ClassInformation_Constructor | PlainMessage<FixMarkersRequest_Marker_ClassInformation_Constructor> | undefined): boolean {
    return proto3.util.equals(FixMarkersRequest_Marker_ClassInformation_Constructor, a, b);
  }
}

/**
 * @generated from message aiserver.v1.FixMarkersRequest.Marker.FunctionSignature
 */
export class FixMarkersRequest_Marker_FunctionSignature extends Message<FixMarkersRequest_Marker_FunctionSignature> {
  /**
   * @generated from field: string label = 1;
   */
  label = "";

  /**
   * @generated from field: string documentation = 2;
   */
  documentation = "";

  /**
   * @generated from field: repeated aiserver.v1.FixMarkersRequest.Marker.FunctionSignature.FunctionParameter parameters = 3;
   */
  parameters: FixMarkersRequest_Marker_FunctionSignature_FunctionParameter[] = [];

  constructor(data?: PartialMessage<FixMarkersRequest_Marker_FunctionSignature>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.FixMarkersRequest.Marker.FunctionSignature";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "label", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "documentation", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "parameters", kind: "message", T: FixMarkersRequest_Marker_FunctionSignature_FunctionParameter, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): FixMarkersRequest_Marker_FunctionSignature {
    return new FixMarkersRequest_Marker_FunctionSignature().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_FunctionSignature {
    return new FixMarkersRequest_Marker_FunctionSignature().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_FunctionSignature {
    return new FixMarkersRequest_Marker_FunctionSignature().fromJsonString(jsonString, options);
  }

  static equals(a: FixMarkersRequest_Marker_FunctionSignature | PlainMessage<FixMarkersRequest_Marker_FunctionSignature> | undefined, b: FixMarkersRequest_Marker_FunctionSignature | PlainMessage<FixMarkersRequest_Marker_FunctionSignature> | undefined): boolean {
    return proto3.util.equals(FixMarkersRequest_Marker_FunctionSignature, a, b);
  }
}

/**
 * @generated from message aiserver.v1.FixMarkersRequest.Marker.FunctionSignature.FunctionParameter
 */
export class FixMarkersRequest_Marker_FunctionSignature_FunctionParameter extends Message<FixMarkersRequest_Marker_FunctionSignature_FunctionParameter> {
  /**
   * @generated from field: string label = 1;
   */
  label = "";

  /**
   * @generated from field: string documentation = 2;
   */
  documentation = "";

  constructor(data?: PartialMessage<FixMarkersRequest_Marker_FunctionSignature_FunctionParameter>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.FixMarkersRequest.Marker.FunctionSignature.FunctionParameter";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "label", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "documentation", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): FixMarkersRequest_Marker_FunctionSignature_FunctionParameter {
    return new FixMarkersRequest_Marker_FunctionSignature_FunctionParameter().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_FunctionSignature_FunctionParameter {
    return new FixMarkersRequest_Marker_FunctionSignature_FunctionParameter().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): FixMarkersRequest_Marker_FunctionSignature_FunctionParameter {
    return new FixMarkersRequest_Marker_FunctionSignature_FunctionParameter().fromJsonString(jsonString, options);
  }

  static equals(a: FixMarkersRequest_Marker_FunctionSignature_FunctionParameter | PlainMessage<FixMarkersRequest_Marker_FunctionSignature_FunctionParameter> | undefined, b: FixMarkersRequest_Marker_FunctionSignature_FunctionParameter | PlainMessage<FixMarkersRequest_Marker_FunctionSignature_FunctionParameter> | undefined): boolean {
    return proto3.util.equals(FixMarkersRequest_Marker_FunctionSignature_FunctionParameter, a, b);
  }
}

/**
 * @generated from message aiserver.v1.FixMarkersResponse
 */
export class FixMarkersResponse extends Message<FixMarkersResponse> {
  /**
   * @generated from field: string relative_workspace_path = 1;
   */
  relativeWorkspacePath = "";

  /**
   * @generated from field: repeated aiserver.v1.FixMarkersResponse.Change changes = 2;
   */
  changes: FixMarkersResponse_Change[] = [];

  /**
   * this is to prevent repeatedly trying to fix a marker that
   *
   * @generated from field: bool success = 3;
   */
  success = false;

  /**
   * cannot be fixed
   *
   * original iteration number
   *
   * @generated from field: int32 iteration_number = 4;
   */
  iterationNumber = 0;

  constructor(data?: PartialMessage<FixMarkersResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.FixMarkersResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "changes", kind: "message", T: FixMarkersResponse_Change, repeated: true },
    { no: 3, name: "success", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 4, name: "iteration_number", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): FixMarkersResponse {
    return new FixMarkersResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): FixMarkersResponse {
    return new FixMarkersResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): FixMarkersResponse {
    return new FixMarkersResponse().fromJsonString(jsonString, options);
  }

  static equals(a: FixMarkersResponse | PlainMessage<FixMarkersResponse> | undefined, b: FixMarkersResponse | PlainMessage<FixMarkersResponse> | undefined): boolean {
    return proto3.util.equals(FixMarkersResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.FixMarkersResponse.Change
 */
export class FixMarkersResponse_Change extends Message<FixMarkersResponse_Change> {
  /**
   * the line numbers are 1-indexed from file before!
   *
   * @generated from field: int32 start_line = 1;
   */
  startLine = 0;

  /**
   * changes are made (like Inline Diffs)
   *
   * set equal to start_line if no deletion
   *
   * @generated from field: int32 end_line_exclusive = 2;
   */
  endLineExclusive = 0;

  /**
   * this sets apart 1 empty line vs empty string
   *
   * @generated from field: repeated string deleted_lines = 3;
   */
  deletedLines: string[] = [];

  /**
   * @generated from field: repeated string add_lines = 4;
   */
  addLines: string[] = [];

  constructor(data?: PartialMessage<FixMarkersResponse_Change>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.FixMarkersResponse.Change";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "start_line", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 2, name: "end_line_exclusive", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "deleted_lines", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 4, name: "add_lines", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): FixMarkersResponse_Change {
    return new FixMarkersResponse_Change().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): FixMarkersResponse_Change {
    return new FixMarkersResponse_Change().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): FixMarkersResponse_Change {
    return new FixMarkersResponse_Change().fromJsonString(jsonString, options);
  }

  static equals(a: FixMarkersResponse_Change | PlainMessage<FixMarkersResponse_Change> | undefined, b: FixMarkersResponse_Change | PlainMessage<FixMarkersResponse_Change> | undefined): boolean {
    return proto3.util.equals(FixMarkersResponse_Change, a, b);
  }
}

/**
 * ---- start of deprecated ----
 *
 * @generated from message aiserver.v1.StreamLintRequest
 */
export class StreamLintRequest extends Message<StreamLintRequest> {
  /**
   * @generated from field: aiserver.v1.CurrentFileInfo current_file = 1;
   */
  currentFile?: CurrentFileInfo;

  /**
   * @generated from field: repeated aiserver.v1.ConversationMessage conversation = 2;
   */
  conversation: ConversationMessage[] = [];

  /**
   * @generated from field: repeated aiserver.v1.RepositoryInfo repositories = 3;
   */
  repositories: RepositoryInfo[] = [];

  /**
   * @generated from field: aiserver.v1.ExplicitContext explicit_context = 4;
   */
  explicitContext?: ExplicitContext;

  /**
   * @generated from field: optional string workspace_root_path = 5;
   */
  workspaceRootPath?: string;

  /**
   * @generated from field: string query = 6;
   */
  query = "";

  /**
   * Other code blocks to add in
   *
   * @generated from field: repeated aiserver.v1.CodeBlock code_blocks = 7;
   */
  codeBlocks: CodeBlock[] = [];

  /**
   * What model to use and api key to use if applicable
   *
   * @generated from field: aiserver.v1.ModelDetails model_details = 9;
   */
  modelDetails?: ModelDetails;

  /**
   * @generated from field: repeated string documentation_identifiers = 10;
   */
  documentationIdentifiers: string[] = [];

  /**
   * @generated from field: repeated string bad_notifications = 11;
   */
  badNotifications: string[] = [];

  /**
   * @generated from field: string lint_rules = 12;
   */
  lintRules = "";

  constructor(data?: PartialMessage<StreamLintRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.StreamLintRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "current_file", kind: "message", T: CurrentFileInfo },
    { no: 2, name: "conversation", kind: "message", T: ConversationMessage, repeated: true },
    { no: 3, name: "repositories", kind: "message", T: RepositoryInfo, repeated: true },
    { no: 4, name: "explicit_context", kind: "message", T: ExplicitContext },
    { no: 5, name: "workspace_root_path", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 6, name: "query", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 7, name: "code_blocks", kind: "message", T: CodeBlock, repeated: true },
    { no: 9, name: "model_details", kind: "message", T: ModelDetails },
    { no: 10, name: "documentation_identifiers", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 11, name: "bad_notifications", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 12, name: "lint_rules", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamLintRequest {
    return new StreamLintRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamLintRequest {
    return new StreamLintRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamLintRequest {
    return new StreamLintRequest().fromJsonString(jsonString, options);
  }

  static equals(a: StreamLintRequest | PlainMessage<StreamLintRequest> | undefined, b: StreamLintRequest | PlainMessage<StreamLintRequest> | undefined): boolean {
    return proto3.util.equals(StreamLintRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ReportGroundTruthCandidateRequest
 */
export class ReportGroundTruthCandidateRequest extends Message<ReportGroundTruthCandidateRequest> {
  /**
   * the request ID of the originating request that we are now reporting the
   * ground truth for
   *
   * @generated from field: string request_id = 1;
   */
  requestId = "";

  /**
   * @generated from field: int32 time_since_completed_action_ms = 2;
   */
  timeSinceCompletedActionMs = 0;

  /**
   * @generated from field: aiserver.v1.FeatureType feature_type = 3;
   */
  featureType = FeatureType.UNSPECIFIED;

  /**
   * ground truth is generally just the file + value of a selection
   * how the selection defined is up to the feature. for eg edits it is the
   * original selection, but moved to the new file
   *
   * @generated from field: string relative_workspace_path = 4;
   */
  relativeWorkspacePath = "";

  /**
   * @generated from field: string contents = 5;
   */
  contents = "";

  /**
   * @generated from field: aiserver.v1.LineRange selection_in_question = 6;
   */
  selectionInQuestion?: LineRange;

  /**
   * to prevent weird things from happening, we record a few lines above and
   * below the selection this makes the ground truth more robust this is
   * generally something like 3
   *
   * @generated from field: int32 lines_above_and_below = 7;
   */
  linesAboveAndBelow = 0;

  constructor(data?: PartialMessage<ReportGroundTruthCandidateRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ReportGroundTruthCandidateRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "request_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "time_since_completed_action_ms", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "feature_type", kind: "enum", T: proto3.getEnumType(FeatureType) },
    { no: 4, name: "relative_workspace_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 5, name: "contents", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 6, name: "selection_in_question", kind: "message", T: LineRange },
    { no: 7, name: "lines_above_and_below", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ReportGroundTruthCandidateRequest {
    return new ReportGroundTruthCandidateRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ReportGroundTruthCandidateRequest {
    return new ReportGroundTruthCandidateRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ReportGroundTruthCandidateRequest {
    return new ReportGroundTruthCandidateRequest().fromJsonString(jsonString, options);
  }

  static equals(a: ReportGroundTruthCandidateRequest | PlainMessage<ReportGroundTruthCandidateRequest> | undefined, b: ReportGroundTruthCandidateRequest | PlainMessage<ReportGroundTruthCandidateRequest> | undefined): boolean {
    return proto3.util.equals(ReportGroundTruthCandidateRequest, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ReportGroundTruthCandidateResponse
 */
export class ReportGroundTruthCandidateResponse extends Message<ReportGroundTruthCandidateResponse> {
  constructor(data?: PartialMessage<ReportGroundTruthCandidateResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ReportGroundTruthCandidateResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ReportGroundTruthCandidateResponse {
    return new ReportGroundTruthCandidateResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ReportGroundTruthCandidateResponse {
    return new ReportGroundTruthCandidateResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ReportGroundTruthCandidateResponse {
    return new ReportGroundTruthCandidateResponse().fromJsonString(jsonString, options);
  }

  static equals(a: ReportGroundTruthCandidateResponse | PlainMessage<ReportGroundTruthCandidateResponse> | undefined, b: ReportGroundTruthCandidateResponse | PlainMessage<ReportGroundTruthCandidateResponse> | undefined): boolean {
    return proto3.util.equals(ReportGroundTruthCandidateResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.ReportCmdKFateRequest
 */
export class ReportCmdKFateRequest extends Message<ReportCmdKFateRequest> {
  /**
   * the request ID of the originating request that we are now reporting the
   * ground truth for
   *
   * @generated from field: string request_id = 1;
   */
  requestId = "";

  /**
   * @generated from field: aiserver.v1.ReportCmdKFateRequest.Fate fate = 2;
   */
  fate = ReportCmdKFateRequest_Fate.UNSPECIFIED;

  constructor(data?: PartialMessage<ReportCmdKFateRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ReportCmdKFateRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "request_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "fate", kind: "enum", T: proto3.getEnumType(ReportCmdKFateRequest_Fate) },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ReportCmdKFateRequest {
    return new ReportCmdKFateRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ReportCmdKFateRequest {
    return new ReportCmdKFateRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ReportCmdKFateRequest {
    return new ReportCmdKFateRequest().fromJsonString(jsonString, options);
  }

  static equals(a: ReportCmdKFateRequest | PlainMessage<ReportCmdKFateRequest> | undefined, b: ReportCmdKFateRequest | PlainMessage<ReportCmdKFateRequest> | undefined): boolean {
    return proto3.util.equals(ReportCmdKFateRequest, a, b);
  }
}

/**
 * the fate of the cmd-k request
 *
 * @generated from enum aiserver.v1.ReportCmdKFateRequest.Fate
 */
export enum ReportCmdKFateRequest_Fate {
  /**
   * @generated from enum value: FATE_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: FATE_CANCELLED = 1;
   */
  CANCELLED = 1,

  /**
   * @generated from enum value: FATE_ACCEPTED = 2;
   */
  ACCEPTED = 2,

  /**
   * @generated from enum value: FATE_REJECTED = 3;
   */
  REJECTED = 3,

  /**
   * @generated from enum value: FATE_FOLLOWED_UP = 4;
   */
  FOLLOWED_UP = 4,

  /**
   * @generated from enum value: FATE_REPROMPTED = 5;
   */
  REPROMPTED = 5,
}
// Retrieve enum metadata with: proto3.getEnumType(ReportCmdKFateRequest_Fate)
proto3.util.setEnumType(ReportCmdKFateRequest_Fate, "aiserver.v1.ReportCmdKFateRequest.Fate", [
  { no: 0, name: "FATE_UNSPECIFIED" },
  { no: 1, name: "FATE_CANCELLED" },
  { no: 2, name: "FATE_ACCEPTED" },
  { no: 3, name: "FATE_REJECTED" },
  { no: 4, name: "FATE_FOLLOWED_UP" },
  { no: 5, name: "FATE_REPROMPTED" },
]);

/**
 * @generated from message aiserver.v1.ReportCmdKFateResponse
 */
export class ReportCmdKFateResponse extends Message<ReportCmdKFateResponse> {
  constructor(data?: PartialMessage<ReportCmdKFateResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.ReportCmdKFateResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ReportCmdKFateResponse {
    return new ReportCmdKFateResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ReportCmdKFateResponse {
    return new ReportCmdKFateResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ReportCmdKFateResponse {
    return new ReportCmdKFateResponse().fromJsonString(jsonString, options);
  }

  static equals(a: ReportCmdKFateResponse | PlainMessage<ReportCmdKFateResponse> | undefined, b: ReportCmdKFateResponse | PlainMessage<ReportCmdKFateResponse> | undefined): boolean {
    return proto3.util.equals(ReportCmdKFateResponse, a, b);
  }
}

/**
 * @generated from message aiserver.v1.SshConfigPromptProps
 */
export class SshConfigPromptProps extends Message<SshConfigPromptProps> {
  /**
   * @generated from field: string ssh_string = 1;
   */
  sshString = "";

  constructor(data?: PartialMessage<SshConfigPromptProps>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "aiserver.v1.SshConfigPromptProps";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "ssh_string", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): SshConfigPromptProps {
    return new SshConfigPromptProps().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): SshConfigPromptProps {
    return new SshConfigPromptProps().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): SshConfigPromptProps {
    return new SshConfigPromptProps().fromJsonString(jsonString, options);
  }

  static equals(a: SshConfigPromptProps | PlainMessage<SshConfigPromptProps> | undefined, b: SshConfigPromptProps | PlainMessage<SshConfigPromptProps> | undefined): boolean {
    return proto3.util.equals(SshConfigPromptProps, a, b);
  }
}

